
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
   üñ•Ô∏è GopiAI-UI Application
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üîÑ Activating UI environment...
‚úÖ Environment activated
üìÇ Directory: GopiAI-UI
üêç Environment: C:\Users\crazy\GOPI_AI_MODULES\gopiai_env

üöÄ Starting GopiAI-UI Application...
2025-07-12 05:38:36,629 - GopiAI - INFO - [GOPIAI] GopiAI Unified Logger initialized
2025-07-12 05:38:37,345 - gopiai.ui.components.crewai_client - WARNING - ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å spaCy –∏–ª–∏ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏: No module named 'spacy'
2025-07-12 05:38:37,356 - gopiai.ui.memory.manager - INFO - ‚úÖ Simple emotion classifier initialized
2025-07-12 05:38:37,364 - gopiai.ui.memory.manager - INFO - Loaded 542 messages from C:\Users\crazy\.gopiai\memory\chats.json
2025-07-12 05:38:37,364 - gopiai.ui.memory.manager - INFO - Loaded 52 sessions from C:\Users\crazy\.gopiai\memory\sessions.json
2025-07-12 05:38:37,547 - faiss.loader - DEBUG - Environment variable FAISS_OPT_LEVEL is not set, so let's pick the instruction set according to the current CPU
2025-07-12 05:38:37,624 - faiss.loader - INFO - Loading faiss with AVX2 support.
2025-07-12 05:38:37,678 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2025-07-12 05:38:37,688 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-07-12 05:38:49,096 - gopiai.ui.memory.manager - INFO - Initializing embeddings at C:/Users/crazy/.gopiai/memory/vectors
2025-07-12 05:38:49,096 - gopiai.ui.memory.manager - INFO - FAISS found, AVX2 support: True
2025-07-12 05:38:49,105 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2025-07-12 05:38:49,944 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/nli-mpnet-base-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-07-12 05:38:49,989 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/nli-mpnet-base-v2/20bdd570b61882341b3cedf7fe1246b109f26517/config.json HTTP/1.1" 200 0
2025-07-12 05:38:50,714 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/nli-mpnet-base-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-07-12 05:38:50,758 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/nli-mpnet-base-v2/20bdd570b61882341b3cedf7fe1246b109f26517/config.json HTTP/1.1" 200 0
2025-07-12 05:38:51,035 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/nli-mpnet-base-v2/resolve/main/1_Pooling/config.json HTTP/1.1" 307 0
2025-07-12 05:38:51,078 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/nli-mpnet-base-v2/20bdd570b61882341b3cedf7fe1246b109f26517/1_Pooling%2Fconfig.json HTTP/1.1" 200 0
2025-07-12 05:38:51,789 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/nli-mpnet-base-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-07-12 05:38:51,838 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/nli-mpnet-base-v2/20bdd570b61882341b3cedf7fe1246b109f26517/config.json HTTP/1.1" 200 0
2025-07-12 05:38:53,695 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/nli-mpnet-base-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-07-12 05:38:53,738 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/nli-mpnet-base-v2/20bdd570b61882341b3cedf7fe1246b109f26517/tokenizer_config.json HTTP/1.1" 200 0
2025-07-12 05:38:54,463 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/nli-mpnet-base-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-07-12 05:38:54,524 - gopiai.ui.memory.manager - INFO - No existing embeddings found, will create a new index.
2025-07-12 05:38:54,551 - gopiai.ui.memory.manager - INFO - Saved embeddings to C:/Users/crazy/.gopiai/memory/vectors
2025-07-12 05:38:54,552 - gopiai.ui.memory.manager - INFO - Updated and saved 542 items to embeddings index.
2025-07-12 05:38:54,557 - gopiai.ui.components.chat_widget - INFO - ‚úÖ Memory manager initialized
üîß Enhanced DEBUG logging enabled for chat_widget.py (console + file)
2025-07-12 05:38:54,564 - gopiai.ui.components.chat_widget - INFO - === Chat Widget Debug Session Started ===
–ú–æ–¥—É–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è GopiAI v0.3.2 —Å —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π —Ç–µ–º
–î–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ –ø—É—Ç–∏ –¥–ª—è –º–æ–¥—É–ª–µ–π:
- C:\Users\crazy\GOPI_AI_MODULES\GopiAI-Core (—Å—É—â–µ—Å—Ç–≤—É–µ—Ç: True)
- C:\Users\crazy\GOPI_AI_MODULES\GopiAI-Widgets (—Å—É—â–µ—Å—Ç–≤—É–µ—Ç: True)
- C:\Users\crazy\GOPI_AI_MODULES\GopiAI-App (—Å—É—â–µ—Å—Ç–≤—É–µ—Ç: True)
- C:\Users\crazy\GOPI_AI_MODULES\GopiAI-Extensions (—Å—É—â–µ—Å—Ç–≤—É–µ—Ç: True)
- C:\Users\crazy\GOPI_AI_MODULES\rag_memory_system (—Å—É—â–µ—Å—Ç–≤—É–µ—Ç: True)
- C:\Users\crazy\GOPI_AI_MODULES (—Å—É—â–µ—Å—Ç–≤—É–µ—Ç: True)
[OK] –í—Å–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –º–æ–¥—É–ª–∏ UI –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ
[MEMORY] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω MemoryManager
[MEMORY] –î–∞–Ω–Ω—ã–µ —Ö—Ä–∞–Ω—è—Ç—Å—è –≤: C:\Users\crazy\.gopiai\memory
[WARNING] –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –ø–∞–º—è—Ç–∏: name 'datetime' is not defined
[LAUNCH] –ó–∞–ø—É—Å–∫ –º–æ–¥—É–ª—å–Ω–æ–≥–æ GopiAI...
üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥—É–ª—å–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ GopiAI —Å —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π —Ç–µ–º...
[WARNING] –°–∏—Å—Ç–µ–º–∞ –∏–∫–æ–Ω–æ–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞
2025-07-12 05:38:54,635 - gopiai.ui.utils.theme_manager - INFO - –ó–∞–≥—Ä—É–∂–µ–Ω–∞ —Ç–µ–º–∞: Indigo Candy (dark)
‚úÖ –ú–µ–Ω–µ–¥–∂–µ—Ä —Ç–µ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω
2025-07-12 05:38:54,637 - gopiai.ui.utils.theme_manager - INFO - –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ç–µ–º—ã –∫ QApplication/QCoreApplication
‚úÖ –ü—Ä–∏–º–µ–Ω–µ–Ω–∞ —Ç–µ–º–∞ –∏–∑ —Ñ–∞–π–ª–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫
[SETUP] –ù–∞—Å—Ç—Ä–æ–π–∫–∞ UI –∏–∑ –º–æ–¥—É–ª–µ–π...
INFO: ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 1597 Lucide –∏–∫–æ–Ω–æ–∫
2025-07-12 05:38:55,210 - icon_manager - INFO - ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 1597 Lucide –∏–∫–æ–Ω–æ–∫
INFO: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω UniversalIconManager —Å Lucide –∏–∫–æ–Ω–∫–∞–º–∏
2025-07-12 05:38:55,218 - icon_manager - INFO - –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω UniversalIconManager —Å Lucide –∏–∫–æ–Ω–∫–∞–º–∏
‚úÖ Titlebar: –ó–∞–≥—Ä—É–∂–µ–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ –∏–∫–æ–Ω–æ–∫ UniversalIconManager
INFO: ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 1597 Lucide –∏–∫–æ–Ω–æ–∫
2025-07-12 05:38:55,584 - icon_manager - INFO - ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 1597 Lucide –∏–∫–æ–Ω–æ–∫
INFO: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω UniversalIconManager —Å Lucide –∏–∫–æ–Ω–∫–∞–º–∏
2025-07-12 05:38:55,588 - icon_manager - INFO - –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω UniversalIconManager —Å Lucide –∏–∫–æ–Ω–∫–∞–º–∏
‚úÖ Titlebar: –ó–∞–≥—Ä—É–∂–µ–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ –∏–∫–æ–Ω–æ–∫ UniversalIconManager
INFO: ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 1597 Lucide –∏–∫–æ–Ω–æ–∫
2025-07-12 05:38:55,952 - icon_manager - INFO - ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 1597 Lucide –∏–∫–æ–Ω–æ–∫
INFO: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω UniversalIconManager —Å Lucide –∏–∫–æ–Ω–∫–∞–º–∏
2025-07-12 05:38:55,955 - icon_manager - INFO - –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω UniversalIconManager —Å Lucide –∏–∫–æ–Ω–∫–∞–º–∏
INFO: ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 1597 Lucide –∏–∫–æ–Ω–æ–∫
2025-07-12 05:38:56,368 - icon_manager - INFO - ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 1597 Lucide –∏–∫–æ–Ω–æ–∫
INFO: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω UniversalIconManager —Å Lucide –∏–∫–æ–Ω–∫–∞–º–∏
2025-07-12 05:38:56,371 - icon_manager - INFO - –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω UniversalIconManager —Å Lucide –∏–∫–æ–Ω–∫–∞–º–∏
‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ –∏–∫–æ–Ω–æ–∫ UniversalIconManager
üé® CustomFileSystemModel –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —Å icon_manager: <class 'gopiai.ui.components.icon_file_system_model.UniversalIconManager'>
INFO: ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 1597 Lucide –∏–∫–æ–Ω–æ–∫
2025-07-12 05:38:56,766 - icon_manager - INFO - ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 1597 Lucide –∏–∫–æ–Ω–æ–∫
INFO: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω UniversalIconManager —Å Lucide –∏–∫–æ–Ω–∫–∞–º–∏
2025-07-12 05:38:56,770 - icon_manager - INFO - –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω UniversalIconManager —Å Lucide –∏–∫–æ–Ω–∫–∞–º–∏
[OK] Terminal: –ó–∞–≥—Ä—É–∂–µ–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ –∏–∫–æ–Ω–æ–∫ UniversalIconManager
INFO: ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 1597 Lucide –∏–∫–æ–Ω–æ–∫
2025-07-12 05:38:57,133 - icon_manager - INFO - ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 1597 Lucide –∏–∫–æ–Ω–æ–∫
INFO: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω UniversalIconManager —Å Lucide –∏–∫–æ–Ω–∫–∞–º–∏
2025-07-12 05:38:57,133 - icon_manager - INFO - –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω UniversalIconManager —Å Lucide –∏–∫–æ–Ω–∫–∞–º–∏
2025-07-12 05:38:57 - UIAssistant_20250712_053857 - INFO - ==================================================
2025-07-12 05:38:57,160 - UIAssistant_20250712_053857 - INFO - ==================================================
2025-07-12 05:38:57 - UIAssistant_20250712_053857 - INFO - UI Assistant Session Started: 20250712_053857
2025-07-12 05:38:57,167 - UIAssistant_20250712_053857 - INFO - UI Assistant Session Started: 20250712_053857
2025-07-12 05:38:57 - UIAssistant_20250712_053857 - INFO - ==================================================
2025-07-12 05:38:57,175 - UIAssistant_20250712_053857 - INFO - ==================================================
2025-07-12 05:38:57 - UIAssistant_20250712_053857 - INFO - Initializing UIAssistantTool
2025-07-12 05:38:57,187 - UIAssistant_20250712_053857 - INFO - Initializing UIAssistantTool
2025-07-12 05:38:57,288 - gopiai.ui_core.llm - INFO - LLM client initialized
2025-07-12 05:38:57 - UIAssistant_20250712_053857 - INFO - UIAssistantTool initialized successfully
2025-07-12 05:38:57,298 - UIAssistant_20250712_053857 - INFO - UIAssistantTool initialized successfully
2025-07-12 05:38:57,305 - gopiai.utils.performance - DEBUG - Cached result for get_ui_assistant (TTL: 300s)
2025-07-12 05:38:57,327 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5050
2025-07-12 05:38:57,408 - urllib3.connectionpool - DEBUG - http://127.0.0.1:5050 "GET /api/health HTTP/1.1" 200 98
2025-07-12 05:38:57,410 - gopiai.ui.components.chat_widget - INFO - ‚úÖ CrewAI API server is available.
 –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è txtai embeddings...
2025-07-12 05:38:58,013 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /conversations/vectors/resolve/main/config.json HTTP/1.1" 401 0
2025-07-12 05:38:58,320 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /conversations/vectors/resolve/main/config.json HTTP/1.1" 401 0
2025-07-12 05:38:58,597 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /conversations/vectors/resolve/main/1_Pooling/config.json HTTP/1.1" 401 0
2025-07-12 05:38:58,866 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /conversations/vectors/resolve/main/config.json HTTP/1.1" 401 0
 –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ txtai: conversations/vectors is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
 –ó–∞–≥—Ä—É–∂–µ–Ω–æ 126 —Å–æ–æ–±—â–µ–Ω–∏–π –∏ 1 —Å–µ—Å—Å–∏–π
2025-07-12 05:38:58,874 - gopiai.ui.components.chat_widget - WARNING - ‚ö†Ô∏è Embedded memory system initialized but txtai not available.
üîç ChatWidget —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ
üîç –ü–µ—Ä–µ–¥–∞–µ–º theme_manager –≤ ChatWidget...
üîç theme_manager –ø–µ—Ä–µ–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ
[OK] –ü–æ–≤–µ–¥–µ–Ω–∏–µ —Å–ø–ª–∏—Ç—Ç–µ—Ä–æ–≤ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏
[OK] –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —Å–ø–ª–∏—Ç—Ç–µ—Ä–æ–≤ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã
[OK] –ú–æ–¥—É–ª—å–Ω—ã–π UI –Ω–∞—Å—Ç—Ä–æ–µ–Ω —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏ —Ä–∞–∑–º–µ—Ä–æ–≤ –ø–∞–Ω–µ–ª–µ–π
[OK] –°–∏–≥–Ω–∞–ª openSettingsRequested –ø–æ–¥–∫–ª—é—á–µ–Ω
‚úÖ –°–∏–≥–Ω–∞–ª openBrowserRequested –ø–æ–¥–∫–ª—é—á–µ–Ω –∫ add_browser_tab
‚úÖ –°–∏–≥–Ω–∞–ª—ã –º–µ–Ω—é –ø–æ–¥–∫–ª—é—á–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ
[OK] –ü—Ä–∏–º–µ–Ω–µ–Ω –º–∞–∫–µ—Ç –≤ —Å—Ç–∏–ª–µ VSCode —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º–∏ —Ü–≤–µ—Ç–∞–º–∏
[OK] –ì–æ—Ä—è—á–∏–µ –∫–ª–∞–≤–∏—à–∏ –¥–ª—è –ø–∞–Ω–µ–ª–µ–π –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã (–≤–∫–ª—é—á–∞—è —Å–±—Ä–æ—Å —Ä–∞–∑–º–µ—Ä–æ–≤)
[OK] –°–∏–≥–Ω–∞–ª file_double_clicked –ø–æ–¥–∫–ª—é—á–µ–Ω
[OK] –°–∏–≥–Ω–∞–ª file_selected –ø–æ–¥–∫–ª—é—á–µ–Ω
[OK] –°–∏–≥–Ω–∞–ª—ã —Ñ–∞–π–ª–æ–≤–æ–≥–æ –ø—Ä–æ–≤–æ–¥–Ω–∏–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω—ã
[OK] –ú–æ–¥—É–ª—å–Ω—ã–π UI –Ω–∞—Å—Ç—Ä–æ–µ–Ω
[OK] AI Assistant –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —á–∞—Ç–µ
[OK] FramelessGopiAIStandaloneWindow –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!
üîÑ –ò–∫–æ–Ω–∫–∏ –º–µ–Ω—é –æ–±–Ω–æ–≤–ª–µ–Ω—ã
[SUCCESS] GopiAI v0.3.0 —É—Å–ø–µ—à–Ω–æ –∑–∞–ø—É—â–µ–Ω!
[INFO] –ú–æ–¥—É–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∞–∫—Ç–∏–≤–Ω–∞
[INFO] –†–∞–∑–º–µ—Ä –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–º–µ–Ω—å—à–µ–Ω
2025-07-12 05:38:59,296 - gopiai.ui.utils.theme_manager - INFO - –¢–µ–º–∞ —É—Å–ø–µ—à–Ω–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
2025-07-12 05:41:05,813 - gopiai.ui.memory.manager - INFO - Saved embeddings to C:/Users/crazy/.gopiai/memory/vectors
2025-07-12 05:41:05,833 - gopiai.ui.memory.manager - INFO - Saved embeddings to C:/Users/crazy/.gopiai/memory/vectors
2025-07-12 05:41:05,853 - gopiai.ui.memory.manager - WARNING - Search unavailable - vector store is empty or not initialized.
2025-07-12 05:41:05,856 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5050
2025-07-12 05:41:05,860 - urllib3.connectionpool - DEBUG - http://127.0.0.1:5050 "GET /api/health HTTP/1.1" 200 98
2025-07-12 05:41:05,861 - gopiai.ui.components.crewai_client - DEBUG - –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ CrewAI: {'message': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?', 'metadata': {'session_id': 'session_1752278936', 'chat_history': [{'role': 'system', 'content': '–¢—ã - –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–≥–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é. –ë—É–¥—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–º –∏ –æ—Ç–∑—ã–≤—á–∏–≤—ã–º.'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'assistant', 'content': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?'}, {'role': 'user', 'content': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?'}]}, 'async_processing': True, 'system_prompt': '–¢—ã - –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –ë—É–¥—å –≤–µ–∂–ª–∏–≤—ã–º –∏ –∫—Ä–∞—Ç–∫–∏–º. –ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å –æ—Ç–≤–µ—Ç–∞, —Ç–∞–∫ –∏ —Å–∫–∞–∂–∏.'}
2025-07-12 05:41:05,864 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5050
2025-07-12 05:41:05,864 - urllib3.connectionpool - DEBUG - http://127.0.0.1:5050 "POST /api/process HTTP/1.1" 200 343
2025-07-12 05:41:05,871 - gopiai.ui.components.crewai_client - INFO - üîÑ [TASK] –ü–æ–ª—É—á–µ–Ω task_id –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏: 7e22da8f-872d-4efd-a6aa-23739982f7e8
2025-07-12 05:41:06,374 - gopiai.ui.components.chat_widget - INFO - üîÑ [SIGNAL_HANDLER] –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø–æ—Ç–æ–∫–µ: {'created_at': '2025-07-12T05:41:05.864215', 'message': '–ó–∞–¥–∞—á–∞ –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∞ –≤ –æ—á–µ—Ä–µ–¥—å –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É', 'status': 'processing', 'task_id': '7e22da8f-872d-4efd-a6aa-23739982f7e8'}
2025-07-12 05:41:06,375 - gopiai.ui.components.chat_widget - INFO - üîÑ [TASK] –ó–∞–ø—É—â–µ–Ω –æ–ø—Ä–æ—Å —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á–∏ 7e22da8f-872d-4efd-a6aa-23739982f7e8
2025-07-12 05:41:07,382 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5050
2025-07-12 05:41:07,395 - urllib3.connectionpool - DEBUG - http://127.0.0.1:5050 "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 527
2025-07-12 05:41:07,396 - gopiai.ui.components.chat_widget - INFO - üîÑ [TASK] –°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ 7e22da8f-872d-4efd-a6aa-23739982f7e8: {'created_at': '2025-07-12T05:41:05.864215', 'message': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?', 'started_at': '2025-07-12T05:41:05.864215', 'status': 'processing', 'task_id': '7e22da8f-872d-4efd-a6aa-23739982f7e8'}
2025-07-12 05:41:08,390 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5050
2025-07-12 05:41:08,392 - urllib3.connectionpool - DEBUG - http://127.0.0.1:5050 "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 527
2025-07-12 05:41:08,396 - gopiai.ui.components.chat_widget - INFO - üîÑ [TASK] –°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ 7e22da8f-872d-4efd-a6aa-23739982f7e8: {'created_at': '2025-07-12T05:41:05.864215', 'message': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?', 'started_at': '2025-07-12T05:41:05.864215', 'status': 'processing', 'task_id': '7e22da8f-872d-4efd-a6aa-23739982f7e8'}
2025-07-12 05:41:09,392 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5050
2025-07-12 05:41:09,401 - urllib3.connectionpool - DEBUG - http://127.0.0.1:5050 "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 527
2025-07-12 05:41:09,403 - gopiai.ui.components.chat_widget - INFO - üîÑ [TASK] –°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ 7e22da8f-872d-4efd-a6aa-23739982f7e8: {'created_at': '2025-07-12T05:41:05.864215', 'message': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?', 'started_at': '2025-07-12T05:41:05.864215', 'status': 'processing', 'task_id': '7e22da8f-872d-4efd-a6aa-23739982f7e8'}
2025-07-12 05:41:10,384 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5050
2025-07-12 05:41:10,388 - urllib3.connectionpool - DEBUG - http://127.0.0.1:5050 "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 527
2025-07-12 05:41:10,390 - gopiai.ui.components.chat_widget - INFO - üîÑ [TASK] –°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ 7e22da8f-872d-4efd-a6aa-23739982f7e8: {'created_at': '2025-07-12T05:41:05.864215', 'message': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?', 'started_at': '2025-07-12T05:41:05.864215', 'status': 'processing', 'task_id': '7e22da8f-872d-4efd-a6aa-23739982f7e8'}
2025-07-12 05:41:11,385 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5050
2025-07-12 05:41:11,433 - urllib3.connectionpool - DEBUG - http://127.0.0.1:5050 "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 527
2025-07-12 05:41:11,435 - gopiai.ui.components.chat_widget - INFO - üîÑ [TASK] –°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ 7e22da8f-872d-4efd-a6aa-23739982f7e8: {'created_at': '2025-07-12T05:41:05.864215', 'message': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?', 'started_at': '2025-07-12T05:41:05.864215', 'status': 'processing', 'task_id': '7e22da8f-872d-4efd-a6aa-23739982f7e8'}
2025-07-12 05:41:12,396 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5050
2025-07-12 05:41:12,404 - urllib3.connectionpool - DEBUG - http://127.0.0.1:5050 "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 527
2025-07-12 05:41:12,405 - gopiai.ui.components.chat_widget - INFO - üîÑ [TASK] –°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ 7e22da8f-872d-4efd-a6aa-23739982f7e8: {'created_at': '2025-07-12T05:41:05.864215', 'message': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?', 'started_at': '2025-07-12T05:41:05.864215', 'status': 'processing', 'task_id': '7e22da8f-872d-4efd-a6aa-23739982f7e8'}
2025-07-12 05:41:13,382 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5050
2025-07-12 05:41:13,386 - urllib3.connectionpool - DEBUG - http://127.0.0.1:5050 "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 527
2025-07-12 05:41:13,386 - gopiai.ui.components.chat_widget - INFO - üîÑ [TASK] –°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ 7e22da8f-872d-4efd-a6aa-23739982f7e8: {'created_at': '2025-07-12T05:41:05.864215', 'message': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?', 'started_at': '2025-07-12T05:41:05.864215', 'status': 'processing', 'task_id': '7e22da8f-872d-4efd-a6aa-23739982f7e8'}
2025-07-12 05:41:14,388 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5050
2025-07-12 05:41:14,393 - urllib3.connectionpool - DEBUG - http://127.0.0.1:5050 "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 527
2025-07-12 05:41:14,395 - gopiai.ui.components.chat_widget - INFO - üîÑ [TASK] –°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ 7e22da8f-872d-4efd-a6aa-23739982f7e8: {'created_at': '2025-07-12T05:41:05.864215', 'message': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?', 'started_at': '2025-07-12T05:41:05.864215', 'status': 'processing', 'task_id': '7e22da8f-872d-4efd-a6aa-23739982f7e8'}
2025-07-12 05:41:15,401 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5050
2025-07-12 05:41:15,409 - urllib3.connectionpool - DEBUG - http://127.0.0.1:5050 "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 527
2025-07-12 05:41:15,411 - gopiai.ui.components.chat_widget - INFO - üîÑ [TASK] –°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ 7e22da8f-872d-4efd-a6aa-23739982f7e8: {'created_at': '2025-07-12T05:41:05.864215', 'message': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?', 'started_at': '2025-07-12T05:41:05.864215', 'status': 'processing', 'task_id': '7e22da8f-872d-4efd-a6aa-23739982f7e8'}
2025-07-12 05:41:16,417 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5050
2025-07-12 05:41:16,422 - urllib3.connectionpool - DEBUG - http://127.0.0.1:5050 "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 527
2025-07-12 05:41:16,424 - gopiai.ui.components.chat_widget - INFO - üîÑ [TASK] –°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ 7e22da8f-872d-4efd-a6aa-23739982f7e8: {'created_at': '2025-07-12T05:41:05.864215', 'message': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?', 'started_at': '2025-07-12T05:41:05.864215', 'status': 'processing', 'task_id': '7e22da8f-872d-4efd-a6aa-23739982f7e8'}
2025-07-12 05:41:17,437 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5050
2025-07-12 05:41:17,441 - urllib3.connectionpool - DEBUG - http://127.0.0.1:5050 "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 527
2025-07-12 05:41:17,443 - gopiai.ui.components.chat_widget - INFO - üîÑ [TASK] –°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ 7e22da8f-872d-4efd-a6aa-23739982f7e8: {'created_at': '2025-07-12T05:41:05.864215', 'message': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?', 'started_at': '2025-07-12T05:41:05.864215', 'status': 'processing', 'task_id': '7e22da8f-872d-4efd-a6aa-23739982f7e8'}
2025-07-12 05:41:18,456 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5050
2025-07-12 05:41:18,461 - urllib3.connectionpool - DEBUG - http://127.0.0.1:5050 "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 527
2025-07-12 05:41:18,462 - gopiai.ui.components.chat_widget - INFO - üîÑ [TASK] –°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ 7e22da8f-872d-4efd-a6aa-23739982f7e8: {'created_at': '2025-07-12T05:41:05.864215', 'message': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?', 'started_at': '2025-07-12T05:41:05.864215', 'status': 'processing', 'task_id': '7e22da8f-872d-4efd-a6aa-23739982f7e8'}
2025-07-12 05:41:19,471 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5050
2025-07-12 05:41:19,474 - urllib3.connectionpool - DEBUG - http://127.0.0.1:5050 "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 527
2025-07-12 05:41:19,474 - gopiai.ui.components.chat_widget - INFO - üîÑ [TASK] –°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ 7e22da8f-872d-4efd-a6aa-23739982f7e8: {'created_at': '2025-07-12T05:41:05.864215', 'message': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?', 'started_at': '2025-07-12T05:41:05.864215', 'status': 'processing', 'task_id': '7e22da8f-872d-4efd-a6aa-23739982f7e8'}
2025-07-12 05:41:20,474 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5050
2025-07-12 05:41:20,474 - urllib3.connectionpool - DEBUG - http://127.0.0.1:5050 "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 527
2025-07-12 05:41:20,474 - gopiai.ui.components.chat_widget - INFO - üîÑ [TASK] –°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ 7e22da8f-872d-4efd-a6aa-23739982f7e8: {'created_at': '2025-07-12T05:41:05.864215', 'message': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?', 'started_at': '2025-07-12T05:41:05.864215', 'status': 'processing', 'task_id': '7e22da8f-872d-4efd-a6aa-23739982f7e8'}
2025-07-12 05:41:21,475 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5050
2025-07-12 05:41:21,475 - urllib3.connectionpool - DEBUG - http://127.0.0.1:5050 "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 527
2025-07-12 05:41:21,480 - gopiai.ui.components.chat_widget - INFO - üîÑ [TASK] –°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ 7e22da8f-872d-4efd-a6aa-23739982f7e8: {'created_at': '2025-07-12T05:41:05.864215', 'message': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?', 'started_at': '2025-07-12T05:41:05.864215', 'status': 'processing', 'task_id': '7e22da8f-872d-4efd-a6aa-23739982f7e8'}
2025-07-12 05:41:22,476 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5050
2025-07-12 05:41:22,480 - urllib3.connectionpool - DEBUG - http://127.0.0.1:5050 "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 527
2025-07-12 05:41:22,480 - gopiai.ui.components.chat_widget - INFO - üîÑ [TASK] –°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ 7e22da8f-872d-4efd-a6aa-23739982f7e8: {'created_at': '2025-07-12T05:41:05.864215', 'message': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?', 'started_at': '2025-07-12T05:41:05.864215', 'status': 'processing', 'task_id': '7e22da8f-872d-4efd-a6aa-23739982f7e8'}
2025-07-12 05:41:23,495 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5050
2025-07-12 05:41:23,496 - urllib3.connectionpool - DEBUG - http://127.0.0.1:5050 "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 1027
2025-07-12 05:41:23,496 - gopiai.ui.components.chat_widget - INFO - üîÑ [TASK] –°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ 7e22da8f-872d-4efd-a6aa-23739982f7e8: {'completed_at': '2025-07-12T05:41:22.963723', 'created_at': '2025-07-12T05:41:05.864215', 'error': None, 'message': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?', 'result': {'analysis': {'analysis_time': 0.0, 'complexity': 0, 'requires_crewai': False, 'type': 'general'}, 'processed_with_crewai': False, 'response': '–Ø –∑–∞–ø–æ–º–Ω–∏–ª, —á—Ç–æ —Ç—ã –ø—Ä–æ—Å–∏–ª–∞ –º–µ–Ω—è –±—ã—Ç—å –ø–æ–ª–µ–∑–Ω—ã–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º.\n'}, 'started_at': '2025-07-12T05:41:05.864215', 'status': 'completed', 'task_id': '7e22da8f-872d-4efd-a6aa-23739982f7e8'}
2025-07-12 05:41:23,513 - gopiai.ui.memory.manager - INFO - Saved embeddings to C:/Users/crazy/.gopiai/memory/vectors
2025-07-12 05:41:23,535 - gopiai.ui.memory.manager - INFO - Saved embeddings to C:/Users/crazy/.gopiai/memory/vectors

(gopiai_env) C:\Users\crazy\GOPI_AI_MODULES\GopiAI-UI>



‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
   ü§ñ CrewAI API Server Environment
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üîÑ Activating CrewAI environment...
‚úÖ Environment activated
üìÇ Directory: GopiAI-CrewAI
üêç Environment: C:\Users\crazy\GOPI_AI_MODULES\GopiAI-CrewAI\crewai_env

üöÄ Starting CrewAI API Server...
DEBUG: Content of llm_rotation_config.py at C:\Users\crazy\GOPI_AI_MODULES\GopiAI-CrewAI\llm_rotation_config.py:
import os
import time
import threading
# –ö–æ–Ω—Ñ–∏–≥ –º–æ–¥–µ–ª–µ–π Gemini/Gemma –¥–ª—è —Ä–æ—Ç–∞—Ü–∏–∏ –∏ –∑–∞–¥–∞—á
LLM_MODELS_CONFIG = [
    {
        "name": "Gemini 1.5 Flash",
        "id": "gemini/gemini-1.5-flash",
        "provider": "google",
        "rpm": 15,
        "tpm": 250000,
        "type": ["simple", "dialog", "code", "summarize"],
        "multimodal": False,
        "embedding": False,
        "priority": 3,
        "rpd": 50,
        "deprecated": False,
        "base_score": 0.5
    },
    {
  ...
‚Üê[92m05:38:40 - LiteLLM:DEBUG‚Üê[0m: http_handler.py:533 - Using AiohttpTransport...
2025-07-12 05:38:40,609 - LiteLLM - DEBUG - Using AiohttpTransport...
‚Üê[92m05:38:40 - LiteLLM:DEBUG‚Üê[0m: http_handler.py:557 - Creating AiohttpTransport...
2025-07-12 05:38:40,612 - LiteLLM - DEBUG - Creating AiohttpTransport...
2025-07-12 05:38:41,471 - httpcore.connection - DEBUG - connect_tcp.started host='raw.githubusercontent.com' port=443 local_address=None timeout=5 socket_options=None
2025-07-12 05:38:41,507 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E79938E330>
2025-07-12 05:38:41,510 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E79931CB50> server_hostname='raw.githubusercontent.com' timeout=5
2025-07-12 05:38:41,551 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E79938E240>
2025-07-12 05:38:41,558 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'GET']>
2025-07-12 05:38:41,560 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-07-12 05:38:41,566 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'GET']>
2025-07-12 05:38:41,569 - httpcore.http11 - DEBUG - send_request_body.complete
2025-07-12 05:38:41,570 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'GET']>
2025-07-12 05:38:41,598 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Connection', b'keep-alive'), (b'Content-Length', b'26669'), (b'Cache-Control', b'max-age=300'), (b'Content-Security-Policy', b"default-src 'none'; style-src 'unsafe-inline'; sandbox"), (b'Content-Type', b'text/plain; charset=utf-8'), (b'ETag', b'W/"e0ddf9b9734f7b6410fd3f9fc8939dcf7a4add8d889a448efe4d9d1ccbed517f"'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'X-Content-Type-Options', b'nosniff'), (b'X-Frame-Options', b'deny'), (b'X-XSS-Protection', b'1; mode=block'), (b'X-GitHub-Request-Id', b'6EF7:31DCEC:327EA:D61FE:6870A0A1'), (b'Content-Encoding', b'gzip'), (b'Accept-Ranges', b'bytes'), (b'Date', b'Sat, 12 Jul 2025 00:08:37 GMT'), (b'Via', b'1.1 varnish'), (b'X-Served-By', b'cache-del21748-DEL'), (b'X-Cache', b'HIT'), (b'X-Cache-Hits', b'1'), (b'X-Timer', b'S1752278917.226131,VS0,VE1'), (b'Vary', b'Authorization,Accept-Encoding'), (b'Access-Control-Allow-Origin', b'*'), (b'Cross-Origin-Resource-Policy', b'cross-origin'), (b'X-Fastly-Request-ID', b'b638f35329932cf6d3dc5ce28ea9bd3ce65aab0f'), (b'Expires', b'Sat, 12 Jul 2025 00:13:37 GMT'), (b'Source-Age', b'59')])
2025-07-12 05:38:41,602 - httpx - INFO - HTTP Request: GET https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json "HTTP/1.1 200 OK"
2025-07-12 05:38:41,604 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'GET']>
2025-07-12 05:38:41,610 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-07-12 05:38:41,611 - httpcore.http11 - DEBUG - response_closed.started
2025-07-12 05:38:41,611 - httpcore.http11 - DEBUG - response_closed.complete
2025-07-12 05:38:41,612 - httpcore.connection - DEBUG - close.started
2025-07-12 05:38:41,613 - httpcore.connection - DEBUG - close.complete
‚Üê[92m05:38:42 - LiteLLM:DEBUG‚Üê[0m: http_handler.py:533 - Using AiohttpTransport...
2025-07-12 05:38:42,122 - LiteLLM - DEBUG - Using AiohttpTransport...
‚Üê[92m05:38:42 - LiteLLM:DEBUG‚Üê[0m: http_handler.py:557 - Creating AiohttpTransport...
2025-07-12 05:38:42,124 - LiteLLM - DEBUG - Creating AiohttpTransport...
‚Üê[92m05:38:42 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:169 - [Non-Blocking] Unable to import GenericAPILogger - LiteLLM Enterprise Feature - No module named 'litellm_enterprise'
2025-07-12 05:38:42,583 - LiteLLM - DEBUG - [Non-Blocking] Unable to import GenericAPILogger - LiteLLM Enterprise Feature - No module named 'litellm_enterprise'
‚Üê[92m05:38:43 - LiteLLM:DEBUG‚Üê[0m: transformation.py:17 - [Non-Blocking] Unable to import _ENTERPRISE_ResponsesSessionHandler - LiteLLM Enterprise Feature - No module named 'litellm_enterprise'
2025-07-12 05:38:43,064 - LiteLLM - DEBUG - [Non-Blocking] Unable to import _ENTERPRISE_ResponsesSessionHandler - LiteLLM Enterprise Feature - No module named 'litellm_enterprise'
‚Üê[92m05:38:43 - LiteLLM:DEBUG‚Üê[0m: http_handler.py:533 - Using AiohttpTransport...
2025-07-12 05:38:43,074 - LiteLLM - DEBUG - Using AiohttpTransport...
‚Üê[92m05:38:43 - LiteLLM:DEBUG‚Üê[0m: http_handler.py:557 - Creating AiohttpTransport...
2025-07-12 05:38:43,080 - LiteLLM - DEBUG - Creating AiohttpTransport...
‚Üê[92m05:38:43 - LiteLLM:DEBUG‚Üê[0m: http_handler.py:533 - Using AiohttpTransport...
2025-07-12 05:38:43,089 - LiteLLM - DEBUG - Using AiohttpTransport...
‚Üê[92m05:38:43 - LiteLLM:DEBUG‚Üê[0m: http_handler.py:557 - Creating AiohttpTransport...
2025-07-12 05:38:43,089 - LiteLLM - DEBUG - Creating AiohttpTransport...
DEBUG: LLM_MODELS_CONFIG loaded: [{'name': 'Gemini 1.5 Flash', 'id': 'gemini/gemini-1.5-flash', 'provider': 'google', 'rpm': 15, 'tpm': 250000, 'type': ['simple', 'dialog', 'code', 'summarize'], 'multimodal': False, 'embedding': False, 'priority': 3, 'rpd': 50, 'deprecated': False, 'base_score': 0.5}, {'name': 'Gemini 2.0 Flash-Lite', 'id': 'gemini/gemini-2.0-flash-lite', 'provider': 'google', 'rpm': 30, 'tpm': 1000000, 'type': ['simple', 'dialog', 'code', 'summarize'], 'multimodal': False, 'embedding': False, 'priority': 4, 'rpd': 200, 'deprecated': False, 'base_score': 0.5}, {'name': 'Gemma 3', 'id': 'gemini/gemma-3', 'provider': 'google', 'rpm': 30, 'tpm': 14400, 'type': ['simple', 'lookup', 'short_answer'], 'multimodal': False, 'embedding': False, 'priority': 1, 'rpd': 0, 'deprecated': False, 'base_score': 0.5}, {'name': 'Gemma 3n', 'id': 'gemini/gemma-3n', 'provider': 'google', 'rpm': 30, 'tpm': 14400, 'type': ['simple', 'lookup', 'short_answer'], 'multimodal': False, 'embedding': False, 'priority': 2, 'rpd': 0, 'deprecated': False, 'base_score': 0.5}, {'name': 'Gemini 2.5 Flash-Lite Preview', 'id': 'gemini/gemini-2.5-flash-lite-preview', 'provider': 'google', 'rpm': 15, 'tpm': 60000, 'type': ['dialog', 'code', 'summarize'], 'multimodal': False, 'embedding': False, 'priority': 5, 'rpd': 0, 'deprecated': False, 'base_score': 0.5}, {'name': 'Gemini 2.5 Flash', 'id': 'gemini/gemini-2.5-flash', 'provider': 'google', 'rpm': 10, 'tpm': 60000, 'type': ['dialog', 'code', 'multimodal', 'vision', 'long_answer'], 'multimodal': True, 'embedding': False, 'priority': 6, 'rpd': 0, 'deprecated': False, 'base_score': 0.5}, {'name': 'Gemini Embedding Experimental', 'id': 'gemini/gemini-embedding-experimental', 'provider': 'google', 'rpm': 5, 'tpm': 10000, 'type': ['embedding'], 'multimodal': False, 'embedding': True, 'priority': 10, 'rpd': 0, 'deprecated': False, 'base_score': 0.5}]
[OK] RateLimitMonitor –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å blacklist –º–µ—Ö–∞–Ω–∏–∑–º–æ–º
[OK] –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ LLM –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ
GopiAI Integration Tools loaded successfully!
[OK] CrewAI —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω!
2025-07-12 05:38:44,641 - tools.gopiai_integration.ai_router_llm - INFO - ‚úÖ AIRouterLLM –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π —Ä–æ—Ç–∞—Ü–∏–∏
2025-07-12 05:38:44,641 - tools.gopiai_integration.self_reflection - INFO - ReflectionEnabledAIRouter –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (reflection=enabled)
2025-07-12 05:38:44,643 - tools.gopiai_integration.self_reflection - INFO - –ü–æ—Ä–æ–≥ –∫–∞—á–µ—Å—Ç–≤–∞: 8.0/10
[OK] AI Router —Å —Å–∞–º–æ—Ä–µ—Ñ–ª–µ–∫—Å–∏–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω (–ø–æ—Ä–æ–≥ –∫–∞—á–µ—Å—Ç–≤–∞: 8.0)
[OK] –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è RAG-—Å–∏—Å—Ç–µ–º–∞ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–∞.
‚úÖ –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
[OK] –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞.
Smart Delegator —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω
Starting CrewAI API server at http://127.0.0.1:5050
This server should be run from the CrewAI environment (crewai_env)
Using Python: C:\Users\crazy\GOPI_AI_MODULES\GopiAI-CrewAI\crewai_env\Scripts\python.exe
CrewAI module is available
Langchain module is available
Request timeout: 300 seconds
Connection timeout: 60 seconds
 * Serving Flask app 'crewai_api_server'
 * Debug mode: off
2025-07-12 05:38:44,676 - werkzeug - INFO - ‚Üê[31m‚Üê[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.‚Üê[0m
 * Running on http://127.0.0.1:5050
2025-07-12 05:38:44,677 - werkzeug - INFO - ‚Üê[33mPress CTRL+C to quit‚Üê[0m
2025-07-12 05:38:57,400 - werkzeug - INFO - 127.0.0.1 - - [12/Jul/2025 05:38:57] "GET /api/health HTTP/1.1" 200 -
2025-07-12 05:41:05,859 - werkzeug - INFO - 127.0.0.1 - - [12/Jul/2025 05:41:05] "GET /api/health HTTP/1.1" 200 -
2025-07-12 05:41:05,864 - werkzeug - INFO - 127.0.0.1 - - [12/Jul/2025 05:41:05] "POST /api/process HTTP/1.1" 200 -
üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: —Å–ª–æ–∂–Ω–æ—Å—Ç—å=0, —Ç–∏–ø=general, CrewAI=False
üìä [–ó–∞–¥–∞—á–∞ 7e22da8f-872d-4efd-a6aa-23739982f7e8] –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: —Å–ª–æ–∂–Ω–æ—Å—Ç—å=0, —Ç–∏–ø=general
üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: —Å–ª–æ–∂–Ω–æ—Å—Ç—å=0, —Ç–∏–ø=general, CrewAI=False
üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: —Å–ª–æ–∂–Ω–æ—Å—Ç—å=0, —Ç–∏–ø=general, CrewAI=False
2025-07-12 05:41:05,874 - tools.gopiai_integration.smart_delegator - INFO - üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ AI Router...
2025-07-12 05:41:05,874 - tools.gopiai_integration.smart_delegator - INFO - ‚úÖ AI Router –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã
2025-07-12 05:41:05,902 - faiss.loader - DEBUG - Environment variable FAISS_OPT_LEVEL is not set, so let's pick the instruction set according to the current CPU
2025-07-12 05:41:05,905 - faiss.loader - INFO - Loading faiss with AVX2 support.
2025-07-12 05:41:05,942 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2025-07-12 05:41:05,946 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-07-12 05:41:07,385 - werkzeug - INFO - 127.0.0.1 - - [12/Jul/2025 05:41:07] "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 -
2025-07-12 05:41:08,392 - werkzeug - INFO - 127.0.0.1 - - [12/Jul/2025 05:41:08] "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 -
2025-07-12 05:41:09,395 - werkzeug - INFO - 127.0.0.1 - - [12/Jul/2025 05:41:09] "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 -
2025-07-12 05:41:10,387 - werkzeug - INFO - 127.0.0.1 - - [12/Jul/2025 05:41:10] "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 -
2025-07-12 05:41:11,431 - werkzeug - INFO - 127.0.0.1 - - [12/Jul/2025 05:41:11] "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 -
2025-07-12 05:41:12,400 - werkzeug - INFO - 127.0.0.1 - - [12/Jul/2025 05:41:12] "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 -
2025-07-12 05:41:13,386 - werkzeug - INFO - 127.0.0.1 - - [12/Jul/2025 05:41:13] "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 -
2025-07-12 05:41:14,330 - opentelemetry.trace - WARNING - Overriding of current TracerProvider is not allowed
2025-07-12 05:41:14,392 - werkzeug - INFO - 127.0.0.1 - - [12/Jul/2025 05:41:14] "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 -
2025-07-12 05:41:15,405 - werkzeug - INFO - 127.0.0.1 - - [12/Jul/2025 05:41:15] "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 -
 –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è txtai embeddings...
2025-07-12 05:41:15,626 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2025-07-12 05:41:16,009 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /conversations/vectors/resolve/main/config.json HTTP/1.1" 401 0
2025-07-12 05:41:16,420 - werkzeug - INFO - 127.0.0.1 - - [12/Jul/2025 05:41:16] "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 -
2025-07-12 05:41:16,669 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /conversations/vectors/resolve/main/config.json HTTP/1.1" 401 0
2025-07-12 05:41:16,929 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /conversations/vectors/resolve/main/1_Pooling/config.json HTTP/1.1" 401 0
2025-07-12 05:41:17,195 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /conversations/vectors/resolve/main/config.json HTTP/1.1" 401 0
 –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ txtai: conversations/vectors is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
 –§–∞–π–ª —á–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω, –Ω–∞—á–∏–Ω–∞–µ–º —Å —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞
 –ü–æ–∏—Å–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –ø—É—Å—Ç–∞ –∏–ª–∏ –Ω–µ –≥–æ—Ç–æ–≤–∞.
2025-07-12 05:41:17,214 - tools.gopiai_integration.smart_delegator - INFO - –ó–∞–≥—Ä—É–∂–µ–Ω–æ 2 —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞
2025-07-12 05:41:17,215 - tools.gopiai_integration.smart_delegator - INFO - üöÄ –í—ã–∑–æ–≤ LLM —Å –∏—Å—Ç–æ—Ä–∏–µ–π —á–∞—Ç–∞...
2025-07-12 05:41:17,216 - tools.gopiai_integration.smart_delegator - DEBUG - –û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ LLM: [
  {
    "role": "system",
    "content": "–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –±–µ—Å–µ–¥—ã –∏ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.\n–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.\n\n–ò–ù–°–¢–†–£–ö–¶–ò–ò:\n1. –£—á–∏—Ç—ã–≤–∞–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, –Ω–æ –Ω–µ —É–ø–æ–º–∏–Ω–∞–π –µ–≥–æ –Ω–∞–ø—Ä—è–º—É—é –≤ –æ—Ç–≤–µ—Ç–µ\n2. –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω, –ø–æ–ª–∞–≥–∞–π—Å—è –Ω–∞ —Å–≤–æ–∏ –∑–Ω–∞–Ω–∏—è\n3. –ë—É–¥—å –∫—Ä–∞—Ç–æ–∫ –∏ —Ç–æ—á–µ–Ω –≤ –æ—Ç–≤–µ—Ç–∞—Ö"
  },
  {
    "role": "assistant",
    "content": "–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?"
  },
  {
    "role": "user",
    "content": "–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?"
  }
]
[AVAILABLE] –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è 'dialog': ['gemini/gemini-1.5-flash', 'gemini/gemini-2.0-flash-lite', 'gemini/gemini-2.5-flash-lite-preview', 'gemini/gemini-2.5-flash']
[CHECK] –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏ gemini/gemini-1.5-flash —Å 215 —Ç–æ–∫–µ–Ω–∞–º–∏...
[STATS] –ú–æ–¥–µ–ª—å gemini/gemini-1.5-flash: —Ç–µ–∫—É—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ RPM=0/15, TPM=0/250000, RPD=0/50
[OK] –ú–æ–¥–µ–ª—å gemini/gemini-1.5-flash: RPM_OK=True, TPM_OK=True, RPD_OK=True -> RESULT=True
[SELECTED] AI Router: –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å 'gemini/gemini-1.5-flash' (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 3)
2025-07-12 05:41:17,233 - tools.gopiai_integration.smart_delegator - INFO - –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: gemini/gemini-1.5-flash
[AVAILABLE] –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è 'dialog': ['gemini/gemini-1.5-flash', 'gemini/gemini-2.0-flash-lite', 'gemini/gemini-2.5-flash-lite-preview', 'gemini/gemini-2.5-flash']
[CHECK] –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏ gemini/gemini-1.5-flash —Å 215 —Ç–æ–∫–µ–Ω–∞–º–∏...
[STATS] –ú–æ–¥–µ–ª—å gemini/gemini-1.5-flash: —Ç–µ–∫—É—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ RPM=0/15, TPM=0/250000, RPD=0/50
[OK] –ú–æ–¥–µ–ª—å gemini/gemini-1.5-flash: RPM_OK=True, TPM_OK=True, RPD_OK=True -> RESULT=True
[SELECTED] AI Router: –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å 'gemini/gemini-1.5-flash' (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 3)
üîÑ –ü–æ–ø—ã—Ç–∫–∞ 1: –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å gemini/gemini-1.5-flash
05:41:17 - LiteLLM:DEBUG: utils.py:340 -

2025-07-12 05:41:17,244 - LiteLLM - DEBUG -

05:41:17 - LiteLLM:DEBUG: utils.py:340 - Request to litellm:
2025-07-12 05:41:17,247 - LiteLLM - DEBUG - Request to litellm:
05:41:17 - LiteLLM:DEBUG: utils.py:340 - litellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –±–µ—Å–µ–¥—ã –∏ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.\n–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.\n\n–ò–ù–°–¢–†–£–ö–¶–ò–ò:\n1. –£—á–∏—Ç—ã–≤–∞–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, –Ω–æ –Ω–µ —É–ø–æ–º–∏–Ω–∞–π –µ–≥–æ –Ω–∞–ø—Ä—è–º—É—é –≤ –æ—Ç–≤–µ—Ç–µ\n2. –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω, –ø–æ–ª–∞–≥–∞–π—Å—è –Ω–∞ —Å–≤–æ–∏ –∑–Ω–∞–Ω–∏—è\n3. –ë—É–¥—å –∫—Ä–∞—Ç–æ–∫ –∏ —Ç–æ—á–µ–Ω –≤ –æ—Ç–≤–µ—Ç–∞—Ö'}, {'role': 'assistant', 'content': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?'}, {'role': 'user', 'content': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?'}], temperature=0.7, max_tokens=2000)
2025-07-12 05:41:17,271 - LiteLLM - DEBUG - litellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –±–µ—Å–µ–¥—ã –∏ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.\n–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.\n\n–ò–ù–°–¢–†–£–ö–¶–ò–ò:\n1. –£—á–∏—Ç—ã–≤–∞–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, –Ω–æ –Ω–µ —É–ø–æ–º–∏–Ω–∞–π –µ–≥–æ –Ω–∞–ø—Ä—è–º—É—é –≤ –æ—Ç–≤–µ—Ç–µ\n2. –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω, –ø–æ–ª–∞–≥–∞–π—Å—è –Ω–∞ —Å–≤–æ–∏ –∑–Ω–∞–Ω–∏—è\n3. –ë—É–¥—å –∫—Ä–∞—Ç–æ–∫ –∏ —Ç–æ—á–µ–Ω –≤ –æ—Ç–≤–µ—Ç–∞—Ö'}, {'role': 'assistant', 'content': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?'}, {'role': 'user', 'content': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?'}], temperature=0.7, max_tokens=2000)
05:41:17 - LiteLLM:DEBUG: utils.py:340 -

2025-07-12 05:41:17,312 - LiteLLM - DEBUG -

05:41:17 - LiteLLM:DEBUG: litellm_logging.py:461 - self.optional_params: {}
2025-07-12 05:41:17,352 - LiteLLM - DEBUG - self.optional_params: {}
05:41:17 - LiteLLM:DEBUG: utils.py:340 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-07-12 05:41:17,367 - LiteLLM - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
05:41:17 - LiteLLM:DEBUG: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
2025-07-12 05:41:17,379 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
05:41:17 - LiteLLM:INFO: utils.py:3119 -
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-07-12 05:41:17,383 - LiteLLM - INFO -
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
05:41:17 - LiteLLM:DEBUG: utils.py:3122 -
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.7, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 2000, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –±–µ—Å–µ–¥—ã –∏ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.\n–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.\n\n–ò–ù–°–¢–†–£–ö–¶–ò–ò:\n1. –£—á–∏—Ç—ã–≤–∞–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, –Ω–æ –Ω–µ —É–ø–æ–º–∏–Ω–∞–π –µ–≥–æ –Ω–∞–ø—Ä—è–º—É—é –≤ –æ—Ç–≤–µ—Ç–µ\n2. –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω, –ø–æ–ª–∞–≥–∞–π—Å—è –Ω–∞ —Å–≤–æ–∏ –∑–Ω–∞–Ω–∏—è\n3. –ë—É–¥—å –∫—Ä–∞—Ç–æ–∫ –∏ —Ç–æ—á–µ–Ω –≤ –æ—Ç–≤–µ—Ç–∞—Ö'}, {'role': 'assistant', 'content': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?'}, {'role': 'user', 'content': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?'}], 'thinking': None, 'web_search_options': None}
2025-07-12 05:41:17,385 - LiteLLM - DEBUG -
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.7, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 2000, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –±–µ—Å–µ–¥—ã –∏ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.\n–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.\n\n–ò–ù–°–¢–†–£–ö–¶–ò–ò:\n1. –£—á–∏—Ç—ã–≤–∞–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, –Ω–æ –Ω–µ —É–ø–æ–º–∏–Ω–∞–π –µ–≥–æ –Ω–∞–ø—Ä—è–º—É—é –≤ –æ—Ç–≤–µ—Ç–µ\n2. –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω, –ø–æ–ª–∞–≥–∞–π—Å—è –Ω–∞ —Å–≤–æ–∏ –∑–Ω–∞–Ω–∏—è\n3. –ë—É–¥—å –∫—Ä–∞—Ç–æ–∫ –∏ —Ç–æ—á–µ–Ω –≤ –æ—Ç–≤–µ—Ç–∞—Ö'}, {'role': 'assistant', 'content': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?'}, {'role': 'user', 'content': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?'}], 'thinking': None, 'web_search_options': None}
05:41:17 - LiteLLM:DEBUG: utils.py:3125 -
LiteLLM: Non-Default params passed to completion() {'temperature': 0.7, 'max_tokens': 2000}
2025-07-12 05:41:17,396 - LiteLLM - DEBUG -
LiteLLM: Non-Default params passed to completion() {'temperature': 0.7, 'max_tokens': 2000}
05:41:17 - LiteLLM:DEBUG: utils.py:340 - Final returned optional params: {'temperature': 0.7, 'max_output_tokens': 2000}
2025-07-12 05:41:17,398 - LiteLLM - DEBUG - Final returned optional params: {'temperature': 0.7, 'max_output_tokens': 2000}
05:41:17 - LiteLLM:DEBUG: litellm_logging.py:461 - self.optional_params: {'temperature': 0.7, 'max_tokens': 2000}
2025-07-12 05:41:17,400 - LiteLLM - DEBUG - self.optional_params: {'temperature': 0.7, 'max_tokens': 2000}
05:41:17 - LiteLLM:DEBUG: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-12 05:41:17,401 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-12 05:41:17,440 - werkzeug - INFO - 127.0.0.1 - - [12/Jul/2025 05:41:17] "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 -
05:41:17 - LiteLLM:DEBUG: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-12 05:41:17,772 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
05:41:17 - LiteLLM:DEBUG: litellm_logging.py:908 -

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****gu0Q \
-H 'Content-Type: ap****on' \
-d '{'contents': [{'role': 'model', 'parts': [{'text': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?'}]}, {'role': 'user', 'parts': [{'text': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?'}]}], 'system_instruction': {'parts': [{'text': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –±–µ—Å–µ–¥—ã –∏ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.\n–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.\n\n–ò–ù–°–¢–†–£–ö–¶–ò–ò:\n1. –£—á–∏—Ç—ã–≤–∞–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, –Ω–æ –Ω–µ —É–ø–æ–º–∏–Ω–∞–π –µ–≥–æ –Ω–∞–ø—Ä—è–º—É—é –≤ –æ—Ç–≤–µ—Ç–µ\n2. –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω, –ø–æ–ª–∞–≥–∞–π—Å—è –Ω–∞ —Å–≤–æ–∏ –∑–Ω–∞–Ω–∏—è\n3. –ë—É–¥—å –∫—Ä–∞—Ç–æ–∫ –∏ —Ç–æ—á–µ–Ω –≤ –æ—Ç–≤–µ—Ç–∞—Ö'}]}, 'generationConfig': {'temperature': 0.7, 'max_output_tokens': 2000}}'


2025-07-12 05:41:17,777 - LiteLLM - DEBUG -

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****gu0Q \
-H 'Content-Type: ap****on' \
-d '{'contents': [{'role': 'model', 'parts': [{'text': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?'}]}, {'role': 'user', 'parts': [{'text': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?'}]}], 'system_instruction': {'parts': [{'text': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –±–µ—Å–µ–¥—ã –∏ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.\n–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.\n\n–ò–ù–°–¢–†–£–ö–¶–ò–ò:\n1. –£—á–∏—Ç—ã–≤–∞–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, –Ω–æ –Ω–µ —É–ø–æ–º–∏–Ω–∞–π –µ–≥–æ –Ω–∞–ø—Ä—è–º—É—é –≤ –æ—Ç–≤–µ—Ç–µ\n2. –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω, –ø–æ–ª–∞–≥–∞–π—Å—è –Ω–∞ —Å–≤–æ–∏ –∑–Ω–∞–Ω–∏—è\n3. –ë—É–¥—å –∫—Ä–∞—Ç–æ–∫ –∏ —Ç–æ—á–µ–Ω –≤ –æ—Ç–≤–µ—Ç–∞—Ö'}]}, 'generationConfig': {'temperature': 0.7, 'max_output_tokens': 2000}}'


2025-07-12 05:41:18,145 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None
2025-07-12 05:41:18,174 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E7C8A1A300>
2025-07-12 05:41:18,176 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E7C8A37BD0> server_hostname='generativelanguage.googleapis.com' timeout=600.0
2025-07-12 05:41:18,217 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E7C873E4E0>
2025-07-12 05:41:18,217 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-12 05:41:18,220 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-07-12 05:41:18,220 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-12 05:41:18,220 - httpcore.http11 - DEBUG - send_request_body.complete
2025-07-12 05:41:18,220 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-12 05:41:18,458 - werkzeug - INFO - 127.0.0.1 - - [12/Jul/2025 05:41:18] "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 -
2025-07-12 05:41:19,474 - werkzeug - INFO - 127.0.0.1 - - [12/Jul/2025 05:41:19] "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 -
2025-07-12 05:41:19,870 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sat, 12 Jul 2025 00:11:15 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1610'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-12 05:41:19,874 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyD2taiOJ6Z7nLcVQrz_U0ct4G0HlyLgu0Q "HTTP/1.1 429 Too Many Requests"
2025-07-12 05:41:19,874 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-12 05:41:19,876 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-07-12 05:41:19,876 - httpcore.http11 - DEBUG - response_closed.started
2025-07-12 05:41:19,876 - httpcore.http11 - DEBUG - response_closed.complete




05:41:19 - LiteLLM:DEBUG: exception_mapping_utils.py:2300 - Logging Details: logger_fn - None | callable(logger_fn) - False
2025-07-12 05:41:19,876 - LiteLLM - DEBUG - Logging Details: logger_fn - None | callable(logger_fn) - False
05:41:19 - LiteLLM:DEBUG: litellm_logging.py:2216 - Logging Details LiteLLM-Failure Call: []
2025-07-12 05:41:19,892 - LiteLLM - DEBUG - Logging Details LiteLLM-Failure Call: []
2025-07-12 05:41:19,898 - tools.gopiai_integration.smart_delegator - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ –º–æ–¥–µ–ª–∏ gemini/gemini-1.5-flash: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerDayPerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "50"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "44s"
      }
    ]
  }
}


üö´ –ú–æ–¥–µ–ª—å gemini/gemini-1.5-flash –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞ –Ω–∞ 3600 —Å–µ–∫—É–Ω–¥ –¥–æ 06:41:19
[AVAILABLE] –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è 'dialog': ['gemini/gemini-2.0-flash-lite', 'gemini/gemini-2.5-flash-lite-preview', 'gemini/gemini-2.5-flash']
[CHECK] –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏ gemini/gemini-2.0-flash-lite —Å 215 —Ç–æ–∫–µ–Ω–∞–º–∏...
[STATS] –ú–æ–¥–µ–ª—å gemini/gemini-2.0-flash-lite: —Ç–µ–∫—É—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ RPM=0/30, TPM=0/1000000, RPD=0/200
[OK] –ú–æ–¥–µ–ª—å gemini/gemini-2.0-flash-lite: RPM_OK=True, TPM_OK=True, RPD_OK=True -> RESULT=True
[SELECTED] AI Router: –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å 'gemini/gemini-2.0-flash-lite' (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 4)
üîÑ –ü–æ–ø—ã—Ç–∫–∞ 2: –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å gemini/gemini-2.0-flash-lite
05:41:19 - LiteLLM:DEBUG: utils.py:340 -

2025-07-12 05:41:19,913 - LiteLLM - DEBUG -

05:41:19 - LiteLLM:DEBUG: utils.py:340 - Request to litellm:
2025-07-12 05:41:19,913 - LiteLLM - DEBUG - Request to litellm:
05:41:19 - LiteLLM:DEBUG: utils.py:340 - litellm.completion(model='gemini/gemini-2.0-flash-lite', messages=[{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –±–µ—Å–µ–¥—ã –∏ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.\n–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.\n\n–ò–ù–°–¢–†–£–ö–¶–ò–ò:\n1. –£—á–∏—Ç—ã–≤–∞–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, –Ω–æ –Ω–µ —É–ø–æ–º–∏–Ω–∞–π –µ–≥–æ –Ω–∞–ø—Ä—è–º—É—é –≤ –æ—Ç–≤–µ—Ç–µ\n2. –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω, –ø–æ–ª–∞–≥–∞–π—Å—è –Ω–∞ —Å–≤–æ–∏ –∑–Ω–∞–Ω–∏—è\n3. –ë—É–¥—å –∫—Ä–∞—Ç–æ–∫ –∏ —Ç–æ—á–µ–Ω –≤ –æ—Ç–≤–µ—Ç–∞—Ö'}, {'role': 'assistant', 'content': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?'}, {'role': 'user', 'content': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?'}], temperature=0.7, max_tokens=2000)
2025-07-12 05:41:19,921 - LiteLLM - DEBUG - litellm.completion(model='gemini/gemini-2.0-flash-lite', messages=[{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –±–µ—Å–µ–¥—ã –∏ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.\n–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.\n\n–ò–ù–°–¢–†–£–ö–¶–ò–ò:\n1. –£—á–∏—Ç—ã–≤–∞–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, –Ω–æ –Ω–µ —É–ø–æ–º–∏–Ω–∞–π –µ–≥–æ –Ω–∞–ø—Ä—è–º—É—é –≤ –æ—Ç–≤–µ—Ç–µ\n2. –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω, –ø–æ–ª–∞–≥–∞–π—Å—è –Ω–∞ —Å–≤–æ–∏ –∑–Ω–∞–Ω–∏—è\n3. –ë—É–¥—å –∫—Ä–∞—Ç–æ–∫ –∏ —Ç–æ—á–µ–Ω –≤ –æ—Ç–≤–µ—Ç–∞—Ö'}, {'role': 'assistant', 'content': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?'}, {'role': 'user', 'content': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?'}], temperature=0.7, max_tokens=2000)
05:41:19 - LiteLLM:DEBUG: utils.py:340 -

2025-07-12 05:41:19,924 - LiteLLM - DEBUG -

05:41:19 - LiteLLM:DEBUG: litellm_logging.py:461 - self.optional_params: {}
2025-07-12 05:41:19,924 - LiteLLM - DEBUG - self.optional_params: {}
05:41:19 - LiteLLM:DEBUG: utils.py:340 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-07-12 05:41:19,928 - LiteLLM - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
05:41:19 - LiteLLM:DEBUG: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'custom_llm_provider': 'vertex_ai'}
2025-07-12 05:41:19,930 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'custom_llm_provider': 'vertex_ai'}
05:41:19 - LiteLLM:INFO: utils.py:3119 -
LiteLLM completion() model= gemini-2.0-flash-lite; provider = gemini
2025-07-12 05:41:19,930 - LiteLLM - INFO -
LiteLLM completion() model= gemini-2.0-flash-lite; provider = gemini
05:41:19 - LiteLLM:DEBUG: utils.py:3122 -
LiteLLM: Params passed to completion() {'model': 'gemini-2.0-flash-lite', 'functions': None, 'function_call': None, 'temperature': 0.7, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 2000, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –±–µ—Å–µ–¥—ã –∏ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.\n–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.\n\n–ò–ù–°–¢–†–£–ö–¶–ò–ò:\n1. –£—á–∏—Ç—ã–≤–∞–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, –Ω–æ –Ω–µ —É–ø–æ–º–∏–Ω–∞–π –µ–≥–æ –Ω–∞–ø—Ä—è–º—É—é –≤ –æ—Ç–≤–µ—Ç–µ\n2. –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω, –ø–æ–ª–∞–≥–∞–π—Å—è –Ω–∞ —Å–≤–æ–∏ –∑–Ω–∞–Ω–∏—è\n3. –ë—É–¥—å –∫—Ä–∞—Ç–æ–∫ –∏ —Ç–æ—á–µ–Ω –≤ –æ—Ç–≤–µ—Ç–∞—Ö'}, {'role': 'assistant', 'content': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?'}, {'role': 'user', 'content': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?'}], 'thinking': None, 'web_search_options': None}
2025-07-12 05:41:19,930 - LiteLLM - DEBUG -
LiteLLM: Params passed to completion() {'model': 'gemini-2.0-flash-lite', 'functions': None, 'function_call': None, 'temperature': 0.7, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 2000, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –±–µ—Å–µ–¥—ã –∏ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.\n–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.\n\n–ò–ù–°–¢–†–£–ö–¶–ò–ò:\n1. –£—á–∏—Ç—ã–≤–∞–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, –Ω–æ –Ω–µ —É–ø–æ–º–∏–Ω–∞–π –µ–≥–æ –Ω–∞–ø—Ä—è–º—É—é –≤ –æ—Ç–≤–µ—Ç–µ\n2. –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω, –ø–æ–ª–∞–≥–∞–π—Å—è –Ω–∞ —Å–≤–æ–∏ –∑–Ω–∞–Ω–∏—è\n3. –ë—É–¥—å –∫—Ä–∞—Ç–æ–∫ –∏ —Ç–æ—á–µ–Ω –≤ –æ—Ç–≤–µ—Ç–∞—Ö'}, {'role': 'assistant', 'content': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?'}, {'role': 'user', 'content': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?'}], 'thinking': None, 'web_search_options': None}
05:41:19 - LiteLLM:DEBUG: utils.py:3125 -
LiteLLM: Non-Default params passed to completion() {'temperature': 0.7, 'max_tokens': 2000}
2025-07-12 05:41:19,945 - LiteLLM - DEBUG -
LiteLLM: Non-Default params passed to completion() {'temperature': 0.7, 'max_tokens': 2000}
05:41:19 - LiteLLM:DEBUG: utils.py:340 - Final returned optional params: {'temperature': 0.7, 'max_output_tokens': 2000}
2025-07-12 05:41:19,945 - LiteLLM - DEBUG - Final returned optional params: {'temperature': 0.7, 'max_output_tokens': 2000}
05:41:19 - LiteLLM:DEBUG: litellm_logging.py:461 - self.optional_params: {'temperature': 0.7, 'max_tokens': 2000}
2025-07-12 05:41:19,945 - LiteLLM - DEBUG - self.optional_params: {'temperature': 0.7, 'max_tokens': 2000}
05:41:19 - LiteLLM:DEBUG: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
2025-07-12 05:41:19,945 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
05:41:20 - LiteLLM:DEBUG: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
2025-07-12 05:41:20,306 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
05:41:20 - LiteLLM:DEBUG: litellm_logging.py:908 -

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent?key=*****gu0Q \
-H 'Content-Type: ap****on' \
-d '{'contents': [{'role': 'model', 'parts': [{'text': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?'}]}, {'role': 'user', 'parts': [{'text': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?'}]}], 'system_instruction': {'parts': [{'text': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –±–µ—Å–µ–¥—ã –∏ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.\n–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.\n\n–ò–ù–°–¢–†–£–ö–¶–ò–ò:\n1. –£—á–∏—Ç—ã–≤–∞–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, –Ω–æ –Ω–µ —É–ø–æ–º–∏–Ω–∞–π –µ–≥–æ –Ω–∞–ø—Ä—è–º—É—é –≤ –æ—Ç–≤–µ—Ç–µ\n2. –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω, –ø–æ–ª–∞–≥–∞–π—Å—è –Ω–∞ —Å–≤–æ–∏ –∑–Ω–∞–Ω–∏—è\n3. –ë—É–¥—å –∫—Ä–∞—Ç–æ–∫ –∏ —Ç–æ—á–µ–Ω –≤ –æ—Ç–≤–µ—Ç–∞—Ö'}]}, 'generationConfig': {'temperature': 0.7, 'max_output_tokens': 2000}}'


2025-07-12 05:41:20,310 - LiteLLM - DEBUG -

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent?key=*****gu0Q \
-H 'Content-Type: ap****on' \
-d '{'contents': [{'role': 'model', 'parts': [{'text': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?'}]}, {'role': 'user', 'parts': [{'text': '–ø—Ä–∏–≤–µ—Ç! —è –ø—Ä–æ—Å–∏–ª–∞ —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å –≤ –ø—Ä–æ—à–ª–æ–π —Å–µ—Å—Å–∏–∏. –ß—Ç–æ —ç—Ç–æ –±—ã–ª–æ?'}]}], 'system_instruction': {'parts': [{'text': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –±–µ—Å–µ–¥—ã –∏ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.\n–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.\n\n–ò–ù–°–¢–†–£–ö–¶–ò–ò:\n1. –£—á–∏—Ç—ã–≤–∞–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, –Ω–æ –Ω–µ —É–ø–æ–º–∏–Ω–∞–π –µ–≥–æ –Ω–∞–ø—Ä—è–º—É—é –≤ –æ—Ç–≤–µ—Ç–µ\n2. –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω, –ø–æ–ª–∞–≥–∞–π—Å—è –Ω–∞ —Å–≤–æ–∏ –∑–Ω–∞–Ω–∏—è\n3. –ë—É–¥—å –∫—Ä–∞—Ç–æ–∫ –∏ —Ç–æ—á–µ–Ω –≤ –æ—Ç–≤–µ—Ç–∞—Ö'}]}, 'generationConfig': {'temperature': 0.7, 'max_output_tokens': 2000}}'


2025-07-12 05:41:20,474 - werkzeug - INFO - 127.0.0.1 - - [12/Jul/2025 05:41:20] "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 -
2025-07-12 05:41:20,673 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None
2025-07-12 05:41:20,705 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E7C8A86CC0>
2025-07-12 05:41:20,705 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E7C8BF6DD0> server_hostname='generativelanguage.googleapis.com' timeout=600.0
2025-07-12 05:41:20,746 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E7C8A86960>
2025-07-12 05:41:20,746 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-12 05:41:20,746 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-07-12 05:41:20,752 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-12 05:41:20,752 - httpcore.http11 - DEBUG - send_request_body.complete
2025-07-12 05:41:20,753 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-12 05:41:21,475 - werkzeug - INFO - 127.0.0.1 - - [12/Jul/2025 05:41:21] "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 -
2025-07-12 05:41:22,480 - werkzeug - INFO - 127.0.0.1 - - [12/Jul/2025 05:41:22] "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 -
2025-07-12 05:41:22,871 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sat, 12 Jul 2025 00:11:18 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=2090'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-12 05:41:22,874 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent?key=AIzaSyD2taiOJ6Z7nLcVQrz_U0ct4G0HlyLgu0Q "HTTP/1.1 200 OK"
2025-07-12 05:41:22,874 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-12 05:41:22,874 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-07-12 05:41:22,877 - httpcore.http11 - DEBUG - response_closed.started
2025-07-12 05:41:22,877 - httpcore.http11 - DEBUG - response_closed.complete
05:41:22 - LiteLLM:DEBUG: utils.py:340 - RAW RESPONSE:
{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "–Ø –∑–∞–ø–æ–º–Ω–∏–ª, —á—Ç–æ —Ç—ã –ø—Ä–æ—Å–∏–ª–∞ –º–µ–Ω—è –±—ã—Ç—å –ø–æ–ª–µ–∑–Ω—ã–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º.\n"
          }
        ],
        "role": "model"
      },
      "finishReason": "STOP",
      "avgLogprobs": -0.52399921417236328
    }
  ],
  "usageMetadata": {
    "promptTokenCount": 141,
    "candidatesTokenCount": 18,
    "totalTokenCount": 159,
    "promptTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 141
      }
    ],
    "candidatesTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 18
      }
    ]
  },
  "modelVersion": "gemini-2.0-flash-lite",
  "responseId": "JahxaNisNpecmecPgfSQmQc"
}



2025-07-12 05:41:22,877 - LiteLLM - DEBUG - RAW RESPONSE:
{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "–Ø –∑–∞–ø–æ–º–Ω–∏–ª, —á—Ç–æ —Ç—ã –ø—Ä–æ—Å–∏–ª–∞ –º–µ–Ω—è –±—ã—Ç—å –ø–æ–ª–µ–∑–Ω—ã–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º.\n"
          }
        ],
        "role": "model"
      },
      "finishReason": "STOP",
      "avgLogprobs": -0.52399921417236328
    }
  ],
  "usageMetadata": {
    "promptTokenCount": 141,
    "candidatesTokenCount": 18,
    "totalTokenCount": 159,
    "promptTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 141
      }
    ],
    "candidatesTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 18
      }
    ]
  },
  "modelVersion": "gemini-2.0-flash-lite",
  "responseId": "JahxaNisNpecmecPgfSQmQc"
}



2025-07-12 05:41:22,903 - httpcore.connection - DEBUG - close.started
2025-07-12 05:41:22,905 - httpcore.connection - DEBUG - close.complete
05:41:22 - LiteLLM:INFO: utils.py:1215 - Wrapper: Completed Call, calling success_handler
2025-07-12 05:41:22,905 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
05:41:22 - LiteLLM:DEBUG: litellm_logging.py:1394 - Logging Details LiteLLM-Success Call: Cache_hit=None
2025-07-12 05:41:22,905 - LiteLLM - DEBUG - Logging Details LiteLLM-Success Call: Cache_hit=None
05:41:22 - LiteLLM:INFO: cost_calculator.py:655 - selected model name for cost calculation: gemini/gemini-2.0-flash-lite
2025-07-12 05:41:22,907 - LiteLLM - INFO - selected model name for cost calculation: gemini/gemini-2.0-flash-lite
05:41:22 - LiteLLM:INFO: cost_calculator.py:655 - selected model name for cost calculation: gemini/gemini-2.0-flash-lite
2025-07-12 05:41:22,907 - LiteLLM - INFO - selected model name for cost calculation: gemini/gemini-2.0-flash-lite
05:41:22 - LiteLLM:DEBUG: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
2025-07-12 05:41:22,907 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
05:41:22 - LiteLLM:DEBUG: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
2025-07-12 05:41:22,911 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
05:41:22 - LiteLLM:DEBUG: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
2025-07-12 05:41:22,913 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
05:41:22 - LiteLLM:DEBUG: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
2025-07-12 05:41:22,916 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
05:41:22 - LiteLLM:DEBUG: utils.py:4783 - model_info: {'key': 'gemini/gemini-2.0-flash-lite', 'max_tokens': None, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': 7.5e-08, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': True, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': True, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 4000}
2025-07-12 05:41:22,916 - LiteLLM - DEBUG - model_info: {'key': 'gemini/gemini-2.0-flash-lite', 'max_tokens': None, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': 7.5e-08, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': True, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': True, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 4000}
05:41:22 - LiteLLM:DEBUG: utils.py:4783 - model_info: {'key': 'gemini/gemini-2.0-flash-lite', 'max_tokens': None, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': 7.5e-08, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': True, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': True, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 4000}
2025-07-12 05:41:22,922 - LiteLLM - DEBUG - model_info: {'key': 'gemini/gemini-2.0-flash-lite', 'max_tokens': None, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': 7.5e-08, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': True, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': True, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 4000}
05:41:22 - LiteLLM:DEBUG: litellm_logging.py:1131 - response_cost: 1.5975e-05
2025-07-12 05:41:22,930 - LiteLLM - DEBUG - response_cost: 1.5975e-05
05:41:22 - LiteLLM:DEBUG: litellm_logging.py:1131 - response_cost: 1.5975e-05
‚úÖ –£—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏ gemini/gemini-2.0-flash-lite2025-07-12 05:41:22,942 - LiteLLM - DEBUG - response_cost: 1.5975e-05

05:41:22 - LiteLLM:DEBUG: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'custom_llm_provider': 'vertex_ai'}
2025-07-12 05:41:22,946 - tools.gopiai_integration.smart_delegator - INFO - ‚úÖ –û—Ç–≤–µ—Ç –æ—Ç LLM –ø–æ–ª—É—á–µ–Ω
2025-07-12 05:41:22,945 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'custom_llm_provider': 'vertex_ai'}
05:41:22 - LiteLLM:DEBUG: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
2025-07-12 05:41:22,948 - tools.gopiai_integration.smart_delegator - INFO - ‚è± –ó–∞–ø—Ä–æ—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∑–∞ 17.07 —Å–µ–∫
‚è± –ó–∞–ø—Ä–æ—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∑–∞ 17.08 —Å–µ–∫2025-07-12 05:41:22,948 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}

05:41:22 - LiteLLM:DEBUG: utils.py:4783 - model_info: {'key': 'gemini/gemini-2.0-flash-lite', 'max_tokens': None, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': 7.5e-08, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': True, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': True, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 4000}
‚úÖ [–ó–∞–¥–∞—á–∞ 7e22da8f-872d-4efd-a6aa-23739982f7e8] –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω, –¥–ª–∏–Ω–∞: 59 —Å–∏–º–≤–æ–ª–æ–≤2025-07-12 05:41:22,954 - LiteLLM - DEBUG - model_info: {'key': 'gemini/gemini-2.0-flash-lite', 'max_tokens': None, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': 7.5e-08, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': True, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': True, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 4000}

05:41:22 - LiteLLM:DEBUG: litellm_logging.py:1423 - Logging Details LiteLLM-Success Call streaming complete
2025-07-12 05:41:22,963 - LiteLLM - DEBUG - Logging Details LiteLLM-Success Call streaming complete
05:41:22 - LiteLLM:INFO: cost_calculator.py:655 - selected model name for cost calculation: gemini/gemini-2.0-flash-lite
2025-07-12 05:41:22,963 - LiteLLM - INFO - selected model name for cost calculation: gemini/gemini-2.0-flash-lite
05:41:22 - LiteLLM:DEBUG: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
2025-07-12 05:41:22,963 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
05:41:22 - LiteLLM:DEBUG: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
2025-07-12 05:41:22,971 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
05:41:22 - LiteLLM:DEBUG: utils.py:4783 - model_info: {'key': 'gemini/gemini-2.0-flash-lite', 'max_tokens': None, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': 7.5e-08, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': True, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': True, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 4000}
2025-07-12 05:41:22,974 - LiteLLM - DEBUG - model_info: {'key': 'gemini/gemini-2.0-flash-lite', 'max_tokens': None, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': 7.5e-08, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': True, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': True, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 4000}
05:41:22 - LiteLLM:DEBUG: litellm_logging.py:1131 - response_cost: 1.5975e-05
2025-07-12 05:41:22,981 - LiteLLM - DEBUG - response_cost: 1.5975e-05
05:41:22 - LiteLLM:DEBUG: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'custom_llm_provider': 'vertex_ai'}
2025-07-12 05:41:22,981 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'custom_llm_provider': 'vertex_ai'}
05:41:22 - LiteLLM:DEBUG: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
2025-07-12 05:41:22,981 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
05:41:22 - LiteLLM:DEBUG: utils.py:4783 - model_info: {'key': 'gemini/gemini-2.0-flash-lite', 'max_tokens': None, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': 7.5e-08, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': True, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': True, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 4000}
2025-07-12 05:41:22,981 - LiteLLM - DEBUG - model_info: {'key': 'gemini/gemini-2.0-flash-lite', 'max_tokens': None, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': 7.5e-08, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': True, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': True, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 4000}
2025-07-12 05:41:23,496 - werkzeug - INFO - 127.0.0.1 - - [12/Jul/2025 05:41:23] "GET /api/task/7e22da8f-872d-4efd-a6aa-23739982f7e8 HTTP/1.1" 200 -
