
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
   üñ•Ô∏è GopiAI-UI Application
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üîÑ Activating UI environment...
‚úÖ Environment activated
üìÇ Directory: GopiAI-UI
üêç Environment: C:\Users\crazy\GOPI_AI_MODULES\gopiai_env

üöÄ Starting GopiAI-UI Application...
2025-07-10 05:52:52,212 - GopiAI - INFO - [GOPIAI] GopiAI Unified Logger initialized
2025-07-10 05:52:52,876 - gopiai.ui.components.crewai_client - WARNING - ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å spaCy –∏–ª–∏ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏: No module named 'spacy'
2025-07-10 05:52:52,882 - gopiai.ui.memory.manager - INFO - ‚úÖ Simple emotion classifier initialized
2025-07-10 05:52:52,885 - gopiai.ui.memory.manager - INFO - Loaded 134 messages from C:\Users\crazy\.gopiai\memory\chats.json
2025-07-10 05:52:52,887 - gopiai.ui.memory.manager - INFO - Loaded 26 sessions from C:\Users\crazy\.gopiai\memory\sessions.json
2025-07-10 05:52:53,086 - faiss.loader - DEBUG - Environment variable FAISS_OPT_LEVEL is not set, so let's pick the instruction set according to the current CPU
2025-07-10 05:52:53,247 - faiss.loader - INFO - Loading faiss with AVX2 support.
2025-07-10 05:52:53,294 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2025-07-10 05:52:53,302 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-07-10 05:53:08,913 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2025-07-10 05:53:09,751 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-mpnet-base-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-07-10 05:53:09,794 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-mpnet-base-v2/84fccfe766bcfd679e39efefe4ebf45af190ad2d/config.json HTTP/1.1" 200 0
2025-07-10 05:53:10,472 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-mpnet-base-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-07-10 05:53:10,510 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-mpnet-base-v2/84fccfe766bcfd679e39efefe4ebf45af190ad2d/config.json HTTP/1.1" 200 0
2025-07-10 05:53:10,762 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-mpnet-base-v2/resolve/main/1_Pooling/config.json HTTP/1.1" 307 0
2025-07-10 05:53:10,800 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-mpnet-base-v2/84fccfe766bcfd679e39efefe4ebf45af190ad2d/1_Pooling%2Fconfig.json HTTP/1.1" 200 0
2025-07-10 05:53:11,064 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-mpnet-base-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-07-10 05:53:11,100 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-mpnet-base-v2/84fccfe766bcfd679e39efefe4ebf45af190ad2d/config.json HTTP/1.1" 200 0
2025-07-10 05:53:13,377 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-mpnet-base-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-07-10 05:53:13,411 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-mpnet-base-v2/84fccfe766bcfd679e39efefe4ebf45af190ad2d/tokenizer_config.json HTTP/1.1" 200 0
2025-07-10 05:53:13,711 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/paraphrase-multilingual-mpnet-base-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-07-10 05:53:14,882 - gopiai.ui.memory.manager - INFO - ‚úÖ txtai embeddings initialized
2025-07-10 05:53:48,016 - gopiai.ui.components.chat_widget - INFO - ‚úÖ Memory manager initialized
üîß Enhanced DEBUG logging enabled for chat_widget.py (console + file)
2025-07-10 05:53:48,019 - gopiai.ui.components.chat_widget - INFO - === Chat Widget Debug Session Started ===
–ú–æ–¥—É–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è GopiAI v0.3.2 —Å —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π —Ç–µ–º
–î–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ –ø—É—Ç–∏ –¥–ª—è –º–æ–¥—É–ª–µ–π:
- C:\Users\crazy\GOPI_AI_MODULES\GopiAI-Core (—Å—É—â–µ—Å—Ç–≤—É–µ—Ç: True)
- C:\Users\crazy\GOPI_AI_MODULES\GopiAI-Widgets (—Å—É—â–µ—Å—Ç–≤—É–µ—Ç: True)
- C:\Users\crazy\GOPI_AI_MODULES\GopiAI-App (—Å—É—â–µ—Å—Ç–≤—É–µ—Ç: True)
- C:\Users\crazy\GOPI_AI_MODULES\GopiAI-Extensions (—Å—É—â–µ—Å—Ç–≤—É–µ—Ç: True)
- C:\Users\crazy\GOPI_AI_MODULES\rag_memory_system (—Å—É—â–µ—Å—Ç–≤—É–µ—Ç: True)
- C:\Users\crazy\GOPI_AI_MODULES (—Å—É—â–µ—Å—Ç–≤—É–µ—Ç: True)
[OK] –í—Å–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –º–æ–¥—É–ª–∏ UI –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ
[MEMORY] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω MemoryManager
[MEMORY] –î–∞–Ω–Ω—ã–µ —Ö—Ä–∞–Ω—è—Ç—Å—è –≤: C:\Users\crazy\.gopiai\memory
[WARNING] –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –ø–∞–º—è—Ç–∏: name 'datetime' is not defined
[LAUNCH] –ó–∞–ø—É—Å–∫ –º–æ–¥—É–ª—å–Ω–æ–≥–æ GopiAI...
üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥—É–ª—å–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ GopiAI —Å —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π —Ç–µ–º...
[WARNING] –°–∏—Å—Ç–µ–º–∞ –∏–∫–æ–Ω–æ–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞
2025-07-10 05:53:48,096 - gopiai.ui.utils.theme_manager - INFO - –ó–∞–≥—Ä—É–∂–µ–Ω–∞ —Ç–µ–º–∞: Indigo Candy (dark)
‚úÖ –ú–µ–Ω–µ–¥–∂–µ—Ä —Ç–µ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω
2025-07-10 05:53:48,103 - gopiai.ui.utils.theme_manager - INFO - –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ç–µ–º—ã –∫ QApplication/QCoreApplication
‚úÖ –ü—Ä–∏–º–µ–Ω–µ–Ω–∞ —Ç–µ–º–∞ –∏–∑ —Ñ–∞–π–ª–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫
[SETUP] –ù–∞—Å—Ç—Ä–æ–π–∫–∞ UI –∏–∑ –º–æ–¥—É–ª–µ–π...
INFO: ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 1597 Lucide –∏–∫–æ–Ω–æ–∫
2025-07-10 05:53:48,585 - icon_manager - INFO - ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 1597 Lucide –∏–∫–æ–Ω–æ–∫
INFO: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω UniversalIconManager —Å Lucide –∏–∫–æ–Ω–∫–∞–º–∏
2025-07-10 05:53:48,587 - icon_manager - INFO - –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω UniversalIconManager —Å Lucide –∏–∫–æ–Ω–∫–∞–º–∏
‚úÖ Titlebar: –ó–∞–≥—Ä—É–∂–µ–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ –∏–∫–æ–Ω–æ–∫ UniversalIconManager
INFO: ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 1597 Lucide –∏–∫–æ–Ω–æ–∫
2025-07-10 05:53:48,955 - icon_manager - INFO - ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 1597 Lucide –∏–∫–æ–Ω–æ–∫
INFO: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω UniversalIconManager —Å Lucide –∏–∫–æ–Ω–∫–∞–º–∏
2025-07-10 05:53:48,960 - icon_manager - INFO - –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω UniversalIconManager —Å Lucide –∏–∫–æ–Ω–∫–∞–º–∏
‚úÖ Titlebar: –ó–∞–≥—Ä—É–∂–µ–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ –∏–∫–æ–Ω–æ–∫ UniversalIconManager
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ minimize –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:48,969 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ minimize –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ square –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:48,977 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ square –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ maximize –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:48,981 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ maximize –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ x –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:48,985 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ x –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
INFO: ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 1597 Lucide –∏–∫–æ–Ω–æ–∫
2025-07-10 05:53:49,398 - icon_manager - INFO - ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 1597 Lucide –∏–∫–æ–Ω–æ–∫
INFO: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω UniversalIconManager —Å Lucide –∏–∫–æ–Ω–∫–∞–º–∏
2025-07-10 05:53:49,398 - icon_manager - INFO - –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω UniversalIconManager —Å Lucide –∏–∫–æ–Ω–∫–∞–º–∏
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ file-code –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:49,404 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ file-code –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ book-open –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:49,407 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ book-open –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ folder-open –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:49,417 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ folder-open –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ save –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:49,423 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ save –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ save-all –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:49,423 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ save-all –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ x –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:49,436 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ x –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ undo –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:49,438 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ undo –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ redo –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:49,448 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ redo –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ scissors –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:49,448 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ scissors –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ copy –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:49,456 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ copy –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ clipboard –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:49,464 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ clipboard –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ trash-2 –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:49,469 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ trash-2 –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ text-select –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:49,473 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ text-select –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ message-circle –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:49,473 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ message-circle –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ globe –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:49,473 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ globe –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ terminal –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:49,491 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ terminal –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ settings –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:49,497 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ settings –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ briefcase –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:49,504 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ briefcase –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ mic –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:49,506 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ mic –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ cpu –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:49,514 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ cpu –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ folder –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:49,523 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ folder –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ pencil –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:49,524 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ pencil –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ eye –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:49,524 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ eye –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ puzzle –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:49,535 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ puzzle –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
INFO: ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 1597 Lucide –∏–∫–æ–Ω–æ–∫
2025-07-10 05:53:49,919 - icon_manager - INFO - ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 1597 Lucide –∏–∫–æ–Ω–æ–∫
INFO: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω UniversalIconManager —Å Lucide –∏–∫–æ–Ω–∫–∞–º–∏
2025-07-10 05:53:49,923 - icon_manager - INFO - –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω UniversalIconManager —Å Lucide –∏–∫–æ–Ω–∫–∞–º–∏
‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ –∏–∫–æ–Ω–æ–∫ UniversalIconManager
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ folder –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:49,930 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ folder –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ home –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:49,939 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ home –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ arrow-up –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:49,945 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ arrow-up –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ arrow-right –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:49,958 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ arrow-right –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
üé® CustomFileSystemModel –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —Å icon_manager: <class 'gopiai.ui.components.icon_file_system_model.UniversalIconManager'>
INFO: ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 1597 Lucide –∏–∫–æ–Ω–æ–∫
2025-07-10 05:53:50,380 - icon_manager - INFO - ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 1597 Lucide –∏–∫–æ–Ω–æ–∫
INFO: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω UniversalIconManager —Å Lucide –∏–∫–æ–Ω–∫–∞–º–∏
2025-07-10 05:53:50,385 - icon_manager - INFO - –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω UniversalIconManager —Å Lucide –∏–∫–æ–Ω–∫–∞–º–∏
[OK] Terminal: –ó–∞–≥—Ä—É–∂–µ–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ –∏–∫–æ–Ω–æ–∫ UniversalIconManager
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ terminal –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:50,392 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ terminal –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ plus –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:50,396 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ plus –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
INFO: ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 1597 Lucide –∏–∫–æ–Ω–æ–∫
2025-07-10 05:53:50,791 - icon_manager - INFO - ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 1597 Lucide –∏–∫–æ–Ω–æ–∫
INFO: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω UniversalIconManager —Å Lucide –∏–∫–æ–Ω–∫–∞–º–∏
2025-07-10 05:53:50,795 - icon_manager - INFO - –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω UniversalIconManager —Å Lucide –∏–∫–æ–Ω–∫–∞–º–∏
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ paperclip –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:50,797 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ paperclip –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ image –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:50,804 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ image –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ trash-2 –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:50,811 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ trash-2 –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ info –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:50,819 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ info –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ send –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:50,827 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ send –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:50,837 - gopiai.ui_core.llm - INFO - LLM client initialized
2025-07-10 05:53:50,842 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5050
2025-07-10 05:53:50,852 - urllib3.connectionpool - DEBUG - http://127.0.0.1:5050 "GET /api/health HTTP/1.1" 200 98
2025-07-10 05:53:50,854 - gopiai.ui.components.chat_widget - INFO - ‚úÖ CrewAI API server is available.
FAISS –¥–æ—Å—Ç—É–ø–µ–Ω
üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è txtai embeddings...
2025-07-10 05:53:51,877 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/nli-mpnet-base-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-07-10 05:53:51,911 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/nli-mpnet-base-v2/20bdd570b61882341b3cedf7fe1246b109f26517/config.json HTTP/1.1" 200 0
2025-07-10 05:53:52,173 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/nli-mpnet-base-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-07-10 05:53:52,212 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/nli-mpnet-base-v2/20bdd570b61882341b3cedf7fe1246b109f26517/config.json HTTP/1.1" 200 0
2025-07-10 05:53:52,482 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/nli-mpnet-base-v2/resolve/main/1_Pooling/config.json HTTP/1.1" 307 0
2025-07-10 05:53:52,528 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/nli-mpnet-base-v2/20bdd570b61882341b3cedf7fe1246b109f26517/1_Pooling%2Fconfig.json HTTP/1.1" 200 0
2025-07-10 05:53:52,788 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/nli-mpnet-base-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-07-10 05:53:52,832 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/nli-mpnet-base-v2/20bdd570b61882341b3cedf7fe1246b109f26517/config.json HTTP/1.1" 200 0
2025-07-10 05:53:53,256 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/nli-mpnet-base-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-07-10 05:53:53,292 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/nli-mpnet-base-v2/20bdd570b61882341b3cedf7fe1246b109f26517/tokenizer_config.json HTTP/1.1" 200 0
2025-07-10 05:53:53,573 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/nli-mpnet-base-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
‚úÖ txtai –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω
‚úÖ FAISS –∏–Ω–¥–µ–∫—Å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω
üìÇ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 126 —Å–æ–æ–±—â–µ–Ω–∏–π
üìÅ –§–∞–π–ª—ã –≤–µ–∫—Ç–æ—Ä–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã - –æ—Å—Ç–∞–≤–ª—è–µ–º –∏–Ω–¥–µ–∫—Å –ø—É—Å—Ç—ã–º –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –ø–æ–∑–∂–µ
‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è —É–∂–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Ä–∞–Ω–µ–µ (–Ω–∞–π–¥–µ–Ω —Ñ–ª–∞–≥)
2025-07-10 05:53:53,640 - gopiai.ui.components.chat_widget - INFO - ‚úÖ Embedded memory system available. Stats: {'total_messages': 126, 'total_sessions': 1, 'txtai_available': True, 'vector_messages': 0, 'faiss_available': True, 'data_dir': 'conversations'}
üîç ChatWidget —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ
üîç –ü–µ—Ä–µ–¥–∞–µ–º theme_manager –≤ ChatWidget...
üîç theme_manager –ø–µ—Ä–µ–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ
[OK] –ü–æ–≤–µ–¥–µ–Ω–∏–µ —Å–ø–ª–∏—Ç—Ç–µ—Ä–æ–≤ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏
[OK] –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —Å–ø–ª–∏—Ç—Ç–µ—Ä–æ–≤ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã
[OK] –ú–æ–¥—É–ª—å–Ω—ã–π UI –Ω–∞—Å—Ç—Ä–æ–µ–Ω —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏ —Ä–∞–∑–º–µ—Ä–æ–≤ –ø–∞–Ω–µ–ª–µ–π
[OK] –°–∏–≥–Ω–∞–ª openSettingsRequested –ø–æ–¥–∫–ª—é—á–µ–Ω
‚úÖ –°–∏–≥–Ω–∞–ª openBrowserRequested –ø–æ–¥–∫–ª—é—á–µ–Ω –∫ add_browser_tab
‚úÖ –°–∏–≥–Ω–∞–ª—ã –º–µ–Ω—é –ø–æ–¥–∫–ª—é—á–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ
[OK] –ü—Ä–∏–º–µ–Ω–µ–Ω –º–∞–∫–µ—Ç –≤ —Å—Ç–∏–ª–µ VSCode —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º–∏ —Ü–≤–µ—Ç–∞–º–∏
[OK] –ì–æ—Ä—è—á–∏–µ –∫–ª–∞–≤–∏—à–∏ –¥–ª—è –ø–∞–Ω–µ–ª–µ–π –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã (–≤–∫–ª—é—á–∞—è —Å–±—Ä–æ—Å —Ä–∞–∑–º–µ—Ä–æ–≤)
[OK] –°–∏–≥–Ω–∞–ª file_double_clicked –ø–æ–¥–∫–ª—é—á–µ–Ω
[OK] –°–∏–≥–Ω–∞–ª file_selected –ø–æ–¥–∫–ª—é—á–µ–Ω
[OK] –°–∏–≥–Ω–∞–ª—ã —Ñ–∞–π–ª–æ–≤–æ–≥–æ –ø—Ä–æ–≤–æ–¥–Ω–∏–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω—ã
[OK] –ú–æ–¥—É–ª—å–Ω—ã–π UI –Ω–∞—Å—Ç—Ä–æ–µ–Ω
[OK] AI Assistant –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —á–∞—Ç–µ
[OK] FramelessGopiAIStandaloneWindow –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!
üîÑ –ò–∫–æ–Ω–∫–∏ –º–µ–Ω—é –æ–±–Ω–æ–≤–ª–µ–Ω—ã
[SUCCESS] GopiAI v0.3.0 —É—Å–ø–µ—à–Ω–æ –∑–∞–ø—É—â–µ–Ω!
[INFO] –ú–æ–¥—É–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∞–∫—Ç–∏–≤–Ω–∞
[INFO] –†–∞–∑–º–µ—Ä –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–º–µ–Ω—å—à–µ–Ω
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ code –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:53,909 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ code –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ file-text –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:53,925 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ file-text –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ play –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:53,925 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ play –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ settings –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:53,940 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ settings –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ image –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:53,947 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ image –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ eye-off –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:53,958 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ eye-off –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ git-branch –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:53,973 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ git-branch –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:54,082 - gopiai.ui.utils.theme_manager - INFO - –¢–µ–º–∞ —É—Å–ø–µ—à–Ω–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ archive –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:53:54,100 - icon_manager - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∫–æ–Ω–∫–∏ archive –∏–∑ SVG: cannot import name 'QSvgWidget' from 'PySide6.QtSvg' (c:\Users\crazy\GOPI_AI_MODULES\gopiai_env\Lib\site-packages\PySide6\QtSvg.pyd)
2025-07-10 05:54:14,636 - gopiai.ui.components.chat_widget - INFO - [MEMORY] –ù–∞–π–¥–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø–∞–º—è—Ç–∏: 1. [ASSISTANT]  ‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å... (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 18.00)
2. [ASSISTANT] ‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å... (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 16.00)
3. [ASSISTANT] ‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å... (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 8.00)...
2025-07-10 05:54:14,646 - gopiai.ui.components.crewai_client - DEBUG - –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ CrewAI: {'message': '–ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?', 'metadata': {'session_id': 'session_1752107030', 'chat_history': [{'role': 'system', 'content': '–¢—ã - –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–≥–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é. –ë—É–¥—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–º –∏ –æ—Ç–∑—ã–≤—á–∏–≤—ã–º.'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'assistant', 'content': '–ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}, {'role': 'user', 'content': '–ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}], 'rag_context': '1. [ASSISTANT] ‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å... (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 18.00)\n2. [ASSISTANT] ‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å... (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 16.00)\n3. [ASSISTANT] ‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å... (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 8.00)'}, 'system_prompt': '–¢—ã - –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –ë—É–¥—å –≤–µ–∂–ª–∏–≤—ã–º –∏ –∫—Ä–∞—Ç–∫–∏–º. –ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å –æ—Ç–≤–µ—Ç–∞, —Ç–∞–∫ –∏ —Å–∫–∞–∂–∏.'}
2025-07-10 05:54:14,673 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5050
2025-07-10 05:54:20,855 - urllib3.connectionpool - DEBUG - http://127.0.0.1:5050 "POST /api/process HTTP/1.1" 200 618
2025-07-10 05:54:21,358 - gopiai.ui.components.chat_widget - INFO - üîÑ [SIGNAL_HANDLER] –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø–æ—Ç–æ–∫–µ: {'analysis': {'analysis_time': 0.0, 'complexity': 0, 'requires_crewai': False, 'type': 'creative'}, 'processed_with_crewai': False, 'response': '–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.  üòä\n'}
2025-07-10 05:55:02,981 - gopiai.ui.components.chat_widget - INFO - [MEMORY] –ù–∞–π–¥–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø–∞–º—è—Ç–∏: 1. [ASSISTANT] –ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ —Å–≤–æ–µ–π —Å–æ–±–∞–∫–µ? (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 5.00)
2. [ASSISTANT] –ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ —Å–≤–æ–µ–π —Å–æ–±–∞–∫–µ? (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 7.00)
3. [ASSISTANT] –ü—Ä–∏–≤–µ...
2025-07-10 05:55:03,045 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5050
2025-07-10 05:55:03,189 - urllib3.connectionpool - DEBUG - http://127.0.0.1:5050 "GET /api/health HTTP/1.1" 200 98
2025-07-10 05:55:03,189 - gopiai.ui.components.crewai_client - DEBUG - –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ CrewAI: {'message': '–Ω–µ–µ–µ–µ—ÇüòÑ –ü–æ–¥—É–º–∞–π –µ—â–µ, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –≤—Å–ø–æ–º–Ω–∏—Ç—å', 'metadata': {'session_id': 'session_1752107030', 'chat_history': [{'role': 'system', 'content': '–¢—ã - –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–≥–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é. –ë—É–¥—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–º –∏ –æ—Ç–∑—ã–≤—á–∏–≤—ã–º.'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'assistant', 'content': '–Ω–µ–µ–µ–µ—ÇüòÑ –ü–æ–¥—É–º–∞–π –µ—â–µ, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –≤—Å–ø–æ–º–Ω–∏—Ç—å'}, {'role': 'assistant', 'content': '–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. üòä\n'}, {'role': 'assistant', 'content': '–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. üòä\n'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–Ω–µ–µ–µ–µ—ÇüòÑ –ü–æ–¥—É–º–∞–π –µ—â–µ, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –≤—Å–ø–æ–º–Ω–∏—Ç—å'}], 'rag_context': '1. [ASSISTANT] –ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ —Å–≤–æ–µ–π —Å–æ–±–∞–∫–µ? (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 5.00)\n2. [ASSISTANT] –ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ —Å–≤–æ–µ–π —Å–æ–±–∞–∫–µ? (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 7.00)\n3. [ASSISTANT] –ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ —Å–≤–æ–µ–π —Å–æ–±–∞–∫–µ? (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 12.00)'}, 'system_prompt': '–¢—ã - –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –ë—É–¥—å –≤–µ–∂–ª–∏–≤—ã–º –∏ –∫—Ä–∞—Ç–∫–∏–º. –ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å –æ—Ç–≤–µ—Ç–∞, —Ç–∞–∫ –∏ —Å–∫–∞–∂–∏.'}
2025-07-10 05:55:03,193 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5050
2025-07-10 05:55:12,945 - urllib3.connectionpool - DEBUG - http://127.0.0.1:5050 "POST /api/process HTTP/1.1" 200 1268
2025-07-10 05:55:13,448 - gopiai.ui.components.chat_widget - INFO - üîÑ [SIGNAL_HANDLER] –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø–æ—Ç–æ–∫–µ: {'analysis': {'analysis_time': 0.0, 'complexity': 0, 'requires_crewai': False, 'type': 'general'}, 'processed_with_crewai': False, 'response': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å... –•–æ—Ä–æ—à–æ, –¥–∞–≤–∞–π –ø–æ–ø—Ä–æ–±—É–µ–º –µ—â—ë —Ä–∞–∑! ü§î –¢—ã –≥–æ–≤–æ—Ä–∏–ª–∞ –ø—Ä–æ —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π... —ç—ç—ç... —á—Ç–æ-—Ç–æ —Å–≤—è–∑–∞–Ω–Ω–æ–µ —Å —Ä—ã–±–∞–º–∏... –ú–æ–∂–µ—Ç –±—ã—Ç—å, –æ–Ω –ª—é–±–∏—Ç —Ä—ã–±—É? –ò–ª–∏ —É –Ω–µ–≥–æ –µ—Å—Ç—å –∞–∫–≤–∞—Ä–∏—É–º? –ò–ª–∏... –æ–Ω –∫–∞–∫-—Ç–æ —Å–≤—è–∑–∞–Ω —Å –º–æ—Ä–µ–º? –î–∞–≤–∞–π, –ø–æ–¥—Å–∫–∞–∑—ã–≤–∞–π! üòÑ\n'}
2025-07-10 05:56:01,143 - gopiai.ui.components.chat_widget - INFO - [MEMORY] –ù–∞–π–¥–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø–∞–º—è—Ç–∏: 1. [ASSISTANT] –ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ —Å–≤–æ–µ–π —Å–æ–±–∞–∫–µ? (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 18.00)
2. [ASSISTANT] –ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ —Å–≤–æ–µ–π —Å–æ–±–∞–∫–µ? (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 16.00)
3. [ASSISTANT] –ü—Ä–∏...
2025-07-10 05:56:01,154 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5050
2025-07-10 05:56:01,182 - urllib3.connectionpool - DEBUG - http://127.0.0.1:5050 "GET /api/health HTTP/1.1" 200 98
2025-07-10 05:56:01,194 - gopiai.ui.components.crewai_client - DEBUG - –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ CrewAI: {'message': '–ù—É, –Ω–µ–µ–µ–µ—Ç ü§£ –ò —Å —á–µ–≥–æ —Ç—ã –≤–∑—è–ª–∞, —á—Ç–æ —ç—Ç–æ —á–µ–ª–æ–≤–µ–∫?', 'metadata': {'session_id': 'session_1752107030', 'chat_history': [{'role': 'system', 'content': '–¢—ã - –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–≥–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é. –ë—É–¥—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–º –∏ –æ—Ç–∑—ã–≤—á–∏–≤—ã–º.'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'assistant', 'content': '–ù—É, –Ω–µ–µ–µ–µ—Ç ü§£ –ò —Å —á–µ–≥–æ —Ç—ã –≤–∑—è–ª–∞, —á—Ç–æ —ç—Ç–æ —á–µ–ª–æ–≤–µ–∫?'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å... –•–æ—Ä–æ—à–æ, –¥–∞–≤–∞–π –ø–æ–ø—Ä–æ–±—É–µ–º –µ—â—ë —Ä–∞–∑! ü§î –¢—ã –≥–æ–≤–æ—Ä–∏–ª–∞ –ø—Ä–æ —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π... —ç—ç—ç... —á—Ç–æ-—Ç–æ —Å–≤—è–∑–∞–Ω–Ω–æ–µ —Å —Ä—ã–±–∞–º–∏... –ú–æ–∂–µ—Ç –±—ã—Ç—å, –æ–Ω –ª—é–±–∏—Ç —Ä—ã–±—É? –ò–ª–∏ —É –Ω–µ–≥–æ –µ—Å—Ç—å –∞–∫–≤–∞—Ä–∏—É–º? –ò–ª–∏... –æ–Ω –∫–∞–∫-—Ç–æ —Å–≤—è–∑–∞–Ω —Å –º–æ—Ä–µ–º? –î–∞–≤–∞–π, –ø–æ–¥—Å–∫–∞–∑—ã–≤–∞–π! üòÑ\n'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å... –•–æ—Ä–æ—à–æ, –¥–∞–≤–∞–π –ø–æ–ø—Ä–æ–±—É–µ–º –µ—â—ë —Ä–∞–∑! ü§î –¢—ã –≥–æ–≤–æ—Ä–∏–ª–∞ –ø—Ä–æ —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π... —ç—ç—ç... —á—Ç–æ-—Ç–æ —Å–≤—è–∑–∞–Ω–Ω–æ–µ —Å —Ä—ã–±–∞–º–∏... –ú–æ–∂–µ—Ç –±—ã—Ç—å, –æ–Ω –ª—é–±–∏—Ç —Ä—ã–±—É? –ò–ª–∏ —É –Ω–µ–≥–æ –µ—Å—Ç—å –∞–∫–≤–∞—Ä–∏—É–º? –ò–ª–∏... –æ–Ω –∫–∞–∫-—Ç–æ —Å–≤—è–∑–∞–Ω —Å –º–æ—Ä–µ–º? –î–∞–≤–∞–π, –ø–æ–¥—Å–∫–∞–∑—ã–≤–∞–π! üòÑ\n'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–ù—É, –Ω–µ–µ–µ–µ—Ç ü§£ –ò —Å —á–µ–≥–æ —Ç—ã –≤–∑—è–ª–∞, —á—Ç–æ —ç—Ç–æ —á–µ–ª–æ–≤–µ–∫?'}], 'rag_context': '1. [ASSISTANT] –ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ —Å–≤–æ–µ–π —Å–æ–±–∞–∫–µ? (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 18.00)\n2. [ASSISTANT] –ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ —Å–≤–æ–µ–π —Å–æ–±–∞–∫–µ? (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 16.00)\n3. [ASSISTANT] –ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ —Å–≤–æ–µ–π —Å–æ–±–∞–∫–µ? (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 8.00)'}, 'system_prompt': '–¢—ã - –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –ë—É–¥—å –≤–µ–∂–ª–∏–≤—ã–º –∏ –∫—Ä–∞—Ç–∫–∏–º. –ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å –æ—Ç–≤–µ—Ç–∞, —Ç–∞–∫ –∏ —Å–∫–∞–∂–∏.'}
2025-07-10 05:56:01,263 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5050
2025-07-10 05:56:09,177 - urllib3.connectionpool - DEBUG - http://127.0.0.1:5050 "POST /api/process HTTP/1.1" 200 1380
2025-07-10 05:56:09,679 - gopiai.ui.components.chat_widget - INFO - üîÑ [SIGNAL_HANDLER] –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø–æ—Ç–æ–∫–µ: {'analysis': {'analysis_time': 0.0, 'complexity': 0, 'requires_crewai': False, 'type': 'general'}, 'processed_with_crewai': False, 'response': '–ü—Ä–æ—Å—Ç–∏, —è –Ω–µ–º–Ω–æ–≥–æ –∑–∞–ø—É—Ç–∞–ª—Å—è!  –Ø –Ω–µ –∏–º–µ—é –¥–æ—Å—Ç—É–ø–∞ –∫ –ø—Ä–µ–¥—ã–¥—É—â–∏–º —Ä–∞–∑–≥–æ–≤–æ—Ä–∞–º –∏ –Ω–µ –∑–Ω–∞—é, –æ –∫–æ–º –∏–ª–∏ –æ —á—ë–º —Ç—ã –≥–æ–≤–æ—Ä–∏–ª–∞ —Ä–∞–Ω—å—à–µ.  –ß—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–¥–∞–π —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å –∑–∞–Ω–æ–≤–æ.  –ß–µ–º –ø–æ–¥—Ä–æ–±–Ω–µ–µ —Ç—ã –æ–ø–∏—à–µ—à—å —Å–≤–æ—é –ø—Ä–æ—Å—å–±—É, —Ç–µ–º –ª—É—á—à–µ —è —Å–º–æ–≥—É —Ç–µ–±–µ –ø–æ–º–æ—á—å.\n'}
2025-07-10 05:56:43,136 - gopiai.ui.components.chat_widget - INFO - [MEMORY] –ù–∞–π–¥–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø–∞–º—è—Ç–∏: 1. [ASSISTANT] –ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ —Å–≤–æ–µ–π —Å–æ–±–∞–∫–µ? (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 6.00)
2. [ASSISTANT] –ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ —Å–≤–æ–µ–π —Å–æ–±–∞–∫–µ? (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 3.00)
3. [ASSISTANT] –ü—Ä–∏–≤–µ...
2025-07-10 05:56:43,161 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5050
2025-07-10 05:56:43,187 - urllib3.connectionpool - DEBUG - http://127.0.0.1:5050 "GET /api/health HTTP/1.1" 200 98
2025-07-10 05:56:43,197 - gopiai.ui.components.crewai_client - DEBUG - –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ CrewAI: {'message': '–∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É?', 'metadata': {'session_id': 'session_1752107030', 'chat_history': [{'role': 'system', 'content': '–¢—ã - –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–≥–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é. –ë—É–¥—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–º –∏ –æ—Ç–∑—ã–≤—á–∏–≤—ã–º.'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'assistant', 'content': '–∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É?'}, {'role': 'assistant', 'content': '–ü—Ä–æ—Å—Ç–∏, —è –Ω–µ–º–Ω–æ–≥–æ –∑–∞–ø—É—Ç–∞–ª—Å—è!  –Ø –Ω–µ –∏–º–µ—é –¥–æ—Å—Ç—É–ø–∞ –∫ –ø—Ä–µ–¥—ã–¥—É—â–∏–º —Ä–∞–∑–≥–æ–≤–æ—Ä–∞–º –∏ –Ω–µ –∑–Ω–∞—é, –æ –∫–æ–º –∏–ª–∏ –æ —á—ë–º —Ç—ã –≥–æ–≤–æ—Ä–∏–ª–∞ —Ä–∞–Ω—å—à–µ.  –ß—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–¥–∞–π —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å –∑–∞–Ω–æ–≤–æ.  –ß–µ–º –ø–æ–¥—Ä–æ–±–Ω–µ–µ —Ç—ã –æ–ø–∏—à–µ—à—å —Å–≤–æ—é –ø—Ä–æ—Å—å–±—É, —Ç–µ–º –ª—É—á—à–µ —è —Å–º–æ–≥—É —Ç–µ–±–µ –ø–æ–º–æ—á—å.\n'}, {'role': 'assistant', 'content': '–ü—Ä–æ—Å—Ç–∏, —è –Ω–µ–º–Ω–æ–≥–æ –∑–∞–ø—É—Ç–∞–ª—Å—è!  –Ø –Ω–µ –∏–º–µ—é –¥–æ—Å—Ç—É–ø–∞ –∫ –ø—Ä–µ–¥—ã–¥—É—â–∏–º —Ä–∞–∑–≥–æ–≤–æ—Ä–∞–º –∏ –Ω–µ –∑–Ω–∞—é, –æ –∫–æ–º –∏–ª–∏ –æ —á—ë–º —Ç—ã –≥–æ–≤–æ—Ä–∏–ª–∞ —Ä–∞–Ω—å—à–µ.  –ß—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–¥–∞–π —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å –∑–∞–Ω–æ–≤–æ.  –ß–µ–º –ø–æ–¥—Ä–æ–±–Ω–µ–µ —Ç—ã –æ–ø–∏—à–µ—à—å —Å–≤–æ—é –ø—Ä–æ—Å—å–±—É, —Ç–µ–º –ª—É—á—à–µ —è —Å–º–æ–≥—É —Ç–µ–±–µ –ø–æ–º–æ—á—å.\n'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É?'}], 'rag_context': '1. [ASSISTANT] –ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ —Å–≤–æ–µ–π —Å–æ–±–∞–∫–µ? (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 6.00)\n2. [ASSISTANT] –ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ —Å–≤–æ–µ–π —Å–æ–±–∞–∫–µ? (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 3.00)\n3. [ASSISTANT] –ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ —Å–≤–æ–µ–π —Å–æ–±–∞–∫–µ? (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 1.00)'}, 'system_prompt': '–¢—ã - –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –ë—É–¥—å –≤–µ–∂–ª–∏–≤—ã–º –∏ –∫—Ä–∞—Ç–∫–∏–º. –ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å –æ—Ç–≤–µ—Ç–∞, —Ç–∞–∫ –∏ —Å–∫–∞–∂–∏.'}
2025-07-10 05:56:43,233 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5050
2025-07-10 05:57:06,145 - urllib3.connectionpool - DEBUG - http://127.0.0.1:5050 "POST /api/process HTTP/1.1" 200 1526
2025-07-10 05:57:06,647 - gopiai.ui.components.chat_widget - INFO - üîÑ [SIGNAL_HANDLER] –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø–æ—Ç–æ–∫–µ: {'analysis': {'analysis_time': 0.0, 'complexity': 0, 'requires_crewai': False, 'type': 'general'}, 'processed_with_crewai': False, 'response': '–Ø –∏–∑–≤–∏–Ω–∏–ª—Å—è –∑–∞ —Ç–æ, —á—Ç–æ –Ω–µ –ø–æ–º–Ω—é –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤.  –Ø —Å–ø—Ä–æ—Å–∏–ª, –∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É —Ç—ã —Ö–æ—á–µ—à—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å, —á—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å.  –£ –º–µ–Ω—è –Ω–µ—Ç –ø–∞–º—è—Ç–∏ –æ –ø—Ä–æ—à–ª—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö, –ø–æ—ç—Ç–æ–º—É –∫–∞–∂–¥—ã–π –Ω–∞—à —Ä–∞–∑–≥–æ–≤–æ—Ä –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞.  –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏, —á—Ç–æ —Ç—ã —Ö–æ—á–µ—à—å, —á—Ç–æ–±—ã —è —Å–¥–µ–ª–∞–ª.\n'}
2025-07-10 05:57:27,162 - gopiai.ui.components.chat_widget - INFO - [MEMORY] –ù–∞–π–¥–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø–∞–º—è—Ç–∏: 1. [ASSISTANT] –ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ —Å–≤–æ–µ–π —Å–æ–±–∞–∫–µ? (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 18.00)
2. [ASSISTANT] –ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ —Å–≤–æ–µ–π —Å–æ–±–∞–∫–µ? (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 16.00)
3. [ASSISTANT] –ü—Ä–∏...
2025-07-10 05:57:27,285 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5050
2025-07-10 05:57:27,336 - urllib3.connectionpool - DEBUG - http://127.0.0.1:5050 "GET /api/health HTTP/1.1" 200 97
2025-07-10 05:57:27,342 - gopiai.ui.components.crewai_client - DEBUG - –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ CrewAI: {'message': '–ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?', 'metadata': {'session_id': 'session_1752107030', 'chat_history': [{'role': 'system', 'content': '–¢—ã - –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–≥–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é. –ë—É–¥—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–º –∏ –æ—Ç–∑—ã–≤—á–∏–≤—ã–º.'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'assistant', 'content': '–ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}, {'role': 'assistant', 'content': '–Ø –∏–∑–≤–∏–Ω–∏–ª—Å—è –∑–∞ —Ç–æ, —á—Ç–æ –Ω–µ –ø–æ–º–Ω—é –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤.  –Ø —Å–ø—Ä–æ—Å–∏–ª, –∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É —Ç—ã —Ö–æ—á–µ—à—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å, —á—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å.  –£ –º–µ–Ω—è –Ω–µ—Ç –ø–∞–º—è—Ç–∏ –æ –ø—Ä–æ—à–ª—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö, –ø–æ—ç—Ç–æ–º—É –∫–∞–∂–¥—ã–π –Ω–∞—à —Ä–∞–∑–≥–æ–≤–æ—Ä –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞.  –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏, —á—Ç–æ —Ç—ã —Ö–æ—á–µ—à—å, —á—Ç–æ–±—ã —è —Å–¥–µ–ª–∞–ª.\n'}, {'role': 'assistant', 'content': '–Ø –∏–∑–≤–∏–Ω–∏–ª—Å—è –∑–∞ —Ç–æ, —á—Ç–æ –Ω–µ –ø–æ–º–Ω—é –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤.  –Ø —Å–ø—Ä–æ—Å–∏–ª, –∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É —Ç—ã —Ö–æ—á–µ—à—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å, —á—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å.  –£ –º–µ–Ω—è –Ω–µ—Ç –ø–∞–º—è—Ç–∏ –æ –ø—Ä–æ—à–ª—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö, –ø–æ—ç—Ç–æ–º—É –∫–∞–∂–¥—ã–π –Ω–∞—à —Ä–∞–∑–≥–æ–≤–æ—Ä –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞.  –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏, —á—Ç–æ —Ç—ã —Ö–æ—á–µ—à—å, —á—Ç–æ–±—ã —è —Å–¥–µ–ª–∞–ª.\n'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}], 'rag_context': '1. [ASSISTANT] –ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ —Å–≤–æ–µ–π —Å–æ–±–∞–∫–µ? (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 18.00)\n2. [ASSISTANT] –ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ —Å–≤–æ–µ–π —Å–æ–±–∞–∫–µ? (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 16.00)\n3. [ASSISTANT] –ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ —Å–≤–æ–µ–π —Å–æ–±–∞–∫–µ? (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 8.00)'}, 'system_prompt': '–¢—ã - –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –ë—É–¥—å –≤–µ–∂–ª–∏–≤—ã–º –∏ –∫—Ä–∞—Ç–∫–∏–º. –ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å –æ—Ç–≤–µ—Ç–∞, —Ç–∞–∫ –∏ —Å–∫–∞–∂–∏.'}
2025-07-10 05:57:27,364 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5050
2025-07-10 05:57:34,356 - urllib3.connectionpool - DEBUG - http://127.0.0.1:5050 "POST /api/process HTTP/1.1" 200 970
2025-07-10 05:57:34,866 - gopiai.ui.components.chat_widget - INFO - üîÑ [SIGNAL_HANDLER] –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø–æ—Ç–æ–∫–µ: {'analysis': {'analysis_time': 0.0, 'complexity': 0, 'requires_crewai': False, 'type': 'creative'}, 'processed_with_crewai': False, 'response': '–ò–∑–≤–∏–Ω–∏, –Ω–æ —É –º–µ–Ω—è –Ω–µ—Ç –ø–∞–º—è—Ç–∏ –æ –ø—Ä–æ—à–ª—ã—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–∞—Ö.  –ö–∞–∂–¥—ã–π –Ω–∞—à –¥–∏–∞–ª–æ–≥ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –∑–∞–Ω–æ–≤–æ.  –ß—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, —Ä–∞—Å—Å–∫–∞–∂–∏ –º–Ω–µ, –∫—Ç–æ —Ç–∞–∫–∞—è ¬´–∑–æ–ª–æ—Ç–∞—è —Ä—ã–±–∫–∞¬ª.\n'}

(gopiai_env) C:\Users\crazy\GOPI_AI_MODULES\GopiAI-UI>




‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
   ü§ñ CrewAI API Server Environment
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üîÑ Activating CrewAI environment...
‚úÖ Environment activated
üìÇ Directory: GopiAI-CrewAI
üêç Environment: C:\Users\crazy\GOPI_AI_MODULES\GopiAI-CrewAI\crewai_env

üöÄ Starting CrewAI API Server...
DEBUG: Content of llm_rotation_config.py at C:\Users\crazy\GOPI_AI_MODULES\GopiAI-CrewAI\llm_rotation_config.py:
import os
import time
import threading
# –ö–æ–Ω—Ñ–∏–≥ –º–æ–¥–µ–ª–µ–π Gemini/Gemma –¥–ª—è —Ä–æ—Ç–∞—Ü–∏–∏ –∏ –∑–∞–¥–∞—á
LLM_MODELS_CONFIG = [
    {
        "name": "Gemini 1.5 Flash",
        "id": "gemini/gemini-1.5-flash",
        "provider": "google",
        "rpm": 15,
        "tpm": 250000,
        "type": ["simple", "dialog", "code", "summarize"],
        "multimodal": False,
        "embedding": False,
        "priority": 3,
        "rpd": 50,
        "deprecated": False,
        "base_score": 0.5
    },
    {
  ...
‚Üê[92m05:52:56 - LiteLLM:DEBUG‚Üê[0m: http_handler.py:533 - Using AiohttpTransport...
2025-07-10 05:52:56,196 - LiteLLM - DEBUG - Using AiohttpTransport...
‚Üê[92m05:52:56 - LiteLLM:DEBUG‚Üê[0m: http_handler.py:557 - Creating AiohttpTransport...
2025-07-10 05:52:56,199 - LiteLLM - DEBUG - Creating AiohttpTransport...
2025-07-10 05:52:57,141 - httpcore.connection - DEBUG - connect_tcp.started host='raw.githubusercontent.com' port=443 local_address=None timeout=5 socket_options=None
2025-07-10 05:52:57,214 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002572C1AF020>
2025-07-10 05:52:57,215 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002572C14C550> server_hostname='raw.githubusercontent.com' timeout=5
2025-07-10 05:52:57,262 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002572C161520>
2025-07-10 05:52:57,264 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'GET']>
2025-07-10 05:52:57,265 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-07-10 05:52:57,266 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'GET']>
2025-07-10 05:52:57,267 - httpcore.http11 - DEBUG - send_request_body.complete
2025-07-10 05:52:57,268 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'GET']>
2025-07-10 05:52:57,300 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Connection', b'keep-alive'), (b'Content-Length', b'26277'), (b'Cache-Control', b'max-age=300'), (b'Content-Security-Policy', b"default-src 'none'; style-src 'unsafe-inline'; sandbox"), (b'Content-Type', b'text/plain; charset=utf-8'), (b'ETag', b'W/"2e2e8fe8b4766044ddbd63788232b654be39bca74aa232fe7f6ddefb92cb4234"'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'X-Content-Type-Options', b'nosniff'), (b'X-Frame-Options', b'deny'), (b'X-XSS-Protection', b'1; mode=block'), (b'X-GitHub-Request-Id', b'CB54:32C3A4:5D60:34A87:686EFA39'), (b'Content-Encoding', b'gzip'), (b'Accept-Ranges', b'bytes'), (b'Date', b'Thu, 10 Jul 2025 00:22:48 GMT'), (b'Via', b'1.1 varnish'), (b'X-Served-By', b'cache-del21722-DEL'), (b'X-Cache', b'HIT'), (b'X-Cache-Hits', b'5'), (b'X-Timer', b'S1752106969.753063,VS0,VE0'), (b'Vary', b'Authorization,Accept-Encoding'), (b'Access-Control-Allow-Origin', b'*'), (b'Cross-Origin-Resource-Policy', b'cross-origin'), (b'X-Fastly-Request-ID', b'e6cf7f2a49dde0628bec45b51ca0fba26cd72546'), (b'Expires', b'Thu, 10 Jul 2025 00:27:48 GMT'), (b'Source-Age', b'148')])
2025-07-10 05:52:57,304 - httpx - INFO - HTTP Request: GET https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json "HTTP/1.1 200 OK"
2025-07-10 05:52:57,306 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'GET']>
2025-07-10 05:52:57,315 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-07-10 05:52:57,317 - httpcore.http11 - DEBUG - response_closed.started
2025-07-10 05:52:57,318 - httpcore.http11 - DEBUG - response_closed.complete
2025-07-10 05:52:57,320 - httpcore.connection - DEBUG - close.started
2025-07-10 05:52:57,322 - httpcore.connection - DEBUG - close.complete
‚Üê[92m05:52:57 - LiteLLM:DEBUG‚Üê[0m: http_handler.py:533 - Using AiohttpTransport...
2025-07-10 05:52:57,889 - LiteLLM - DEBUG - Using AiohttpTransport...
‚Üê[92m05:52:57 - LiteLLM:DEBUG‚Üê[0m: http_handler.py:557 - Creating AiohttpTransport...
2025-07-10 05:52:57,894 - LiteLLM - DEBUG - Creating AiohttpTransport...
‚Üê[92m05:52:58 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:169 - [Non-Blocking] Unable to import GenericAPILogger - LiteLLM Enterprise Feature - No module named 'litellm_enterprise'
2025-07-10 05:52:58,834 - LiteLLM - DEBUG - [Non-Blocking] Unable to import GenericAPILogger - LiteLLM Enterprise Feature - No module named 'litellm_enterprise'
‚Üê[92m05:53:00 - LiteLLM:DEBUG‚Üê[0m: transformation.py:17 - [Non-Blocking] Unable to import _ENTERPRISE_ResponsesSessionHandler - LiteLLM Enterprise Feature - No module named 'litellm_enterprise'
2025-07-10 05:53:00,096 - LiteLLM - DEBUG - [Non-Blocking] Unable to import _ENTERPRISE_ResponsesSessionHandler - LiteLLM Enterprise Feature - No module named 'litellm_enterprise'
‚Üê[92m05:53:00 - LiteLLM:DEBUG‚Üê[0m: http_handler.py:533 - Using AiohttpTransport...
2025-07-10 05:53:00,111 - LiteLLM - DEBUG - Using AiohttpTransport...
‚Üê[92m05:53:00 - LiteLLM:DEBUG‚Üê[0m: http_handler.py:557 - Creating AiohttpTransport...
2025-07-10 05:53:00,114 - LiteLLM - DEBUG - Creating AiohttpTransport...
‚Üê[92m05:53:00 - LiteLLM:DEBUG‚Üê[0m: http_handler.py:533 - Using AiohttpTransport...
2025-07-10 05:53:00,124 - LiteLLM - DEBUG - Using AiohttpTransport...
‚Üê[92m05:53:00 - LiteLLM:DEBUG‚Üê[0m: http_handler.py:557 - Creating AiohttpTransport...
2025-07-10 05:53:00,127 - LiteLLM - DEBUG - Creating AiohttpTransport...
DEBUG: LLM_MODELS_CONFIG loaded: [{'name': 'Gemini 1.5 Flash', 'id': 'gemini/gemini-1.5-flash', 'provider': 'google', 'rpm': 15, 'tpm': 250000, 'type': ['simple', 'dialog', 'code', 'summarize'], 'multimodal': False, 'embedding': False, 'priority': 3, 'rpd': 50, 'deprecated': False, 'base_score': 0.5}, {'name': 'Gemini 2.0 Flash-Lite', 'id': 'gemini/gemini-2.0-flash-lite', 'provider': 'google', 'rpm': 30, 'tpm': 1000000, 'type': ['simple', 'dialog', 'code', 'summarize'], 'multimodal': False, 'embedding': False, 'priority': 4, 'rpd': 200, 'deprecated': False, 'base_score': 0.5}, {'name': 'Gemma 3', 'id': 'gemini/gemma-3', 'provider': 'google', 'rpm': 30, 'tpm': 14400, 'type': ['simple', 'lookup', 'short_answer'], 'multimodal': False, 'embedding': False, 'priority': 1, 'rpd': 0, 'deprecated': False, 'base_score': 0.5}, {'name': 'Gemma 3n', 'id': 'gemini/gemma-3n', 'provider': 'google', 'rpm': 30, 'tpm': 14400, 'type': ['simple', 'lookup', 'short_answer'], 'multimodal': False, 'embedding': False, 'priority': 2, 'rpd': 0, 'deprecated': False, 'base_score': 0.5}, {'name': 'Gemini 2.5 Flash-Lite Preview', 'id': 'gemini/gemini-2.5-flash-lite-preview', 'provider': 'google', 'rpm': 15, 'tpm': 60000, 'type': ['dialog', 'code', 'summarize'], 'multimodal': False, 'embedding': False, 'priority': 5, 'rpd': 0, 'deprecated': False, 'base_score': 0.5}, {'name': 'Gemini 2.5 Flash', 'id': 'gemini/gemini-2.5-flash', 'provider': 'google', 'rpm': 10, 'tpm': 60000, 'type': ['dialog', 'code', 'multimodal', 'vision', 'long_answer'], 'multimodal': True, 'embedding': False, 'priority': 6, 'rpd': 0, 'deprecated': False, 'base_score': 0.5}, {'name': 'Gemini Embedding Experimental', 'id': 'gemini/gemini-embedding-experimental', 'provider': 'google', 'rpm': 5, 'tpm': 10000, 'type': ['embedding'], 'multimodal': False, 'embedding': True, 'priority': 10, 'rpd': 0, 'deprecated': False, 'base_score': 0.5}]
[OK] RateLimitMonitor –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å blacklist –º–µ—Ö–∞–Ω–∏–∑–º–æ–º
[OK] –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ LLM –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ
GopiAI Integration Tools loaded successfully!
[OK] CrewAI —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω!
2025-07-10 05:53:02,939 - tools.gopiai_integration.ai_router_llm - INFO - ‚úÖ AIRouterLLM –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π —Ä–æ—Ç–∞—Ü–∏–∏
2025-07-10 05:53:02,973 - tools.gopiai_integration.self_reflection - INFO - ReflectionEnabledAIRouter –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (reflection=enabled)
2025-07-10 05:53:02,992 - tools.gopiai_integration.self_reflection - INFO - –ü–æ—Ä–æ–≥ –∫–∞—á–µ—Å—Ç–≤–∞: 8.0/10
[OK] AI Router —Å —Å–∞–º–æ—Ä–µ—Ñ–ª–µ–∫—Å–∏–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω (–ø–æ—Ä–æ–≥ –∫–∞—á–µ—Å—Ç–≤–∞: 8.0)
[OK] –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è RAG-—Å–∏—Å—Ç–µ–º–∞ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–∞.
‚úÖ –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
[OK] –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞.
Smart Delegator —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω
Starting CrewAI API server at http://127.0.0.1:5050
This server should be run from the CrewAI environment (crewai_env)
Using Python: C:\Users\crazy\GOPI_AI_MODULES\GopiAI-CrewAI\crewai_env\Scripts\python.exe
CrewAI module is available
Langchain module is available
Request timeout: 300 seconds
Connection timeout: 60 seconds
 * Serving Flask app 'crewai_api_server'
 * Debug mode: off
2025-07-10 05:53:03,167 - werkzeug - INFO - ‚Üê[31m‚Üê[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.‚Üê[0m
 * Running on http://127.0.0.1:5050
2025-07-10 05:53:03,176 - werkzeug - INFO - ‚Üê[33mPress CTRL+C to quit‚Üê[0m
2025-07-10 05:53:50,851 - werkzeug - INFO - 127.0.0.1 - - [10/Jul/2025 05:53:50] "GET /api/health HTTP/1.1" 200 -
üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: —Å–ª–æ–∂–Ω–æ—Å—Ç—å=0, —Ç–∏–ø=creative, CrewAI=False
üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: —Å–ª–æ–∂–Ω–æ—Å—Ç—å=0, —Ç–∏–ø=creative, CrewAI=False
üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: —Å–ª–æ–∂–Ω–æ—Å—Ç—å=0, —Ç–∏–ø=creative, CrewAI=False
üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: —Å–ª–æ–∂–Ω–æ—Å—Ç—å=0, —Ç–∏–ø=creative, CrewAI=False
2025-07-10 05:54:14,763 - tools.gopiai_integration.smart_delegator - INFO - üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ AI Router...
2025-07-10 05:54:14,771 - tools.gopiai_integration.smart_delegator - INFO - ‚úÖ AI Router –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã
2025-07-10 05:54:14,791 - tools.gopiai_integration.smart_delegator - INFO - –ó–∞–≥—Ä—É–∂–µ–Ω–æ 2 —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞
2025-07-10 05:54:14,805 - tools.gopiai_integration.smart_delegator - INFO - üöÄ –í—ã–∑–æ–≤ LLM —Å –∏—Å—Ç–æ—Ä–∏–µ–π —á–∞—Ç–∞...
2025-07-10 05:54:14,815 - tools.gopiai_integration.smart_delegator - DEBUG - –û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ LLM: [
  {
    "role": "system",
    "content": "–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç."
  },
  {
    "role": "assistant",
    "content": "–ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?"
  },
  {
    "role": "assistant",
    "content": "‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å..."
  },
  {
    "role": "user",
    "content": "–ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?"
  }
]
[AVAILABLE] –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è 'dialog': ['gemini/gemini-1.5-flash', 'gemini/gemini-2.0-flash-lite', 'gemini/gemini-2.5-flash-lite-preview', 'gemini/gemini-2.5-flash']
[CHECK] –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏ gemini/gemini-1.5-flash —Å 124 —Ç–æ–∫–µ–Ω–∞–º–∏...
[STATS] –ú–æ–¥–µ–ª—å gemini/gemini-1.5-flash: —Ç–µ–∫—É—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ RPM=0/15, TPM=0/250000, RPD=0/50
[OK] –ú–æ–¥–µ–ª—å gemini/gemini-1.5-flash: RPM_OK=True, TPM_OK=True, RPD_OK=True -> RESULT=True
[SELECTED] AI Router: –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å 'gemini/gemini-1.5-flash' (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 3)
2025-07-10 05:54:14,832 - tools.gopiai_integration.smart_delegator - INFO - –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: gemini/gemini-1.5-flash
[AVAILABLE] –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è 'dialog': ['gemini/gemini-1.5-flash', 'gemini/gemini-2.0-flash-lite', 'gemini/gemini-2.5-flash-lite-preview', 'gemini/gemini-2.5-flash']
[CHECK] –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏ gemini/gemini-1.5-flash —Å 124 —Ç–æ–∫–µ–Ω–∞–º–∏...
[STATS] –ú–æ–¥–µ–ª—å gemini/gemini-1.5-flash: —Ç–µ–∫—É—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ RPM=0/15, TPM=0/250000, RPD=0/50
[OK] –ú–æ–¥–µ–ª—å gemini/gemini-1.5-flash: RPM_OK=True, TPM_OK=True, RPD_OK=True -> RESULT=True
[SELECTED] AI Router: –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å 'gemini/gemini-1.5-flash' (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 3)
üîÑ –ü–æ–ø—ã—Ç–∫–∞ 1: –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å gemini/gemini-1.5-flash
‚Üê[92m05:54:14 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 -

2025-07-10 05:54:14,838 - LiteLLM - DEBUG -

‚Üê[92m05:54:14 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - ‚Üê[92mRequest to litellm:‚Üê[0m
2025-07-10 05:54:14,840 - LiteLLM - DEBUG - ‚Üê[92mRequest to litellm:‚Üê[0m
‚Üê[92m05:54:14 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - ‚Üê[92mlitellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}, {'role': 'assistant', 'content': '–ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}], temperature=0.7, max_tokens=2000)‚Üê[0m
2025-07-10 05:54:14,842 - LiteLLM - DEBUG - ‚Üê[92mlitellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}, {'role': 'assistant', 'content': '–ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}], temperature=0.7, max_tokens=2000)‚Üê[0m
‚Üê[92m05:54:14 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 -

2025-07-10 05:54:14,850 - LiteLLM - DEBUG -

‚Üê[92m05:54:14 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:461 - self.optional_params: {}
2025-07-10 05:54:14,851 - LiteLLM - DEBUG - self.optional_params: {}
‚Üê[92m05:54:14 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-07-10 05:54:14,853 - LiteLLM - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
‚Üê[92m05:54:14 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
2025-07-10 05:54:14,864 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
‚Üê[92m05:54:14 - LiteLLM:INFO‚Üê[0m: utils.py:3119 -
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-07-10 05:54:14,867 - LiteLLM - INFO -
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
‚Üê[92m05:54:14 - LiteLLM:DEBUG‚Üê[0m: utils.py:3122 -
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.7, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 2000, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}, {'role': 'assistant', 'content': '–ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}], 'thinking': None, 'web_search_options': None}
2025-07-10 05:54:14,869 - LiteLLM - DEBUG -
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.7, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 2000, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}, {'role': 'assistant', 'content': '–ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}], 'thinking': None, 'web_search_options': None}
‚Üê[92m05:54:14 - LiteLLM:DEBUG‚Üê[0m: utils.py:3125 -
LiteLLM: Non-Default params passed to completion() {'temperature': 0.7, 'max_tokens': 2000}
2025-07-10 05:54:14,876 - LiteLLM - DEBUG -
LiteLLM: Non-Default params passed to completion() {'temperature': 0.7, 'max_tokens': 2000}
‚Üê[92m05:54:14 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - Final returned optional params: {'temperature': 0.7, 'max_output_tokens': 2000}
2025-07-10 05:54:14,881 - LiteLLM - DEBUG - Final returned optional params: {'temperature': 0.7, 'max_output_tokens': 2000}
‚Üê[92m05:54:14 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:461 - self.optional_params: {'temperature': 0.7, 'max_tokens': 2000}
2025-07-10 05:54:14,883 - LiteLLM - DEBUG - self.optional_params: {'temperature': 0.7, 'max_tokens': 2000}
‚Üê[92m05:54:14 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:54:14,884 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:54:15 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:54:15,258 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:54:15 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:908 - ‚Üê[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****gu0Q \
-H 'Content-Type: ap****on' \
-d '{'contents': [{'role': 'model', 'parts': [{'text': '–ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}, {'text': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}]}, {'role': 'user', 'parts': [{'text': '–ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}]}], 'system_instruction': {'parts': [{'text': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}]}, 'generationConfig': {'temperature': 0.7, 'max_output_tokens': 2000}}'
‚Üê[0m

2025-07-10 05:54:15,262 - LiteLLM - DEBUG - ‚Üê[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****gu0Q \
-H 'Content-Type: ap****on' \
-d '{'contents': [{'role': 'model', 'parts': [{'text': '–ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}, {'text': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}]}, {'role': 'user', 'parts': [{'text': '–ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}]}], 'system_instruction': {'parts': [{'text': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}]}, 'generationConfig': {'temperature': 0.7, 'max_output_tokens': 2000}}'
‚Üê[0m

2025-07-10 05:54:15,631 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None
2025-07-10 05:54:15,758 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025732C82F00>
2025-07-10 05:54:15,759 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000025732C99F50> server_hostname='generativelanguage.googleapis.com' timeout=600.0
2025-07-10 05:54:15,804 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025732643C20>
2025-07-10 05:54:15,805 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-10 05:54:15,807 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-07-10 05:54:15,808 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-10 05:54:15,809 - httpcore.http11 - DEBUG - send_request_body.complete
2025-07-10 05:54:15,809 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-10 05:54:17,579 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 503, b'Service Unavailable', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 10 Jul 2025 00:24:08 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1739'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-10 05:54:17,581 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyD2taiOJ6Z7nLcVQrz_U0ct4G0HlyLgu0Q "HTTP/1.1 503 Service Unavailable"
2025-07-10 05:54:17,583 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-10 05:54:17,587 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-07-10 05:54:17,588 - httpcore.http11 - DEBUG - response_closed.started
2025-07-10 05:54:17,589 - httpcore.http11 - DEBUG - response_closed.complete




‚Üê[92m05:54:17 - LiteLLM:DEBUG‚Üê[0m: exception_mapping_utils.py:2300 - Logging Details: logger_fn - None | callable(logger_fn) - False
2025-07-10 05:54:17,592 - LiteLLM - DEBUG - Logging Details: logger_fn - None | callable(logger_fn) - False
‚Üê[92m05:54:17 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:2216 - Logging Details LiteLLM-Failure Call: []
2025-07-10 05:54:17,607 - LiteLLM - DEBUG - Logging Details LiteLLM-Failure Call: []
2025-07-10 05:54:17,615 - tools.gopiai_integration.smart_delegator - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ –º–æ–¥–µ–ª–∏ gemini/gemini-1.5-flash: litellm.InternalServerError: litellm.InternalServerError: VertexAIException - {
  "error": {
    "code": 503,
    "message": "The model is overloaded. Please try again later.",
    "status": "UNAVAILABLE"
  }
}


[AVAILABLE] –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è 'dialog': ['gemini/gemini-2.0-flash-lite', 'gemini/gemini-2.5-flash-lite-preview', 'gemini/gemini-2.5-flash']
[CHECK] –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏ gemini/gemini-2.0-flash-lite —Å 124 —Ç–æ–∫–µ–Ω–∞–º–∏...
[STATS] –ú–æ–¥–µ–ª—å gemini/gemini-2.0-flash-lite: —Ç–µ–∫—É—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ RPM=0/30, TPM=0/1000000, RPD=0/200
[OK] –ú–æ–¥–µ–ª—å gemini/gemini-2.0-flash-lite: RPM_OK=True, TPM_OK=True, RPD_OK=True -> RESULT=True
[SELECTED] AI Router: –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å 'gemini/gemini-2.0-flash-lite' (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 4)
üîÑ –ü–æ–ø—ã—Ç–∫–∞ 2: –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å gemini/gemini-2.0-flash-lite
‚Üê[92m05:54:17 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 -

2025-07-10 05:54:17,621 - LiteLLM - DEBUG -

‚Üê[92m05:54:17 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - ‚Üê[92mRequest to litellm:‚Üê[0m
2025-07-10 05:54:17,622 - LiteLLM - DEBUG - ‚Üê[92mRequest to litellm:‚Üê[0m
‚Üê[92m05:54:17 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - ‚Üê[92mlitellm.completion(model='gemini/gemini-2.0-flash-lite', messages=[{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}, {'role': 'assistant', 'content': '–ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}], temperature=0.7, max_tokens=2000)‚Üê[0m
2025-07-10 05:54:17,625 - LiteLLM - DEBUG - ‚Üê[92mlitellm.completion(model='gemini/gemini-2.0-flash-lite', messages=[{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}, {'role': 'assistant', 'content': '–ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}], temperature=0.7, max_tokens=2000)‚Üê[0m
‚Üê[92m05:54:17 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 -

2025-07-10 05:54:17,630 - LiteLLM - DEBUG -

‚Üê[92m05:54:17 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:461 - self.optional_params: {}
2025-07-10 05:54:17,638 - LiteLLM - DEBUG - self.optional_params: {}
‚Üê[92m05:54:17 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-07-10 05:54:17,640 - LiteLLM - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
‚Üê[92m05:54:17 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'custom_llm_provider': 'vertex_ai'}
2025-07-10 05:54:17,642 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'custom_llm_provider': 'vertex_ai'}
‚Üê[92m05:54:17 - LiteLLM:INFO‚Üê[0m: utils.py:3119 -
LiteLLM completion() model= gemini-2.0-flash-lite; provider = gemini
2025-07-10 05:54:17,646 - LiteLLM - INFO -
LiteLLM completion() model= gemini-2.0-flash-lite; provider = gemini
‚Üê[92m05:54:17 - LiteLLM:DEBUG‚Üê[0m: utils.py:3122 -
LiteLLM: Params passed to completion() {'model': 'gemini-2.0-flash-lite', 'functions': None, 'function_call': None, 'temperature': 0.7, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 2000, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}, {'role': 'assistant', 'content': '–ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}], 'thinking': None, 'web_search_options': None}
2025-07-10 05:54:17,650 - LiteLLM - DEBUG -
LiteLLM: Params passed to completion() {'model': 'gemini-2.0-flash-lite', 'functions': None, 'function_call': None, 'temperature': 0.7, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 2000, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}, {'role': 'assistant', 'content': '–ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}], 'thinking': None, 'web_search_options': None}
‚Üê[92m05:54:17 - LiteLLM:DEBUG‚Üê[0m: utils.py:3125 -
LiteLLM: Non-Default params passed to completion() {'temperature': 0.7, 'max_tokens': 2000}
2025-07-10 05:54:17,658 - LiteLLM - DEBUG -
LiteLLM: Non-Default params passed to completion() {'temperature': 0.7, 'max_tokens': 2000}
‚Üê[92m05:54:17 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - Final returned optional params: {'temperature': 0.7, 'max_output_tokens': 2000}
2025-07-10 05:54:17,664 - LiteLLM - DEBUG - Final returned optional params: {'temperature': 0.7, 'max_output_tokens': 2000}
‚Üê[92m05:54:17 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:461 - self.optional_params: {'temperature': 0.7, 'max_tokens': 2000}
2025-07-10 05:54:17,667 - LiteLLM - DEBUG - self.optional_params: {'temperature': 0.7, 'max_tokens': 2000}
‚Üê[92m05:54:17 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
2025-07-10 05:54:17,669 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:54:18 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
2025-07-10 05:54:18,046 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:54:18 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:908 - ‚Üê[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent?key=*****gu0Q \
-H 'Content-Type: ap****on' \
-d '{'contents': [{'role': 'model', 'parts': [{'text': '–ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}, {'text': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}]}, {'role': 'user', 'parts': [{'text': '–ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}]}], 'system_instruction': {'parts': [{'text': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}]}, 'generationConfig': {'temperature': 0.7, 'max_output_tokens': 2000}}'
‚Üê[0m

2025-07-10 05:54:18,048 - LiteLLM - DEBUG - ‚Üê[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent?key=*****gu0Q \
-H 'Content-Type: ap****on' \
-d '{'contents': [{'role': 'model', 'parts': [{'text': '–ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}, {'text': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}]}, {'role': 'user', 'parts': [{'text': '–ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}]}], 'system_instruction': {'parts': [{'text': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}]}, 'generationConfig': {'temperature': 0.7, 'max_output_tokens': 2000}}'
‚Üê[0m

2025-07-10 05:54:18,422 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None
2025-07-10 05:54:18,479 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025732CAB4A0>
2025-07-10 05:54:18,479 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000025732E616D0> server_hostname='generativelanguage.googleapis.com' timeout=600.0
2025-07-10 05:54:18,526 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025732CAB3B0>
2025-07-10 05:54:18,526 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-10 05:54:18,526 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-07-10 05:54:18,526 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-10 05:54:18,526 - httpcore.http11 - DEBUG - send_request_body.complete
2025-07-10 05:54:18,526 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-10 05:54:20,756 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 10 Jul 2025 00:24:12 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=2196'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-10 05:54:20,756 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent?key=AIzaSyD2taiOJ6Z7nLcVQrz_U0ct4G0HlyLgu0Q "HTTP/1.1 200 OK"
2025-07-10 05:54:20,756 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-10 05:54:20,756 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-07-10 05:54:20,761 - httpcore.http11 - DEBUG - response_closed.started
2025-07-10 05:54:20,761 - httpcore.http11 - DEBUG - response_closed.complete
‚Üê[92m05:54:20 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - RAW RESPONSE:
{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. üòä\n"
          }
        ],
        "role": "model"
      },
      "finishReason": "STOP",
      "avgLogprobs": -0.6032215201336405
    }
  ],
  "usageMetadata": {
    "promptTokenCount": 76,
    "candidatesTokenCount": 23,
    "totalTokenCount": 99,
    "promptTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 76
      }
    ],
    "candidatesTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 23
      }
    ]
  },
  "modelVersion": "gemini-2.0-flash-lite",
  "responseId": "KwhvaLSfItq8698P86rXwA8"
}



2025-07-10 05:54:20,761 - LiteLLM - DEBUG - RAW RESPONSE:
{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. üòä\n"
          }
        ],
        "role": "model"
      },
      "finishReason": "STOP",
      "avgLogprobs": -0.6032215201336405
    }
  ],
  "usageMetadata": {
    "promptTokenCount": 76,
    "candidatesTokenCount": 23,
    "totalTokenCount": 99,
    "promptTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 76
      }
    ],
    "candidatesTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 23
      }
    ]
  },
  "modelVersion": "gemini-2.0-flash-lite",
  "responseId": "KwhvaLSfItq8698P86rXwA8"
}



2025-07-10 05:54:20,782 - httpcore.connection - DEBUG - close.started
2025-07-10 05:54:20,785 - httpcore.connection - DEBUG - close.complete
‚Üê[92m05:54:20 - LiteLLM:INFO‚Üê[0m: utils.py:1215 - Wrapper: Completed Call, calling success_handler
2025-07-10 05:54:20,785 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
‚Üê[92m05:54:20 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:1394 - Logging Details LiteLLM-Success Call: Cache_hit=None
2025-07-10 05:54:20,785 - LiteLLM - DEBUG - Logging Details LiteLLM-Success Call: Cache_hit=None
‚Üê[92m05:54:20 - LiteLLM:INFO‚Üê[0m: cost_calculator.py:655 - selected model name for cost calculation: gemini/gemini-2.0-flash-lite
2025-07-10 05:54:20,790 - LiteLLM - INFO - selected model name for cost calculation: gemini/gemini-2.0-flash-lite
‚Üê[92m05:54:20 - LiteLLM:INFO‚Üê[0m: cost_calculator.py:655 - selected model name for cost calculation: gemini/gemini-2.0-flash-lite
2025-07-10 05:54:20,790 - LiteLLM - INFO - selected model name for cost calculation: gemini/gemini-2.0-flash-lite
‚Üê[92m05:54:20 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
2025-07-10 05:54:20,793 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:54:20 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
2025-07-10 05:54:20,793 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:54:20 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
2025-07-10 05:54:20,793 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:54:20 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
2025-07-10 05:54:20,799 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:54:20 - LiteLLM:DEBUG‚Üê[0m: utils.py:4783 - model_info: {'key': 'gemini/gemini-2.0-flash-lite', 'max_tokens': None, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': 7.5e-08, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': True, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': True, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 4000}
2025-07-10 05:54:20,805 - LiteLLM - DEBUG - model_info: {'key': 'gemini/gemini-2.0-flash-lite', 'max_tokens': None, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': 7.5e-08, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': True, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': True, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 4000}
‚Üê[92m05:54:20 - LiteLLM:DEBUG‚Üê[0m: utils.py:4783 - model_info: {'key': 'gemini/gemini-2.0-flash-lite', 'max_tokens': None, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': 7.5e-08, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': True, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': True, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 4000}
2025-07-10 05:54:20,805 - LiteLLM - DEBUG - model_info: {'key': 'gemini/gemini-2.0-flash-lite', 'max_tokens': None, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': 7.5e-08, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': True, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': True, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 4000}
‚Üê[92m05:54:20 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:1131 - response_cost: 1.26e-05
2025-07-10 05:54:20,814 - LiteLLM - DEBUG - response_cost: 1.26e-05
‚Üê[92m05:54:20 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:1131 - response_cost: 1.26e-05
‚úÖ –£—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏ gemini/gemini-2.0-flash-lite2025-07-10 05:54:20,823 - LiteLLM - DEBUG - response_cost: 1.26e-05

‚Üê[92m05:54:20 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'custom_llm_provider': 'vertex_ai'}
2025-07-10 05:54:20,830 - tools.gopiai_integration.smart_delegator - INFO - ‚úÖ –û—Ç–≤–µ—Ç –æ—Ç LLM –ø–æ–ª—É—á–µ–Ω
2025-07-10 05:54:20,830 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'custom_llm_provider': 'vertex_ai'}
‚Üê[92m05:54:20 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
2025-07-10 05:54:20,835 - tools.gopiai_integration.smart_delegator - INFO - ‚è± –ó–∞–ø—Ä–æ—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∑–∞ 6.07 —Å–µ–∫
‚è± –ó–∞–ø—Ä–æ—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∑–∞ 6.10 —Å–µ–∫2025-07-10 05:54:20,835 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}

‚Üê[92m05:54:20 - LiteLLM:DEBUG‚Üê[0m: utils.py:4783 - model_info: {'key': 'gemini/gemini-2.0-flash-lite', 'max_tokens': None, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': 7.5e-08, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': True, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': True, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 4000}
‚úÖ –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω, –¥–ª–∏–Ω–∞: 95 —Å–∏–º–≤–æ–ª–æ–≤2025-07-10 05:54:20,840 - LiteLLM - DEBUG - model_info: {'key': 'gemini/gemini-2.0-flash-lite', 'max_tokens': None, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': 7.5e-08, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': True, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': True, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 4000}

‚Üê[92m05:54:20 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:1423 - Logging Details LiteLLM-Success Call streaming complete
2025-07-10 05:54:20,853 - werkzeug - INFO - 127.0.0.1 - - [10/Jul/2025 05:54:20] "POST /api/process HTTP/1.1" 200 -
2025-07-10 05:54:20,853 - LiteLLM - DEBUG - Logging Details LiteLLM-Success Call streaming complete
‚Üê[92m05:54:20 - LiteLLM:INFO‚Üê[0m: cost_calculator.py:655 - selected model name for cost calculation: gemini/gemini-2.0-flash-lite
2025-07-10 05:54:20,855 - LiteLLM - INFO - selected model name for cost calculation: gemini/gemini-2.0-flash-lite
‚Üê[92m05:54:20 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
2025-07-10 05:54:20,859 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:54:20 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
2025-07-10 05:54:20,861 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:54:20 - LiteLLM:DEBUG‚Üê[0m: utils.py:4783 - model_info: {'key': 'gemini/gemini-2.0-flash-lite', 'max_tokens': None, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': 7.5e-08, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': True, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': True, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 4000}
2025-07-10 05:54:20,861 - LiteLLM - DEBUG - model_info: {'key': 'gemini/gemini-2.0-flash-lite', 'max_tokens': None, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': 7.5e-08, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': True, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': True, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 4000}
‚Üê[92m05:54:20 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:1131 - response_cost: 1.26e-05
2025-07-10 05:54:20,877 - LiteLLM - DEBUG - response_cost: 1.26e-05
‚Üê[92m05:54:20 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'custom_llm_provider': 'vertex_ai'}
2025-07-10 05:54:20,877 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'custom_llm_provider': 'vertex_ai'}
‚Üê[92m05:54:20 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
2025-07-10 05:54:20,882 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:54:20 - LiteLLM:DEBUG‚Üê[0m: utils.py:4783 - model_info: {'key': 'gemini/gemini-2.0-flash-lite', 'max_tokens': None, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': 7.5e-08, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': True, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': True, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 4000}
2025-07-10 05:54:20,885 - LiteLLM - DEBUG - model_info: {'key': 'gemini/gemini-2.0-flash-lite', 'max_tokens': None, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': 7.5e-08, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': True, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': True, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 4000}
2025-07-10 05:55:03,187 - werkzeug - INFO - 127.0.0.1 - - [10/Jul/2025 05:55:03] "GET /api/health HTTP/1.1" 200 -
üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: —Å–ª–æ–∂–Ω–æ—Å—Ç—å=0, —Ç–∏–ø=general, CrewAI=False
üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: —Å–ª–æ–∂–Ω–æ—Å—Ç—å=0, —Ç–∏–ø=general, CrewAI=False
üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: —Å–ª–æ–∂–Ω–æ—Å—Ç—å=0, —Ç–∏–ø=general, CrewAI=False
üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: —Å–ª–æ–∂–Ω–æ—Å—Ç—å=0, —Ç–∏–ø=general, CrewAI=False
2025-07-10 05:55:03,203 - tools.gopiai_integration.smart_delegator - INFO - üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ AI Router...
2025-07-10 05:55:03,203 - tools.gopiai_integration.smart_delegator - INFO - ‚úÖ AI Router –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã
2025-07-10 05:55:03,205 - tools.gopiai_integration.smart_delegator - INFO - –ó–∞–≥—Ä—É–∂–µ–Ω–æ 5 —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞
2025-07-10 05:55:03,205 - tools.gopiai_integration.smart_delegator - INFO - üöÄ –í—ã–∑–æ–≤ LLM —Å –∏—Å—Ç–æ—Ä–∏–µ–π —á–∞—Ç–∞...
2025-07-10 05:55:03,205 - tools.gopiai_integration.smart_delegator - DEBUG - –û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ LLM: [
  {
    "role": "system",
    "content": "–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç."
  },
  {
    "role": "assistant",
    "content": "‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å..."
  },
  {
    "role": "assistant",
    "content": "–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. üòä"
  },
  {
    "role": "assistant",
    "content": "–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. üòä"
  },
  {
    "role": "assistant",
    "content": "–Ω–µ–µ–µ–µ—ÇüòÑ –ü–æ–¥—É–º–∞–π –µ—â–µ, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –≤—Å–ø–æ–º–Ω–∏—Ç—å"
  },
  {
    "role": "assistant",
    "content": "‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å..."
  },
  {
    "role": "user",
    "content": "–Ω–µ–µ–µ–µ—ÇüòÑ –ü–æ–¥—É–º–∞–π –µ—â–µ, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –≤—Å–ø–æ–º–Ω–∏—Ç—å"
  }
]
[AVAILABLE] –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è 'dialog': ['gemini/gemini-1.5-flash', 'gemini/gemini-2.0-flash-lite', 'gemini/gemini-2.5-flash-lite-preview', 'gemini/gemini-2.5-flash']
[CHECK] –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏ gemini/gemini-1.5-flash —Å 184 —Ç–æ–∫–µ–Ω–∞–º–∏...
[STATS] –ú–æ–¥–µ–ª—å gemini/gemini-1.5-flash: —Ç–µ–∫—É—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ RPM=1/15, TPM=124/250000, RPD=1/50
[OK] –ú–æ–¥–µ–ª—å gemini/gemini-1.5-flash: RPM_OK=True, TPM_OK=True, RPD_OK=True -> RESULT=True
[SELECTED] AI Router: –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å 'gemini/gemini-1.5-flash' (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 3)
2025-07-10 05:55:03,224 - tools.gopiai_integration.smart_delegator - INFO - –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: gemini/gemini-1.5-flash
[AVAILABLE] –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è 'dialog': ['gemini/gemini-1.5-flash', 'gemini/gemini-2.0-flash-lite', 'gemini/gemini-2.5-flash-lite-preview', 'gemini/gemini-2.5-flash']
[CHECK] –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏ gemini/gemini-1.5-flash —Å 184 —Ç–æ–∫–µ–Ω–∞–º–∏...
[STATS] –ú–æ–¥–µ–ª—å gemini/gemini-1.5-flash: —Ç–µ–∫—É—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ RPM=1/15, TPM=124/250000, RPD=1/50
[OK] –ú–æ–¥–µ–ª—å gemini/gemini-1.5-flash: RPM_OK=True, TPM_OK=True, RPD_OK=True -> RESULT=True
[SELECTED] AI Router: –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å 'gemini/gemini-1.5-flash' (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 3)
üîÑ –ü–æ–ø—ã—Ç–∫–∞ 1: –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å gemini/gemini-1.5-flash
‚Üê[92m05:55:03 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 -

2025-07-10 05:55:03,229 - LiteLLM - DEBUG -

‚Üê[92m05:55:03 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - ‚Üê[92mRequest to litellm:‚Üê[0m
2025-07-10 05:55:03,229 - LiteLLM - DEBUG - ‚Üê[92mRequest to litellm:‚Üê[0m
‚Üê[92m05:55:03 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - ‚Üê[92mlitellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'assistant', 'content': '–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. üòä'}, {'role': 'assistant', 'content': '–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. üòä'}, {'role': 'assistant', 'content': '–Ω–µ–µ–µ–µ—ÇüòÑ –ü–æ–¥—É–º–∞–π –µ—â–µ, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –≤—Å–ø–æ–º–Ω–∏—Ç—å'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–Ω–µ–µ–µ–µ—ÇüòÑ –ü–æ–¥—É–º–∞–π –µ—â–µ, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –≤—Å–ø–æ–º–Ω–∏—Ç—å'}], temperature=0.7, max_tokens=2000)‚Üê[0m
2025-07-10 05:55:03,229 - LiteLLM - DEBUG - ‚Üê[92mlitellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'assistant', 'content': '–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. üòä'}, {'role': 'assistant', 'content': '–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. üòä'}, {'role': 'assistant', 'content': '–Ω–µ–µ–µ–µ—ÇüòÑ –ü–æ–¥—É–º–∞–π –µ—â–µ, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –≤—Å–ø–æ–º–Ω–∏—Ç—å'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–Ω–µ–µ–µ–µ—ÇüòÑ –ü–æ–¥—É–º–∞–π –µ—â–µ, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –≤—Å–ø–æ–º–Ω–∏—Ç—å'}], temperature=0.7, max_tokens=2000)‚Üê[0m
‚Üê[92m05:55:03 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 -

2025-07-10 05:55:03,235 - LiteLLM - DEBUG -

‚Üê[92m05:55:03 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:461 - self.optional_params: {}
2025-07-10 05:55:03,235 - LiteLLM - DEBUG - self.optional_params: {}
‚Üê[92m05:55:03 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-07-10 05:55:03,235 - LiteLLM - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
‚Üê[92m05:55:03 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
2025-07-10 05:55:03,250 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
‚Üê[92m05:55:03 - LiteLLM:INFO‚Üê[0m: utils.py:3119 -
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-07-10 05:55:03,253 - LiteLLM - INFO -
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
‚Üê[92m05:55:03 - LiteLLM:DEBUG‚Üê[0m: utils.py:3122 -
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.7, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 2000, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'assistant', 'content': '–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. üòä'}, {'role': 'assistant', 'content': '–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. üòä'}, {'role': 'assistant', 'content': '–Ω–µ–µ–µ–µ—ÇüòÑ –ü–æ–¥—É–º–∞–π –µ—â–µ, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –≤—Å–ø–æ–º–Ω–∏—Ç—å'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–Ω–µ–µ–µ–µ—ÇüòÑ –ü–æ–¥—É–º–∞–π –µ—â–µ, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –≤—Å–ø–æ–º–Ω–∏—Ç—å'}], 'thinking': None, 'web_search_options': None}
2025-07-10 05:55:03,255 - LiteLLM - DEBUG -
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.7, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 2000, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'assistant', 'content': '–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. üòä'}, {'role': 'assistant', 'content': '–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. üòä'}, {'role': 'assistant', 'content': '–Ω–µ–µ–µ–µ—ÇüòÑ –ü–æ–¥—É–º–∞–π –µ—â–µ, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –≤—Å–ø–æ–º–Ω–∏—Ç—å'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–Ω–µ–µ–µ–µ—ÇüòÑ –ü–æ–¥—É–º–∞–π –µ—â–µ, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –≤—Å–ø–æ–º–Ω–∏—Ç—å'}], 'thinking': None, 'web_search_options': None}
‚Üê[92m05:55:03 - LiteLLM:DEBUG‚Üê[0m: utils.py:3125 -
LiteLLM: Non-Default params passed to completion() {'temperature': 0.7, 'max_tokens': 2000}
2025-07-10 05:55:03,263 - LiteLLM - DEBUG -
LiteLLM: Non-Default params passed to completion() {'temperature': 0.7, 'max_tokens': 2000}
‚Üê[92m05:55:03 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - Final returned optional params: {'temperature': 0.7, 'max_output_tokens': 2000}
2025-07-10 05:55:03,263 - LiteLLM - DEBUG - Final returned optional params: {'temperature': 0.7, 'max_output_tokens': 2000}
‚Üê[92m05:55:03 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:461 - self.optional_params: {'temperature': 0.7, 'max_tokens': 2000}
2025-07-10 05:55:03,272 - LiteLLM - DEBUG - self.optional_params: {'temperature': 0.7, 'max_tokens': 2000}
‚Üê[92m05:55:03 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:55:03,273 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:55:03 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:55:03,635 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:55:03 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:908 - ‚Üê[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****gu0Q \
-H 'Content-Type: ap****on' \
-d '{'contents': [{'role': 'model', 'parts': [{'text': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'text': '–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. üòä'}, {'text': '–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. üòä'}, {'text': '–Ω–µ–µ–µ–µ—ÇüòÑ –ü–æ–¥—É–º–∞–π –µ—â–µ, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –≤—Å–ø–æ–º–Ω–∏—Ç—å'}, {'text': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}]}, {'role': 'user', 'parts': [{'text': '–Ω–µ–µ–µ–µ—ÇüòÑ –ü–æ–¥—É–º–∞–π –µ—â–µ, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –≤—Å–ø–æ–º–Ω–∏—Ç—å'}]}], 'system_instruction': {'parts': [{'text': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}]}, 'generationConfig': {'temperature': 0.7, 'max_output_tokens': 2000}}'
‚Üê[0m

2025-07-10 05:55:03,641 - LiteLLM - DEBUG - ‚Üê[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****gu0Q \
-H 'Content-Type: ap****on' \
-d '{'contents': [{'role': 'model', 'parts': [{'text': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'text': '–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. üòä'}, {'text': '–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. üòä'}, {'text': '–Ω–µ–µ–µ–µ—ÇüòÑ –ü–æ–¥—É–º–∞–π –µ—â–µ, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –≤—Å–ø–æ–º–Ω–∏—Ç—å'}, {'text': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}]}, {'role': 'user', 'parts': [{'text': '–Ω–µ–µ–µ–µ—ÇüòÑ –ü–æ–¥—É–º–∞–π –µ—â–µ, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –≤—Å–ø–æ–º–Ω–∏—Ç—å'}]}], 'system_instruction': {'parts': [{'text': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}]}, 'generationConfig': {'temperature': 0.7, 'max_output_tokens': 2000}}'
‚Üê[0m

2025-07-10 05:55:04,006 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None
2025-07-10 05:55:04,035 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025732CCC8F0>
2025-07-10 05:55:04,046 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000025732E753D0> server_hostname='generativelanguage.googleapis.com' timeout=600.0
2025-07-10 05:55:04,085 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025732CCC860>
2025-07-10 05:55:04,085 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-10 05:55:04,085 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-07-10 05:55:04,085 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-10 05:55:04,085 - httpcore.http11 - DEBUG - send_request_body.complete
2025-07-10 05:55:04,093 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-10 05:55:09,296 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 503, b'Service Unavailable', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 10 Jul 2025 00:25:00 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=5176'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-10 05:55:09,298 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyD2taiOJ6Z7nLcVQrz_U0ct4G0HlyLgu0Q "HTTP/1.1 503 Service Unavailable"
2025-07-10 05:55:09,301 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-10 05:55:09,302 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-07-10 05:55:09,302 - httpcore.http11 - DEBUG - response_closed.started
2025-07-10 05:55:09,302 - httpcore.http11 - DEBUG - response_closed.complete




‚Üê[92m05:55:09 - LiteLLM:DEBUG‚Üê[0m: exception_mapping_utils.py:2300 - Logging Details: logger_fn - None | callable(logger_fn) - False
2025-07-10 05:55:09,305 - LiteLLM - DEBUG - Logging Details: logger_fn - None | callable(logger_fn) - False
‚Üê[92m05:55:09 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:2216 - Logging Details LiteLLM-Failure Call: []
2025-07-10 05:55:09,314 - LiteLLM - DEBUG - Logging Details LiteLLM-Failure Call: []
2025-07-10 05:55:09,320 - tools.gopiai_integration.smart_delegator - ERROR - –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ –º–æ–¥–µ–ª–∏ gemini/gemini-1.5-flash: litellm.InternalServerError: litellm.InternalServerError: VertexAIException - {
  "error": {
    "code": 503,
    "message": "The model is overloaded. Please try again later.",
    "status": "UNAVAILABLE"
  }
}


[AVAILABLE] –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è 'dialog': ['gemini/gemini-2.0-flash-lite', 'gemini/gemini-2.5-flash-lite-preview', 'gemini/gemini-2.5-flash']
[CHECK] –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏ gemini/gemini-2.0-flash-lite —Å 184 —Ç–æ–∫–µ–Ω–∞–º–∏...
[STATS] –ú–æ–¥–µ–ª—å gemini/gemini-2.0-flash-lite: —Ç–µ–∫—É—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ RPM=1/30, TPM=124/1000000, RPD=1/200
[OK] –ú–æ–¥–µ–ª—å gemini/gemini-2.0-flash-lite: RPM_OK=True, TPM_OK=True, RPD_OK=True -> RESULT=True
[SELECTED] AI Router: –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å 'gemini/gemini-2.0-flash-lite' (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 4)
üîÑ –ü–æ–ø—ã—Ç–∫–∞ 2: –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å gemini/gemini-2.0-flash-lite
‚Üê[92m05:55:09 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 -

2025-07-10 05:55:09,328 - LiteLLM - DEBUG -

‚Üê[92m05:55:09 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - ‚Üê[92mRequest to litellm:‚Üê[0m
2025-07-10 05:55:09,330 - LiteLLM - DEBUG - ‚Üê[92mRequest to litellm:‚Üê[0m
‚Üê[92m05:55:09 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - ‚Üê[92mlitellm.completion(model='gemini/gemini-2.0-flash-lite', messages=[{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'assistant', 'content': '–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. üòä'}, {'role': 'assistant', 'content': '–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. üòä'}, {'role': 'assistant', 'content': '–Ω–µ–µ–µ–µ—ÇüòÑ –ü–æ–¥—É–º–∞–π –µ—â–µ, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –≤—Å–ø–æ–º–Ω–∏—Ç—å'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–Ω–µ–µ–µ–µ—ÇüòÑ –ü–æ–¥—É–º–∞–π –µ—â–µ, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –≤—Å–ø–æ–º–Ω–∏—Ç—å'}], temperature=0.7, max_tokens=2000)‚Üê[0m
2025-07-10 05:55:09,333 - LiteLLM - DEBUG - ‚Üê[92mlitellm.completion(model='gemini/gemini-2.0-flash-lite', messages=[{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'assistant', 'content': '–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. üòä'}, {'role': 'assistant', 'content': '–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. üòä'}, {'role': 'assistant', 'content': '–Ω–µ–µ–µ–µ—ÇüòÑ –ü–æ–¥—É–º–∞–π –µ—â–µ, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –≤—Å–ø–æ–º–Ω–∏—Ç—å'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–Ω–µ–µ–µ–µ—ÇüòÑ –ü–æ–¥—É–º–∞–π –µ—â–µ, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –≤—Å–ø–æ–º–Ω–∏—Ç—å'}], temperature=0.7, max_tokens=2000)‚Üê[0m
‚Üê[92m05:55:09 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 -

2025-07-10 05:55:09,339 - LiteLLM - DEBUG -

‚Üê[92m05:55:09 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:461 - self.optional_params: {}
2025-07-10 05:55:09,341 - LiteLLM - DEBUG - self.optional_params: {}
‚Üê[92m05:55:09 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-07-10 05:55:09,348 - LiteLLM - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
‚Üê[92m05:55:09 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'custom_llm_provider': 'vertex_ai'}
2025-07-10 05:55:09,351 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'custom_llm_provider': 'vertex_ai'}
‚Üê[92m05:55:09 - LiteLLM:INFO‚Üê[0m: utils.py:3119 -
LiteLLM completion() model= gemini-2.0-flash-lite; provider = gemini
2025-07-10 05:55:09,353 - LiteLLM - INFO -
LiteLLM completion() model= gemini-2.0-flash-lite; provider = gemini
‚Üê[92m05:55:09 - LiteLLM:DEBUG‚Üê[0m: utils.py:3122 -
LiteLLM: Params passed to completion() {'model': 'gemini-2.0-flash-lite', 'functions': None, 'function_call': None, 'temperature': 0.7, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 2000, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'assistant', 'content': '–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. üòä'}, {'role': 'assistant', 'content': '–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. üòä'}, {'role': 'assistant', 'content': '–Ω–µ–µ–µ–µ—ÇüòÑ –ü–æ–¥—É–º–∞–π –µ—â–µ, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –≤—Å–ø–æ–º–Ω–∏—Ç—å'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–Ω–µ–µ–µ–µ—ÇüòÑ –ü–æ–¥—É–º–∞–π –µ—â–µ, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –≤—Å–ø–æ–º–Ω–∏—Ç—å'}], 'thinking': None, 'web_search_options': None}
2025-07-10 05:55:09,357 - LiteLLM - DEBUG -
LiteLLM: Params passed to completion() {'model': 'gemini-2.0-flash-lite', 'functions': None, 'function_call': None, 'temperature': 0.7, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 2000, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'assistant', 'content': '–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. üòä'}, {'role': 'assistant', 'content': '–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. üòä'}, {'role': 'assistant', 'content': '–Ω–µ–µ–µ–µ—ÇüòÑ –ü–æ–¥—É–º–∞–π –µ—â–µ, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –≤—Å–ø–æ–º–Ω–∏—Ç—å'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–Ω–µ–µ–µ–µ—ÇüòÑ –ü–æ–¥—É–º–∞–π –µ—â–µ, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –≤—Å–ø–æ–º–Ω–∏—Ç—å'}], 'thinking': None, 'web_search_options': None}
‚Üê[92m05:55:09 - LiteLLM:DEBUG‚Üê[0m: utils.py:3125 -
LiteLLM: Non-Default params passed to completion() {'temperature': 0.7, 'max_tokens': 2000}
2025-07-10 05:55:09,366 - LiteLLM - DEBUG -
LiteLLM: Non-Default params passed to completion() {'temperature': 0.7, 'max_tokens': 2000}
‚Üê[92m05:55:09 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - Final returned optional params: {'temperature': 0.7, 'max_output_tokens': 2000}
2025-07-10 05:55:09,369 - LiteLLM - DEBUG - Final returned optional params: {'temperature': 0.7, 'max_output_tokens': 2000}
‚Üê[92m05:55:09 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:461 - self.optional_params: {'temperature': 0.7, 'max_tokens': 2000}
2025-07-10 05:55:09,372 - LiteLLM - DEBUG - self.optional_params: {'temperature': 0.7, 'max_tokens': 2000}
‚Üê[92m05:55:09 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
2025-07-10 05:55:09,379 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:55:09 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
2025-07-10 05:55:09,740 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:55:09 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:908 - ‚Üê[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent?key=*****gu0Q \
-H 'Content-Type: ap****on' \
-d '{'contents': [{'role': 'model', 'parts': [{'text': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'text': '–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. üòä'}, {'text': '–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. üòä'}, {'text': '–Ω–µ–µ–µ–µ—ÇüòÑ –ü–æ–¥—É–º–∞–π –µ—â–µ, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –≤—Å–ø–æ–º–Ω–∏—Ç—å'}, {'text': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}]}, {'role': 'user', 'parts': [{'text': '–Ω–µ–µ–µ–µ—ÇüòÑ –ü–æ–¥—É–º–∞–π –µ—â–µ, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –≤—Å–ø–æ–º–Ω–∏—Ç—å'}]}], 'system_instruction': {'parts': [{'text': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}]}, 'generationConfig': {'temperature': 0.7, 'max_output_tokens': 2000}}'
‚Üê[0m

2025-07-10 05:55:09,745 - LiteLLM - DEBUG - ‚Üê[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent?key=*****gu0Q \
-H 'Content-Type: ap****on' \
-d '{'contents': [{'role': 'model', 'parts': [{'text': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'text': '–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. üòä'}, {'text': '–ü—Ä–∏–≤–µ—Ç! –î–∞, —è –ø–æ–º–Ω—é! –¢—ã –Ω–∞–∑—ã–≤–∞–ª–∞ –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –ª–µ–≥–∫–æ –∑–∞–±—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. üòä'}, {'text': '–Ω–µ–µ–µ–µ—ÇüòÑ –ü–æ–¥—É–º–∞–π –µ—â–µ, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –≤—Å–ø–æ–º–Ω–∏—Ç—å'}, {'text': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}]}, {'role': 'user', 'parts': [{'text': '–Ω–µ–µ–µ–µ—ÇüòÑ –ü–æ–¥—É–º–∞–π –µ—â–µ, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –≤—Å–ø–æ–º–Ω–∏—Ç—å'}]}], 'system_instruction': {'parts': [{'text': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}]}, 'generationConfig': {'temperature': 0.7, 'max_output_tokens': 2000}}'
‚Üê[0m

2025-07-10 05:55:10,110 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None
2025-07-10 05:55:10,145 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025732CCE300>
2025-07-10 05:55:10,147 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000025732E76BD0> server_hostname='generativelanguage.googleapis.com' timeout=600.0
2025-07-10 05:55:10,188 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025732CCE1B0>
2025-07-10 05:55:10,189 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-10 05:55:10,190 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-07-10 05:55:10,191 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-10 05:55:10,192 - httpcore.http11 - DEBUG - send_request_body.complete
2025-07-10 05:55:10,192 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-10 05:55:12,837 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 10 Jul 2025 00:25:04 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=2614'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-10 05:55:12,837 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent?key=AIzaSyD2taiOJ6Z7nLcVQrz_U0ct4G0HlyLgu0Q "HTTP/1.1 200 OK"
2025-07-10 05:55:12,848 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-10 05:55:12,849 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-07-10 05:55:12,849 - httpcore.http11 - DEBUG - response_closed.started
2025-07-10 05:55:12,849 - httpcore.http11 - DEBUG - response_closed.complete
‚Üê[92m05:55:12 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - RAW RESPONSE:
{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å... –•–æ—Ä–æ—à–æ, –¥–∞–≤–∞–π –ø–æ–ø—Ä–æ–±—É–µ–º –µ—â—ë —Ä–∞–∑! ü§î –¢—ã –≥–æ–≤–æ—Ä–∏–ª–∞ –ø—Ä–æ —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π... —ç—ç—ç... —á—Ç–æ-—Ç–æ —Å–≤—è–∑–∞–Ω–Ω–æ–µ —Å —Ä—ã–±–∞–º–∏... –ú–æ–∂–µ—Ç –±—ã—Ç—å, –æ–Ω –ª—é–±–∏—Ç —Ä—ã–±—É? –ò–ª–∏ —É –Ω–µ–≥–æ –µ—Å—Ç—å –∞–∫–≤–∞—Ä–∏—É–º? –ò–ª–∏... –æ–Ω –∫–∞–∫-—Ç–æ —Å–≤—è–∑–∞–Ω —Å –º–æ—Ä–µ–º? –î–∞–≤–∞–π, –ø–æ–¥—Å–∫–∞–∑—ã–≤–∞–π! üòÑ\n"
          }
        ],
        "role": "model"
      },
      "finishReason": "STOP",
      "avgLogprobs": -0.60282678473485662
    }
  ],
  "usageMetadata": {
    "promptTokenCount": 99,
    "candidatesTokenCount": 73,
    "totalTokenCount": 172,
    "promptTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 99
      }
    ],
    "candidatesTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 73
      }
    ]
  },
  "modelVersion": "gemini-2.0-flash-lite",
  "responseId": "XwhvaP22CaCW2PgPrZCawA0"
}



2025-07-10 05:55:12,849 - LiteLLM - DEBUG - RAW RESPONSE:
{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å... –•–æ—Ä–æ—à–æ, –¥–∞–≤–∞–π –ø–æ–ø—Ä–æ–±—É–µ–º –µ—â—ë —Ä–∞–∑! ü§î –¢—ã –≥–æ–≤–æ—Ä–∏–ª–∞ –ø—Ä–æ —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π... —ç—ç—ç... —á—Ç–æ-—Ç–æ —Å–≤—è–∑–∞–Ω–Ω–æ–µ —Å —Ä—ã–±–∞–º–∏... –ú–æ–∂–µ—Ç –±—ã—Ç—å, –æ–Ω –ª—é–±–∏—Ç —Ä—ã–±—É? –ò–ª–∏ —É –Ω–µ–≥–æ –µ—Å—Ç—å –∞–∫–≤–∞—Ä–∏—É–º? –ò–ª–∏... –æ–Ω –∫–∞–∫-—Ç–æ —Å–≤—è–∑–∞–Ω —Å –º–æ—Ä–µ–º? –î–∞–≤–∞–π, –ø–æ–¥—Å–∫–∞–∑—ã–≤–∞–π! üòÑ\n"
          }
        ],
        "role": "model"
      },
      "finishReason": "STOP",
      "avgLogprobs": -0.60282678473485662
    }
  ],
  "usageMetadata": {
    "promptTokenCount": 99,
    "candidatesTokenCount": 73,
    "totalTokenCount": 172,
    "promptTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 99
      }
    ],
    "candidatesTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 73
      }
    ]
  },
  "modelVersion": "gemini-2.0-flash-lite",
  "responseId": "XwhvaP22CaCW2PgPrZCawA0"
}



2025-07-10 05:55:12,873 - httpcore.connection - DEBUG - close.started
2025-07-10 05:55:12,873 - httpcore.connection - DEBUG - close.complete
‚Üê[92m05:55:12 - LiteLLM:INFO‚Üê[0m: utils.py:1215 - Wrapper: Completed Call, calling success_handler
2025-07-10 05:55:12,873 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
‚Üê[92m05:55:12 - LiteLLM:INFO‚Üê[0m: cost_calculator.py:655 - selected model name for cost calculation: gemini/gemini-2.0-flash-lite
2025-07-10 05:55:12,873 - LiteLLM - INFO - selected model name for cost calculation: gemini/gemini-2.0-flash-lite
‚Üê[92m05:55:12 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:1394 - Logging Details LiteLLM-Success Call: Cache_hit=None
2025-07-10 05:55:12,873 - LiteLLM - DEBUG - Logging Details LiteLLM-Success Call: Cache_hit=None
‚Üê[92m05:55:12 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
2025-07-10 05:55:12,884 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:55:12 - LiteLLM:INFO‚Üê[0m: cost_calculator.py:655 - selected model name for cost calculation: gemini/gemini-2.0-flash-lite
2025-07-10 05:55:12,885 - LiteLLM - INFO - selected model name for cost calculation: gemini/gemini-2.0-flash-lite
‚Üê[92m05:55:12 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
2025-07-10 05:55:12,885 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:55:12 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
2025-07-10 05:55:12,885 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:55:12 - LiteLLM:DEBUG‚Üê[0m: utils.py:4783 - model_info: {'key': 'gemini/gemini-2.0-flash-lite', 'max_tokens': None, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': 7.5e-08, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': True, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': True, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 4000}
2025-07-10 05:55:12,885 - LiteLLM - DEBUG - model_info: {'key': 'gemini/gemini-2.0-flash-lite', 'max_tokens': None, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': 7.5e-08, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': True, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': True, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 4000}
‚Üê[92m05:55:12 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
2025-07-10 05:55:12,885 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:55:12 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:1131 - response_cost: 2.9325e-05
2025-07-10 05:55:12,905 - LiteLLM - DEBUG - response_cost: 2.9325e-05
‚Üê[92m05:55:12 - LiteLLM:DEBUG‚Üê[0m: utils.py:4783 - model_info: {'key': 'gemini/gemini-2.0-flash-lite', 'max_tokens': None, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': 7.5e-08, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': True, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': True, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 4000}
‚úÖ –£—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏ gemini/gemini-2.0-flash-lite2025-07-10 05:55:12,905 - LiteLLM - DEBUG - model_info: {'key': 'gemini/gemini-2.0-flash-lite', 'max_tokens': None, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': 7.5e-08, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': True, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': True, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 4000}

‚Üê[92m05:55:12 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:1131 - response_cost: 2.9325e-05
2025-07-10 05:55:12,923 - tools.gopiai_integration.smart_delegator - INFO - ‚úÖ –û—Ç–≤–µ—Ç –æ—Ç LLM –ø–æ–ª—É—á–µ–Ω
2025-07-10 05:55:12,923 - LiteLLM - DEBUG - response_cost: 2.9325e-05
2025-07-10 05:55:12,923 - tools.gopiai_integration.smart_delegator - INFO - ‚è± –ó–∞–ø—Ä–æ—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∑–∞ 9.72 —Å–µ–∫
‚Üê[92m05:55:12 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'custom_llm_provider': 'vertex_ai'}
‚è± –ó–∞–ø—Ä–æ—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∑–∞ 9.72 —Å–µ–∫2025-07-10 05:55:12,923 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'custom_llm_provider': 'vertex_ai'}

‚Üê[92m05:55:12 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
‚úÖ –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω, –¥–ª–∏–Ω–∞: 240 —Å–∏–º–≤–æ–ª–æ–≤2025-07-10 05:55:12,935 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}

‚Üê[92m05:55:12 - LiteLLM:DEBUG‚Üê[0m: utils.py:4783 - model_info: {'key': 'gemini/gemini-2.0-flash-lite', 'max_tokens': None, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': 7.5e-08, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': True, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': True, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 4000}
2025-07-10 05:55:12,935 - werkzeug - INFO - 127.0.0.1 - - [10/Jul/2025 05:55:12] "POST /api/process HTTP/1.1" 200 -
2025-07-10 05:55:12,935 - LiteLLM - DEBUG - model_info: {'key': 'gemini/gemini-2.0-flash-lite', 'max_tokens': None, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': 7.5e-08, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': True, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': True, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 4000}
‚Üê[92m05:55:12 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:1423 - Logging Details LiteLLM-Success Call streaming complete
2025-07-10 05:55:12,954 - LiteLLM - DEBUG - Logging Details LiteLLM-Success Call streaming complete
‚Üê[92m05:55:12 - LiteLLM:INFO‚Üê[0m: cost_calculator.py:655 - selected model name for cost calculation: gemini/gemini-2.0-flash-lite
2025-07-10 05:55:12,955 - LiteLLM - INFO - selected model name for cost calculation: gemini/gemini-2.0-flash-lite
‚Üê[92m05:55:12 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
2025-07-10 05:55:12,955 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:55:12 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
2025-07-10 05:55:12,961 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:55:12 - LiteLLM:DEBUG‚Üê[0m: utils.py:4783 - model_info: {'key': 'gemini/gemini-2.0-flash-lite', 'max_tokens': None, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': 7.5e-08, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': True, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': True, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 4000}
2025-07-10 05:55:12,964 - LiteLLM - DEBUG - model_info: {'key': 'gemini/gemini-2.0-flash-lite', 'max_tokens': None, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': 7.5e-08, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': True, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': True, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 4000}
‚Üê[92m05:55:12 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:1131 - response_cost: 2.9325e-05
2025-07-10 05:55:12,973 - LiteLLM - DEBUG - response_cost: 2.9325e-05
‚Üê[92m05:55:12 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'custom_llm_provider': 'vertex_ai'}
2025-07-10 05:55:12,977 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'vertex_ai/gemini-2.0-flash-lite', 'custom_llm_provider': 'vertex_ai'}
‚Üê[92m05:55:12 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
2025-07-10 05:55:12,982 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-2.0-flash-lite', 'combined_model_name': 'gemini/gemini-2.0-flash-lite', 'stripped_model_name': 'gemini-2.0-flash-lite', 'combined_stripped_model_name': 'gemini/gemini-2.0-flash-lite', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:55:12 - LiteLLM:DEBUG‚Üê[0m: utils.py:4783 - model_info: {'key': 'gemini/gemini-2.0-flash-lite', 'max_tokens': None, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': 7.5e-08, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': True, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': True, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 4000}
2025-07-10 05:55:12,985 - LiteLLM - DEBUG - model_info: {'key': 'gemini/gemini-2.0-flash-lite', 'max_tokens': None, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': 7.5e-08, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': True, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': True, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 4000}
2025-07-10 05:56:01,169 - werkzeug - INFO - 127.0.0.1 - - [10/Jul/2025 05:56:01] "GET /api/health HTTP/1.1" 200 -
üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: —Å–ª–æ–∂–Ω–æ—Å—Ç—å=0, —Ç–∏–ø=general, CrewAI=False
üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: —Å–ª–æ–∂–Ω–æ—Å—Ç—å=0, —Ç–∏–ø=general, CrewAI=False
üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: —Å–ª–æ–∂–Ω–æ—Å—Ç—å=0, —Ç–∏–ø=general, CrewAI=False
üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: —Å–ª–æ–∂–Ω–æ—Å—Ç—å=0, —Ç–∏–ø=general, CrewAI=False
2025-07-10 05:56:01,344 - tools.gopiai_integration.smart_delegator - INFO - üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ AI Router...
2025-07-10 05:56:01,344 - tools.gopiai_integration.smart_delegator - INFO - ‚úÖ AI Router –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã
2025-07-10 05:56:01,349 - httpcore.connection - DEBUG - close.started
2025-07-10 05:56:01,349 - httpcore.connection - DEBUG - close.complete
2025-07-10 05:56:01,356 - tools.gopiai_integration.smart_delegator - INFO - –ó–∞–≥—Ä—É–∂–µ–Ω–æ 5 —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞
2025-07-10 05:56:01,356 - tools.gopiai_integration.smart_delegator - INFO - üöÄ –í—ã–∑–æ–≤ LLM —Å –∏—Å—Ç–æ—Ä–∏–µ–π —á–∞—Ç–∞...
2025-07-10 05:56:01,356 - tools.gopiai_integration.smart_delegator - DEBUG - –û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ LLM: [
  {
    "role": "system",
    "content": "–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç."
  },
  {
    "role": "assistant",
    "content": "‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å..."
  },
  {
    "role": "assistant",
    "content": "‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å... –•–æ—Ä–æ—à–æ, –¥–∞–≤–∞–π –ø–æ–ø—Ä–æ–±—É–µ–º –µ—â—ë —Ä–∞–∑! ü§î –¢—ã –≥–æ–≤–æ—Ä–∏–ª–∞ –ø—Ä–æ —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π... —ç—ç—ç... —á—Ç–æ-—Ç–æ —Å–≤—è–∑–∞–Ω–Ω–æ–µ —Å —Ä—ã–±–∞–º–∏... –ú–æ–∂–µ—Ç –±—ã—Ç—å, –æ–Ω –ª—é–±–∏—Ç —Ä—ã–±—É? –ò–ª–∏ —É –Ω–µ–≥–æ –µ—Å—Ç—å –∞–∫–≤–∞—Ä–∏—É–º? –ò–ª–∏... –æ–Ω –∫–∞–∫-—Ç–æ —Å–≤—è–∑–∞–Ω —Å –º–æ—Ä–µ–º? –î–∞–≤–∞–π, –ø–æ–¥—Å–∫–∞–∑—ã–≤–∞–π! üòÑ"
  },
  {
    "role": "assistant",
    "content": "‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å... –•–æ—Ä–æ—à–æ, –¥–∞–≤–∞–π –ø–æ–ø—Ä–æ–±—É–µ–º –µ—â—ë —Ä–∞–∑! ü§î –¢—ã –≥–æ–≤–æ—Ä–∏–ª–∞ –ø—Ä–æ —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π... —ç—ç—ç... —á—Ç–æ-—Ç–æ —Å–≤—è–∑–∞–Ω–Ω–æ–µ —Å —Ä—ã–±–∞–º–∏... –ú–æ–∂–µ—Ç –±—ã—Ç—å, –æ–Ω –ª—é–±–∏—Ç —Ä—ã–±—É? –ò–ª–∏ —É –Ω–µ–≥–æ –µ—Å—Ç—å –∞–∫–≤–∞—Ä–∏—É–º? –ò–ª–∏... –æ–Ω –∫–∞–∫-—Ç–æ —Å–≤—è–∑–∞–Ω —Å –º–æ—Ä–µ–º? –î–∞–≤–∞–π, –ø–æ–¥—Å–∫–∞–∑—ã–≤–∞–π! üòÑ"
  },
  {
    "role": "assistant",
    "content": "–ù—É, –Ω–µ–µ–µ–µ—Ç ü§£ –ò —Å —á–µ–≥–æ —Ç—ã –≤–∑—è–ª–∞, —á—Ç–æ —ç—Ç–æ —á–µ–ª–æ–≤–µ–∫?"
  },
  {
    "role": "assistant",
    "content": "‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å..."
  },
  {
    "role": "user",
    "content": "–ù—É, –Ω–µ–µ–µ–µ—Ç ü§£ –ò —Å —á–µ–≥–æ —Ç—ã –≤–∑—è–ª–∞, —á—Ç–æ —ç—Ç–æ —á–µ–ª–æ–≤–µ–∫?"
  }
]
[AVAILABLE] –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è 'dialog': ['gemini/gemini-1.5-flash', 'gemini/gemini-2.0-flash-lite', 'gemini/gemini-2.5-flash-lite-preview', 'gemini/gemini-2.5-flash']
[CHECK] –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏ gemini/gemini-1.5-flash —Å 338 —Ç–æ–∫–µ–Ω–∞–º–∏...
[STATS] –ú–æ–¥–µ–ª—å gemini/gemini-1.5-flash: —Ç–µ–∫—É—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ RPM=0/15, TPM=0/250000, RPD=2/50
[OK] –ú–æ–¥–µ–ª—å gemini/gemini-1.5-flash: RPM_OK=True, TPM_OK=True, RPD_OK=True -> RESULT=True
[SELECTED] AI Router: –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å 'gemini/gemini-1.5-flash' (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 3)
2025-07-10 05:56:01,373 - tools.gopiai_integration.smart_delegator - INFO - –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: gemini/gemini-1.5-flash
[AVAILABLE] –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è 'dialog': ['gemini/gemini-1.5-flash', 'gemini/gemini-2.0-flash-lite', 'gemini/gemini-2.5-flash-lite-preview', 'gemini/gemini-2.5-flash']
[CHECK] –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏ gemini/gemini-1.5-flash —Å 338 —Ç–æ–∫–µ–Ω–∞–º–∏...
[STATS] –ú–æ–¥–µ–ª—å gemini/gemini-1.5-flash: —Ç–µ–∫—É—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ RPM=0/15, TPM=0/250000, RPD=2/50
[OK] –ú–æ–¥–µ–ª—å gemini/gemini-1.5-flash: RPM_OK=True, TPM_OK=True, RPD_OK=True -> RESULT=True
[SELECTED] AI Router: –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å 'gemini/gemini-1.5-flash' (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 3)
üîÑ –ü–æ–ø—ã—Ç–∫–∞ 1: –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å gemini/gemini-1.5-flash
‚Üê[92m05:56:01 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 -

2025-07-10 05:56:01,373 - LiteLLM - DEBUG -

‚Üê[92m05:56:01 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - ‚Üê[92mRequest to litellm:‚Üê[0m
2025-07-10 05:56:01,385 - LiteLLM - DEBUG - ‚Üê[92mRequest to litellm:‚Üê[0m
‚Üê[92m05:56:01 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - ‚Üê[92mlitellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å... –•–æ—Ä–æ—à–æ, –¥–∞–≤–∞–π –ø–æ–ø—Ä–æ–±—É–µ–º –µ—â—ë —Ä–∞–∑! ü§î –¢—ã –≥–æ–≤–æ—Ä–∏–ª–∞ –ø—Ä–æ —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π... —ç—ç—ç... —á—Ç–æ-—Ç–æ —Å–≤—è–∑–∞–Ω–Ω–æ–µ —Å —Ä—ã–±–∞–º–∏... –ú–æ–∂–µ—Ç –±—ã—Ç—å, –æ–Ω –ª—é–±–∏—Ç —Ä—ã–±—É? –ò–ª–∏ —É –Ω–µ–≥–æ –µ—Å—Ç—å –∞–∫–≤–∞—Ä–∏—É–º? –ò–ª–∏... –æ–Ω –∫–∞–∫-—Ç–æ —Å–≤—è–∑–∞–Ω —Å –º–æ—Ä–µ–º? –î–∞–≤–∞–π, –ø–æ–¥—Å–∫–∞–∑—ã–≤–∞–π! üòÑ'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å... –•–æ—Ä–æ—à–æ, –¥–∞–≤–∞–π –ø–æ–ø—Ä–æ–±—É–µ–º –µ—â—ë —Ä–∞–∑! ü§î –¢—ã –≥–æ–≤–æ—Ä–∏–ª–∞ –ø—Ä–æ —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π... —ç—ç—ç... —á—Ç–æ-—Ç–æ —Å–≤—è–∑–∞–Ω–Ω–æ–µ —Å —Ä—ã–±–∞–º–∏... –ú–æ–∂–µ—Ç –±—ã—Ç—å, –æ–Ω –ª—é–±–∏—Ç —Ä—ã–±—É? –ò–ª–∏ —É –Ω–µ–≥–æ –µ—Å—Ç—å –∞–∫–≤–∞—Ä–∏—É–º? –ò–ª–∏... –æ–Ω –∫–∞–∫-—Ç–æ —Å–≤—è–∑–∞–Ω —Å –º–æ—Ä–µ–º? –î–∞–≤–∞–π, –ø–æ–¥—Å–∫–∞–∑—ã–≤–∞–π! üòÑ'}, {'role': 'assistant', 'content': '–ù—É, –Ω–µ–µ–µ–µ—Ç ü§£ –ò —Å —á–µ–≥–æ —Ç—ã –≤–∑—è–ª–∞, —á—Ç–æ —ç—Ç–æ —á–µ–ª–æ–≤–µ–∫?'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–ù—É, –Ω–µ–µ–µ–µ—Ç ü§£ –ò —Å —á–µ–≥–æ —Ç—ã –≤–∑—è–ª–∞, —á—Ç–æ —ç—Ç–æ —á–µ–ª–æ–≤–µ–∫?'}], temperature=0.7, max_tokens=2000)‚Üê[0m
2025-07-10 05:56:01,385 - LiteLLM - DEBUG - ‚Üê[92mlitellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å... –•–æ—Ä–æ—à–æ, –¥–∞–≤–∞–π –ø–æ–ø—Ä–æ–±—É–µ–º –µ—â—ë —Ä–∞–∑! ü§î –¢—ã –≥–æ–≤–æ—Ä–∏–ª–∞ –ø—Ä–æ —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π... —ç—ç—ç... —á—Ç–æ-—Ç–æ —Å–≤—è–∑–∞–Ω–Ω–æ–µ —Å —Ä—ã–±–∞–º–∏... –ú–æ–∂–µ—Ç –±—ã—Ç—å, –æ–Ω –ª—é–±–∏—Ç —Ä—ã–±—É? –ò–ª–∏ —É –Ω–µ–≥–æ –µ—Å—Ç—å –∞–∫–≤–∞—Ä–∏—É–º? –ò–ª–∏... –æ–Ω –∫–∞–∫-—Ç–æ —Å–≤—è–∑–∞–Ω —Å –º–æ—Ä–µ–º? –î–∞–≤–∞–π, –ø–æ–¥—Å–∫–∞–∑—ã–≤–∞–π! üòÑ'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å... –•–æ—Ä–æ—à–æ, –¥–∞–≤–∞–π –ø–æ–ø—Ä–æ–±—É–µ–º –µ—â—ë —Ä–∞–∑! ü§î –¢—ã –≥–æ–≤–æ—Ä–∏–ª–∞ –ø—Ä–æ —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π... —ç—ç—ç... —á—Ç–æ-—Ç–æ —Å–≤—è–∑–∞–Ω–Ω–æ–µ —Å —Ä—ã–±–∞–º–∏... –ú–æ–∂–µ—Ç –±—ã—Ç—å, –æ–Ω –ª—é–±–∏—Ç —Ä—ã–±—É? –ò–ª–∏ —É –Ω–µ–≥–æ –µ—Å—Ç—å –∞–∫–≤–∞—Ä–∏—É–º? –ò–ª–∏... –æ–Ω –∫–∞–∫-—Ç–æ —Å–≤—è–∑–∞–Ω —Å –º–æ—Ä–µ–º? –î–∞–≤–∞–π, –ø–æ–¥—Å–∫–∞–∑—ã–≤–∞–π! üòÑ'}, {'role': 'assistant', 'content': '–ù—É, –Ω–µ–µ–µ–µ—Ç ü§£ –ò —Å —á–µ–≥–æ —Ç—ã –≤–∑—è–ª–∞, —á—Ç–æ —ç—Ç–æ —á–µ–ª–æ–≤–µ–∫?'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–ù—É, –Ω–µ–µ–µ–µ—Ç ü§£ –ò —Å —á–µ–≥–æ —Ç—ã –≤–∑—è–ª–∞, —á—Ç–æ —ç—Ç–æ —á–µ–ª–æ–≤–µ–∫?'}], temperature=0.7, max_tokens=2000)‚Üê[0m
‚Üê[92m05:56:01 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 -

2025-07-10 05:56:01,398 - LiteLLM - DEBUG -

‚Üê[92m05:56:01 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:461 - self.optional_params: {}
2025-07-10 05:56:01,405 - LiteLLM - DEBUG - self.optional_params: {}
‚Üê[92m05:56:01 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-07-10 05:56:01,412 - LiteLLM - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
‚Üê[92m05:56:01 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
2025-07-10 05:56:01,412 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
‚Üê[92m05:56:01 - LiteLLM:INFO‚Üê[0m: utils.py:3119 -
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-07-10 05:56:01,417 - LiteLLM - INFO -
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
‚Üê[92m05:56:01 - LiteLLM:DEBUG‚Üê[0m: utils.py:3122 -
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.7, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 2000, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å... –•–æ—Ä–æ—à–æ, –¥–∞–≤–∞–π –ø–æ–ø—Ä–æ–±—É–µ–º –µ—â—ë —Ä–∞–∑! ü§î –¢—ã –≥–æ–≤–æ—Ä–∏–ª–∞ –ø—Ä–æ —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π... —ç—ç—ç... —á—Ç–æ-—Ç–æ —Å–≤—è–∑–∞–Ω–Ω–æ–µ —Å —Ä—ã–±–∞–º–∏... –ú–æ–∂–µ—Ç –±—ã—Ç—å, –æ–Ω –ª—é–±–∏—Ç —Ä—ã–±—É? –ò–ª–∏ —É –Ω–µ–≥–æ –µ—Å—Ç—å –∞–∫–≤–∞—Ä–∏—É–º? –ò–ª–∏... –æ–Ω –∫–∞–∫-—Ç–æ —Å–≤—è–∑–∞–Ω —Å –º–æ—Ä–µ–º? –î–∞–≤–∞–π, –ø–æ–¥—Å–∫–∞–∑—ã–≤–∞–π! üòÑ'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å... –•–æ—Ä–æ—à–æ, –¥–∞–≤–∞–π –ø–æ–ø—Ä–æ–±—É–µ–º –µ—â—ë —Ä–∞–∑! ü§î –¢—ã –≥–æ–≤–æ—Ä–∏–ª–∞ –ø—Ä–æ —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π... —ç—ç—ç... —á—Ç–æ-—Ç–æ —Å–≤—è–∑–∞–Ω–Ω–æ–µ —Å —Ä—ã–±–∞–º–∏... –ú–æ–∂–µ—Ç –±—ã—Ç—å, –æ–Ω –ª—é–±–∏—Ç —Ä—ã–±—É? –ò–ª–∏ —É –Ω–µ–≥–æ –µ—Å—Ç—å –∞–∫–≤–∞—Ä–∏—É–º? –ò–ª–∏... –æ–Ω –∫–∞–∫-—Ç–æ —Å–≤—è–∑–∞–Ω —Å –º–æ—Ä–µ–º? –î–∞–≤–∞–π, –ø–æ–¥—Å–∫–∞–∑—ã–≤–∞–π! üòÑ'}, {'role': 'assistant', 'content': '–ù—É, –Ω–µ–µ–µ–µ—Ç ü§£ –ò —Å —á–µ–≥–æ —Ç—ã –≤–∑—è–ª–∞, —á—Ç–æ —ç—Ç–æ —á–µ–ª–æ–≤–µ–∫?'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–ù—É, –Ω–µ–µ–µ–µ—Ç ü§£ –ò —Å —á–µ–≥–æ —Ç—ã –≤–∑—è–ª–∞, —á—Ç–æ —ç—Ç–æ —á–µ–ª–æ–≤–µ–∫?'}], 'thinking': None, 'web_search_options': None}
2025-07-10 05:56:01,422 - LiteLLM - DEBUG -
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.7, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 2000, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å... –•–æ—Ä–æ—à–æ, –¥–∞–≤–∞–π –ø–æ–ø—Ä–æ–±—É–µ–º –µ—â—ë —Ä–∞–∑! ü§î –¢—ã –≥–æ–≤–æ—Ä–∏–ª–∞ –ø—Ä–æ —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π... —ç—ç—ç... —á—Ç–æ-—Ç–æ —Å–≤—è–∑–∞–Ω–Ω–æ–µ —Å —Ä—ã–±–∞–º–∏... –ú–æ–∂–µ—Ç –±—ã—Ç—å, –æ–Ω –ª—é–±–∏—Ç —Ä—ã–±—É? –ò–ª–∏ —É –Ω–µ–≥–æ –µ—Å—Ç—å –∞–∫–≤–∞—Ä–∏—É–º? –ò–ª–∏... –æ–Ω –∫–∞–∫-—Ç–æ —Å–≤—è–∑–∞–Ω —Å –º–æ—Ä–µ–º? –î–∞–≤–∞–π, –ø–æ–¥—Å–∫–∞–∑—ã–≤–∞–π! üòÑ'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å... –•–æ—Ä–æ—à–æ, –¥–∞–≤–∞–π –ø–æ–ø—Ä–æ–±—É–µ–º –µ—â—ë —Ä–∞–∑! ü§î –¢—ã –≥–æ–≤–æ—Ä–∏–ª–∞ –ø—Ä–æ —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π... —ç—ç—ç... —á—Ç–æ-—Ç–æ —Å–≤—è–∑–∞–Ω–Ω–æ–µ —Å —Ä—ã–±–∞–º–∏... –ú–æ–∂–µ—Ç –±—ã—Ç—å, –æ–Ω –ª—é–±–∏—Ç —Ä—ã–±—É? –ò–ª–∏ —É –Ω–µ–≥–æ –µ—Å—Ç—å –∞–∫–≤–∞—Ä–∏—É–º? –ò–ª–∏... –æ–Ω –∫–∞–∫-—Ç–æ —Å–≤—è–∑–∞–Ω —Å –º–æ—Ä–µ–º? –î–∞–≤–∞–π, –ø–æ–¥—Å–∫–∞–∑—ã–≤–∞–π! üòÑ'}, {'role': 'assistant', 'content': '–ù—É, –Ω–µ–µ–µ–µ—Ç ü§£ –ò —Å —á–µ–≥–æ —Ç—ã –≤–∑—è–ª–∞, —á—Ç–æ —ç—Ç–æ —á–µ–ª–æ–≤–µ–∫?'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–ù—É, –Ω–µ–µ–µ–µ—Ç ü§£ –ò —Å —á–µ–≥–æ —Ç—ã –≤–∑—è–ª–∞, —á—Ç–æ —ç—Ç–æ —á–µ–ª–æ–≤–µ–∫?'}], 'thinking': None, 'web_search_options': None}
‚Üê[92m05:56:01 - LiteLLM:DEBUG‚Üê[0m: utils.py:3125 -
LiteLLM: Non-Default params passed to completion() {'temperature': 0.7, 'max_tokens': 2000}
2025-07-10 05:56:01,433 - LiteLLM - DEBUG -
LiteLLM: Non-Default params passed to completion() {'temperature': 0.7, 'max_tokens': 2000}
‚Üê[92m05:56:01 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - Final returned optional params: {'temperature': 0.7, 'max_output_tokens': 2000}
2025-07-10 05:56:01,435 - LiteLLM - DEBUG - Final returned optional params: {'temperature': 0.7, 'max_output_tokens': 2000}
‚Üê[92m05:56:01 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:461 - self.optional_params: {'temperature': 0.7, 'max_tokens': 2000}
2025-07-10 05:56:01,443 - LiteLLM - DEBUG - self.optional_params: {'temperature': 0.7, 'max_tokens': 2000}
‚Üê[92m05:56:01 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:56:01,443 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:56:01 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:56:01,877 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:56:01 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:908 - ‚Üê[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****gu0Q \
-H 'Content-Type: ap****on' \
-d '{'contents': [{'role': 'model', 'parts': [{'text': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'text': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å... –•–æ—Ä–æ—à–æ, –¥–∞–≤–∞–π –ø–æ–ø—Ä–æ–±—É–µ–º –µ—â—ë —Ä–∞–∑! ü§î –¢—ã –≥–æ–≤–æ—Ä–∏–ª–∞ –ø—Ä–æ —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π... —ç—ç—ç... —á—Ç–æ-—Ç–æ —Å–≤—è–∑–∞–Ω–Ω–æ–µ —Å —Ä—ã–±–∞–º–∏... –ú–æ–∂–µ—Ç –±—ã—Ç—å, –æ–Ω –ª—é–±–∏—Ç —Ä—ã–±—É? –ò–ª–∏ —É –Ω–µ–≥–æ –µ—Å—Ç—å –∞–∫–≤–∞—Ä–∏—É–º? –ò–ª–∏... –æ–Ω –∫–∞–∫-—Ç–æ —Å–≤—è–∑–∞–Ω —Å –º–æ—Ä–µ–º? –î–∞–≤–∞–π, –ø–æ–¥—Å–∫–∞–∑—ã–≤–∞–π! üòÑ'}, {'text': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å... –•–æ—Ä–æ—à–æ, –¥–∞–≤–∞–π –ø–æ–ø—Ä–æ–±—É–µ–º –µ—â—ë —Ä–∞–∑! ü§î –¢—ã –≥–æ–≤–æ—Ä–∏–ª–∞ –ø—Ä–æ —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π... —ç—ç—ç... —á—Ç–æ-—Ç–æ —Å–≤—è–∑–∞–Ω–Ω–æ–µ —Å —Ä—ã–±–∞–º–∏... –ú–æ–∂–µ—Ç –±—ã—Ç—å, –æ–Ω –ª—é–±–∏—Ç —Ä—ã–±—É? –ò–ª–∏ —É –Ω–µ–≥–æ –µ—Å—Ç—å –∞–∫–≤–∞—Ä–∏—É–º? –ò–ª–∏... –æ–Ω –∫–∞–∫-—Ç–æ —Å–≤—è–∑–∞–Ω —Å –º–æ—Ä–µ–º? –î–∞–≤–∞–π, –ø–æ–¥—Å–∫–∞–∑—ã–≤–∞–π! üòÑ'}, {'text': '–ù—É, –Ω–µ–µ–µ–µ—Ç ü§£ –ò —Å —á–µ–≥–æ —Ç—ã –≤–∑—è–ª–∞, —á—Ç–æ —ç—Ç–æ —á–µ–ª–æ–≤–µ–∫?'}, {'text': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}]}, {'role': 'user', 'parts': [{'text': '–ù—É, –Ω–µ–µ–µ–µ—Ç ü§£ –ò —Å —á–µ–≥–æ —Ç—ã –≤–∑—è–ª–∞, —á—Ç–æ —ç—Ç–æ —á–µ–ª–æ–≤–µ–∫?'}]}], 'system_instruction': {'parts': [{'text': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}]}, 'generationConfig': {'temperature': 0.7, 'max_output_tokens': 2000}}'
‚Üê[0m

2025-07-10 05:56:01,885 - LiteLLM - DEBUG - ‚Üê[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****gu0Q \
-H 'Content-Type: ap****on' \
-d '{'contents': [{'role': 'model', 'parts': [{'text': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'text': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å... –•–æ—Ä–æ—à–æ, –¥–∞–≤–∞–π –ø–æ–ø—Ä–æ–±—É–µ–º –µ—â—ë —Ä–∞–∑! ü§î –¢—ã –≥–æ–≤–æ—Ä–∏–ª–∞ –ø—Ä–æ —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π... —ç—ç—ç... —á—Ç–æ-—Ç–æ —Å–≤—è–∑–∞–Ω–Ω–æ–µ —Å —Ä—ã–±–∞–º–∏... –ú–æ–∂–µ—Ç –±—ã—Ç—å, –æ–Ω –ª—é–±–∏—Ç —Ä—ã–±—É? –ò–ª–∏ —É –Ω–µ–≥–æ –µ—Å—Ç—å –∞–∫–≤–∞—Ä–∏—É–º? –ò–ª–∏... –æ–Ω –∫–∞–∫-—Ç–æ —Å–≤—è–∑–∞–Ω —Å –º–æ—Ä–µ–º? –î–∞–≤–∞–π, –ø–æ–¥—Å–∫–∞–∑—ã–≤–∞–π! üòÑ'}, {'text': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å... –•–æ—Ä–æ—à–æ, –¥–∞–≤–∞–π –ø–æ–ø—Ä–æ–±—É–µ–º –µ—â—ë —Ä–∞–∑! ü§î –¢—ã –≥–æ–≤–æ—Ä–∏–ª–∞ –ø—Ä–æ —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π... —ç—ç—ç... —á—Ç–æ-—Ç–æ —Å–≤—è–∑–∞–Ω–Ω–æ–µ —Å —Ä—ã–±–∞–º–∏... –ú–æ–∂–µ—Ç –±—ã—Ç—å, –æ–Ω –ª—é–±–∏—Ç —Ä—ã–±—É? –ò–ª–∏ —É –Ω–µ–≥–æ –µ—Å—Ç—å –∞–∫–≤–∞—Ä–∏—É–º? –ò–ª–∏... –æ–Ω –∫–∞–∫-—Ç–æ —Å–≤—è–∑–∞–Ω —Å –º–æ—Ä–µ–º? –î–∞–≤–∞–π, –ø–æ–¥—Å–∫–∞–∑—ã–≤–∞–π! üòÑ'}, {'text': '–ù—É, –Ω–µ–µ–µ–µ—Ç ü§£ –ò —Å —á–µ–≥–æ —Ç—ã –≤–∑—è–ª–∞, —á—Ç–æ —ç—Ç–æ —á–µ–ª–æ–≤–µ–∫?'}, {'text': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}]}, {'role': 'user', 'parts': [{'text': '–ù—É, –Ω–µ–µ–µ–µ—Ç ü§£ –ò —Å —á–µ–≥–æ —Ç—ã –≤–∑—è–ª–∞, —á—Ç–æ —ç—Ç–æ —á–µ–ª–æ–≤–µ–∫?'}]}], 'system_instruction': {'parts': [{'text': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}]}, 'generationConfig': {'temperature': 0.7, 'max_output_tokens': 2000}}'
‚Üê[0m

2025-07-10 05:56:02,322 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None
2025-07-10 05:56:02,368 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025732CCE660>
2025-07-10 05:56:02,368 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000025732E90950> server_hostname='generativelanguage.googleapis.com' timeout=600.0
2025-07-10 05:56:02,403 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025732CCE8D0>
2025-07-10 05:56:02,403 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-10 05:56:02,405 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-07-10 05:56:02,405 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-10 05:56:02,405 - httpcore.http11 - DEBUG - send_request_body.complete
2025-07-10 05:56:02,405 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-10 05:56:09,086 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 10 Jul 2025 00:26:00 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=6653'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-10 05:56:09,086 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyD2taiOJ6Z7nLcVQrz_U0ct4G0HlyLgu0Q "HTTP/1.1 200 OK"
2025-07-10 05:56:09,086 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-10 05:56:09,086 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-07-10 05:56:09,086 - httpcore.http11 - DEBUG - response_closed.started
2025-07-10 05:56:09,086 - httpcore.http11 - DEBUG - response_closed.complete
‚Üê[92m05:56:09 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - RAW RESPONSE:
{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "–ü—Ä–æ—Å—Ç–∏, —è –Ω–µ–º–Ω–æ–≥–æ –∑–∞–ø—É—Ç–∞–ª—Å—è!  –Ø –Ω–µ –∏–º–µ—é –¥–æ—Å—Ç—É–ø–∞ –∫ –ø—Ä–µ–¥—ã–¥—É—â–∏–º —Ä–∞–∑–≥–æ–≤–æ—Ä–∞–º –∏ –Ω–µ –∑–Ω–∞—é, –æ –∫–æ–º –∏–ª–∏ –æ —á—ë–º —Ç—ã –≥–æ–≤–æ—Ä–∏–ª–∞ —Ä–∞–Ω—å—à–µ.  –ß—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–¥–∞–π —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å –∑–∞–Ω–æ–≤–æ.  –ß–µ–º –ø–æ–¥—Ä–æ–±–Ω–µ–µ —Ç—ã –æ–ø–∏—à–µ—à—å —Å–≤–æ—é –ø—Ä–æ—Å—å–±—É, —Ç–µ–º –ª—É—á—à–µ —è —Å–º–æ–≥—É —Ç–µ–±–µ –ø–æ–º–æ—á—å.\n"
          }
        ],
        "role": "model"
      },
      "finishReason": "STOP",
      "avgLogprobs": -0.19654831416170362
    }
  ],
  "usageMetadata": {
    "promptTokenCount": 205,
    "candidatesTokenCount": 71,
    "totalTokenCount": 276,
    "promptTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 205
      }
    ],
    "candidatesTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 71
      }
    ]
  },
  "modelVersion": "gemini-1.5-flash",
  "responseId": "kghvaJjHBNq8698P86rXwA8"
}



2025-07-10 05:56:09,086 - LiteLLM - DEBUG - RAW RESPONSE:
{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "–ü—Ä–æ—Å—Ç–∏, —è –Ω–µ–º–Ω–æ–≥–æ –∑–∞–ø—É—Ç–∞–ª—Å—è!  –Ø –Ω–µ –∏–º–µ—é –¥–æ—Å—Ç—É–ø–∞ –∫ –ø—Ä–µ–¥—ã–¥—É—â–∏–º —Ä–∞–∑–≥–æ–≤–æ—Ä–∞–º –∏ –Ω–µ –∑–Ω–∞—é, –æ –∫–æ–º –∏–ª–∏ –æ —á—ë–º —Ç—ã –≥–æ–≤–æ—Ä–∏–ª–∞ —Ä–∞–Ω—å—à–µ.  –ß—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–¥–∞–π —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å –∑–∞–Ω–æ–≤–æ.  –ß–µ–º –ø–æ–¥—Ä–æ–±–Ω–µ–µ —Ç—ã –æ–ø–∏—à–µ—à—å —Å–≤–æ—é –ø—Ä–æ—Å—å–±—É, —Ç–µ–º –ª—É—á—à–µ —è —Å–º–æ–≥—É —Ç–µ–±–µ –ø–æ–º–æ—á—å.\n"
          }
        ],
        "role": "model"
      },
      "finishReason": "STOP",
      "avgLogprobs": -0.19654831416170362
    }
  ],
  "usageMetadata": {
    "promptTokenCount": 205,
    "candidatesTokenCount": 71,
    "totalTokenCount": 276,
    "promptTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 205
      }
    ],
    "candidatesTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 71
      }
    ]
  },
  "modelVersion": "gemini-1.5-flash",
  "responseId": "kghvaJjHBNq8698P86rXwA8"
}



2025-07-10 05:56:09,114 - httpcore.connection - DEBUG - close.started
2025-07-10 05:56:09,116 - httpcore.connection - DEBUG - close.complete
‚Üê[92m05:56:09 - LiteLLM:INFO‚Üê[0m: utils.py:1215 - Wrapper: Completed Call, calling success_handler
2025-07-10 05:56:09,116 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
‚Üê[92m05:56:09 - LiteLLM:INFO‚Üê[0m: cost_calculator.py:655 - selected model name for cost calculation: gemini/gemini-1.5-flash
2025-07-10 05:56:09,116 - LiteLLM - INFO - selected model name for cost calculation: gemini/gemini-1.5-flash
‚Üê[92m05:56:09 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:1394 - Logging Details LiteLLM-Success Call: Cache_hit=None
2025-07-10 05:56:09,116 - LiteLLM - DEBUG - Logging Details LiteLLM-Success Call: Cache_hit=None
‚Üê[92m05:56:09 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:56:09,122 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:56:09 - LiteLLM:INFO‚Üê[0m: cost_calculator.py:655 - selected model name for cost calculation: gemini/gemini-1.5-flash
2025-07-10 05:56:09,124 - LiteLLM - INFO - selected model name for cost calculation: gemini/gemini-1.5-flash
‚Üê[92m05:56:09 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:56:09,124 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:56:09 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:56:09,124 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:56:09 - LiteLLM:DEBUG‚Üê[0m: utils.py:4783 - model_info: {'key': 'gemini/gemini-1.5-flash', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 2000}
2025-07-10 05:56:09,129 - LiteLLM - DEBUG - model_info: {'key': 'gemini/gemini-1.5-flash', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 2000}
‚Üê[92m05:56:09 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:56:09,136 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:56:09 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:1131 - response_cost: 3.6675e-05
2025-07-10 05:56:09,144 - LiteLLM - DEBUG - response_cost: 3.6675e-05
‚Üê[92m05:56:09 - LiteLLM:DEBUG‚Üê[0m: utils.py:4783 - model_info: {'key': 'gemini/gemini-1.5-flash', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 2000}
‚úÖ –£—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏ gemini/gemini-1.5-flash2025-07-10 05:56:09,148 - LiteLLM - DEBUG - model_info: {'key': 'gemini/gemini-1.5-flash', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 2000}

‚Üê[92m05:56:09 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:1131 - response_cost: 3.6675e-05
2025-07-10 05:56:09,155 - tools.gopiai_integration.smart_delegator - INFO - ‚úÖ –û—Ç–≤–µ—Ç –æ—Ç LLM –ø–æ–ª—É—á–µ–Ω
2025-07-10 05:56:09,155 - LiteLLM - DEBUG - response_cost: 3.6675e-05
2025-07-10 05:56:09,161 - tools.gopiai_integration.smart_delegator - INFO - ‚è± –ó–∞–ø—Ä–æ—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∑–∞ 7.82 —Å–µ–∫
‚Üê[92m05:56:09 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
‚è± –ó–∞–ø—Ä–æ—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∑–∞ 7.82 —Å–µ–∫2025-07-10 05:56:09,161 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}

‚Üê[92m05:56:09 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚úÖ –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω, –¥–ª–∏–Ω–∞: 254 —Å–∏–º–≤–æ–ª–æ–≤2025-07-10 05:56:09,161 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}

‚Üê[92m05:56:09 - LiteLLM:DEBUG‚Üê[0m: utils.py:4783 - model_info: {'key': 'gemini/gemini-1.5-flash', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 2000}
2025-07-10 05:56:09,172 - werkzeug - INFO - 127.0.0.1 - - [10/Jul/2025 05:56:09] "POST /api/process HTTP/1.1" 200 -
2025-07-10 05:56:09,171 - LiteLLM - DEBUG - model_info: {'key': 'gemini/gemini-1.5-flash', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 2000}
‚Üê[92m05:56:09 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:1423 - Logging Details LiteLLM-Success Call streaming complete
2025-07-10 05:56:09,181 - LiteLLM - DEBUG - Logging Details LiteLLM-Success Call streaming complete
‚Üê[92m05:56:09 - LiteLLM:INFO‚Üê[0m: cost_calculator.py:655 - selected model name for cost calculation: gemini/gemini-1.5-flash
2025-07-10 05:56:09,185 - LiteLLM - INFO - selected model name for cost calculation: gemini/gemini-1.5-flash
‚Üê[92m05:56:09 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:56:09,187 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:56:09 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:56:09,187 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:56:09 - LiteLLM:DEBUG‚Üê[0m: utils.py:4783 - model_info: {'key': 'gemini/gemini-1.5-flash', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 2000}
2025-07-10 05:56:09,196 - LiteLLM - DEBUG - model_info: {'key': 'gemini/gemini-1.5-flash', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 2000}
‚Üê[92m05:56:09 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:1131 - response_cost: 3.6675e-05
2025-07-10 05:56:09,206 - LiteLLM - DEBUG - response_cost: 3.6675e-05
‚Üê[92m05:56:09 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
2025-07-10 05:56:09,208 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
‚Üê[92m05:56:09 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:56:09,211 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:56:09 - LiteLLM:DEBUG‚Üê[0m: utils.py:4783 - model_info: {'key': 'gemini/gemini-1.5-flash', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 2000}
2025-07-10 05:56:09,211 - LiteLLM - DEBUG - model_info: {'key': 'gemini/gemini-1.5-flash', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 2000}
2025-07-10 05:56:43,177 - werkzeug - INFO - 127.0.0.1 - - [10/Jul/2025 05:56:43] "GET /api/health HTTP/1.1" 200 -
üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: —Å–ª–æ–∂–Ω–æ—Å—Ç—å=0, —Ç–∏–ø=general, CrewAI=False
üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: —Å–ª–æ–∂–Ω–æ—Å—Ç—å=0, —Ç–∏–ø=general, CrewAI=False
üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: —Å–ª–æ–∂–Ω–æ—Å—Ç—å=0, —Ç–∏–ø=general, CrewAI=False
üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: —Å–ª–æ–∂–Ω–æ—Å—Ç—å=0, —Ç–∏–ø=general, CrewAI=False
2025-07-10 05:56:43,293 - tools.gopiai_integration.smart_delegator - INFO - üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ AI Router...
2025-07-10 05:56:43,300 - tools.gopiai_integration.smart_delegator - INFO - ‚úÖ AI Router –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã
2025-07-10 05:56:43,317 - tools.gopiai_integration.smart_delegator - INFO - –ó–∞–≥—Ä—É–∂–µ–Ω–æ 5 —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞
2025-07-10 05:56:43,323 - tools.gopiai_integration.smart_delegator - INFO - üöÄ –í—ã–∑–æ–≤ LLM —Å –∏—Å—Ç–æ—Ä–∏–µ–π —á–∞—Ç–∞...
2025-07-10 05:56:43,332 - tools.gopiai_integration.smart_delegator - DEBUG - –û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ LLM: [
  {
    "role": "system",
    "content": "–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç."
  },
  {
    "role": "assistant",
    "content": "‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å..."
  },
  {
    "role": "assistant",
    "content": "–ü—Ä–æ—Å—Ç–∏, —è –Ω–µ–º–Ω–æ–≥–æ –∑–∞–ø—É—Ç–∞–ª—Å—è!  –Ø –Ω–µ –∏–º–µ—é –¥–æ—Å—Ç—É–ø–∞ –∫ –ø—Ä–µ–¥—ã–¥—É—â–∏–º —Ä–∞–∑–≥–æ–≤–æ—Ä–∞–º –∏ –Ω–µ –∑–Ω–∞—é, –æ –∫–æ–º –∏–ª–∏ –æ —á—ë–º —Ç—ã –≥–æ–≤–æ—Ä–∏–ª–∞ —Ä–∞–Ω—å—à–µ.  –ß—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–¥–∞–π —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å –∑–∞–Ω–æ–≤–æ.  –ß–µ–º –ø–æ–¥—Ä–æ–±–Ω–µ–µ —Ç—ã –æ–ø–∏—à–µ—à—å —Å–≤–æ—é –ø—Ä–æ—Å—å–±—É, —Ç–µ–º –ª—É—á—à–µ —è —Å–º–æ–≥—É —Ç–µ–±–µ –ø–æ–º–æ—á—å."
  },
  {
    "role": "assistant",
    "content": "–ü—Ä–æ—Å—Ç–∏, —è –Ω–µ–º–Ω–æ–≥–æ –∑–∞–ø—É—Ç–∞–ª—Å—è!  –Ø –Ω–µ –∏–º–µ—é –¥–æ—Å—Ç—É–ø–∞ –∫ –ø—Ä–µ–¥—ã–¥—É—â–∏–º —Ä–∞–∑–≥–æ–≤–æ—Ä–∞–º –∏ –Ω–µ –∑–Ω–∞—é, –æ –∫–æ–º –∏–ª–∏ –æ —á—ë–º —Ç—ã –≥–æ–≤–æ—Ä–∏–ª–∞ —Ä–∞–Ω—å—à–µ.  –ß—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–¥–∞–π —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å –∑–∞–Ω–æ–≤–æ.  –ß–µ–º –ø–æ–¥—Ä–æ–±–Ω–µ–µ —Ç—ã –æ–ø–∏—à–µ—à—å —Å–≤–æ—é –ø—Ä–æ—Å—å–±—É, —Ç–µ–º –ª—É—á—à–µ —è —Å–º–æ–≥—É —Ç–µ–±–µ –ø–æ–º–æ—á—å."
  },
  {
    "role": "assistant",
    "content": "–∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É?"
  },
  {
    "role": "assistant",
    "content": "‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å..."
  },
  {
    "role": "user",
    "content": "–∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É?"
  }
]
[AVAILABLE] –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è 'dialog': ['gemini/gemini-1.5-flash', 'gemini/gemini-2.0-flash-lite', 'gemini/gemini-2.5-flash-lite-preview', 'gemini/gemini-2.5-flash']
[CHECK] –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏ gemini/gemini-1.5-flash —Å 320 —Ç–æ–∫–µ–Ω–∞–º–∏...
[STATS] –ú–æ–¥–µ–ª—å gemini/gemini-1.5-flash: —Ç–µ–∫—É—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ RPM=1/15, TPM=338/250000, RPD=3/50
[OK] –ú–æ–¥–µ–ª—å gemini/gemini-1.5-flash: RPM_OK=True, TPM_OK=True, RPD_OK=True -> RESULT=True
[SELECTED] AI Router: –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å 'gemini/gemini-1.5-flash' (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 3)
2025-07-10 05:56:43,349 - tools.gopiai_integration.smart_delegator - INFO - –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: gemini/gemini-1.5-flash
[AVAILABLE] –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è 'dialog': ['gemini/gemini-1.5-flash', 'gemini/gemini-2.0-flash-lite', 'gemini/gemini-2.5-flash-lite-preview', 'gemini/gemini-2.5-flash']
[CHECK] –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏ gemini/gemini-1.5-flash —Å 320 —Ç–æ–∫–µ–Ω–∞–º–∏...
[STATS] –ú–æ–¥–µ–ª—å gemini/gemini-1.5-flash: —Ç–µ–∫—É—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ RPM=1/15, TPM=338/250000, RPD=3/50
[OK] –ú–æ–¥–µ–ª—å gemini/gemini-1.5-flash: RPM_OK=True, TPM_OK=True, RPD_OK=True -> RESULT=True
[SELECTED] AI Router: –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å 'gemini/gemini-1.5-flash' (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 3)
üîÑ –ü–æ–ø—ã—Ç–∫–∞ 1: –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å gemini/gemini-1.5-flash
‚Üê[92m05:56:43 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 -

2025-07-10 05:56:43,355 - LiteLLM - DEBUG -

‚Üê[92m05:56:43 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - ‚Üê[92mRequest to litellm:‚Üê[0m
2025-07-10 05:56:43,355 - LiteLLM - DEBUG - ‚Üê[92mRequest to litellm:‚Üê[0m
‚Üê[92m05:56:43 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - ‚Üê[92mlitellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'assistant', 'content': '–ü—Ä–æ—Å—Ç–∏, —è –Ω–µ–º–Ω–æ–≥–æ –∑–∞–ø—É—Ç–∞–ª—Å—è!  –Ø –Ω–µ –∏–º–µ—é –¥–æ—Å—Ç—É–ø–∞ –∫ –ø—Ä–µ–¥—ã–¥—É—â–∏–º —Ä–∞–∑–≥–æ–≤–æ—Ä–∞–º –∏ –Ω–µ –∑–Ω–∞—é, –æ –∫–æ–º –∏–ª–∏ –æ —á—ë–º —Ç—ã –≥–æ–≤–æ—Ä–∏–ª–∞ —Ä–∞–Ω—å—à–µ.  –ß—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–¥–∞–π —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å –∑–∞–Ω–æ–≤–æ.  –ß–µ–º –ø–æ–¥—Ä–æ–±–Ω–µ–µ —Ç—ã –æ–ø–∏—à–µ—à—å —Å–≤–æ—é –ø—Ä–æ—Å—å–±—É, —Ç–µ–º –ª—É—á—à–µ —è —Å–º–æ–≥—É —Ç–µ–±–µ –ø–æ–º–æ—á—å.'}, {'role': 'assistant', 'content': '–ü—Ä–æ—Å—Ç–∏, —è –Ω–µ–º–Ω–æ–≥–æ –∑–∞–ø—É—Ç–∞–ª—Å—è!  –Ø –Ω–µ –∏–º–µ—é –¥–æ—Å—Ç—É–ø–∞ –∫ –ø—Ä–µ–¥—ã–¥—É—â–∏–º —Ä–∞–∑–≥–æ–≤–æ—Ä–∞–º –∏ –Ω–µ –∑–Ω–∞—é, –æ –∫–æ–º –∏–ª–∏ –æ —á—ë–º —Ç—ã –≥–æ–≤–æ—Ä–∏–ª–∞ —Ä–∞–Ω—å—à–µ.  –ß—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–¥–∞–π —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å –∑–∞–Ω–æ–≤–æ.  –ß–µ–º –ø–æ–¥—Ä–æ–±–Ω–µ–µ —Ç—ã –æ–ø–∏—à–µ—à—å —Å–≤–æ—é –ø—Ä–æ—Å—å–±—É, —Ç–µ–º –ª—É—á—à–µ —è —Å–º–æ–≥—É —Ç–µ–±–µ –ø–æ–º–æ—á—å.'}, {'role': 'assistant', 'content': '–∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É?'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É?'}], temperature=0.7, max_tokens=2000)‚Üê[0m
2025-07-10 05:56:43,360 - LiteLLM - DEBUG - ‚Üê[92mlitellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'assistant', 'content': '–ü—Ä–æ—Å—Ç–∏, —è –Ω–µ–º–Ω–æ–≥–æ –∑–∞–ø—É—Ç–∞–ª—Å—è!  –Ø –Ω–µ –∏–º–µ—é –¥–æ—Å—Ç—É–ø–∞ –∫ –ø—Ä–µ–¥—ã–¥—É—â–∏–º —Ä–∞–∑–≥–æ–≤–æ—Ä–∞–º –∏ –Ω–µ –∑–Ω–∞—é, –æ –∫–æ–º –∏–ª–∏ –æ —á—ë–º —Ç—ã –≥–æ–≤–æ—Ä–∏–ª–∞ —Ä–∞–Ω—å—à–µ.  –ß—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–¥–∞–π —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å –∑–∞–Ω–æ–≤–æ.  –ß–µ–º –ø–æ–¥—Ä–æ–±–Ω–µ–µ —Ç—ã –æ–ø–∏—à–µ—à—å —Å–≤–æ—é –ø—Ä–æ—Å—å–±—É, —Ç–µ–º –ª—É—á—à–µ —è —Å–º–æ–≥—É —Ç–µ–±–µ –ø–æ–º–æ—á—å.'}, {'role': 'assistant', 'content': '–ü—Ä–æ—Å—Ç–∏, —è –Ω–µ–º–Ω–æ–≥–æ –∑–∞–ø—É—Ç–∞–ª—Å—è!  –Ø –Ω–µ –∏–º–µ—é –¥–æ—Å—Ç—É–ø–∞ –∫ –ø—Ä–µ–¥—ã–¥—É—â–∏–º —Ä–∞–∑–≥–æ–≤–æ—Ä–∞–º –∏ –Ω–µ –∑–Ω–∞—é, –æ –∫–æ–º –∏–ª–∏ –æ —á—ë–º —Ç—ã –≥–æ–≤–æ—Ä–∏–ª–∞ —Ä–∞–Ω—å—à–µ.  –ß—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–¥–∞–π —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å –∑–∞–Ω–æ–≤–æ.  –ß–µ–º –ø–æ–¥—Ä–æ–±–Ω–µ–µ —Ç—ã –æ–ø–∏—à–µ—à—å —Å–≤–æ—é –ø—Ä–æ—Å—å–±—É, —Ç–µ–º –ª—É—á—à–µ —è —Å–º–æ–≥—É —Ç–µ–±–µ –ø–æ–º–æ—á—å.'}, {'role': 'assistant', 'content': '–∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É?'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É?'}], temperature=0.7, max_tokens=2000)‚Üê[0m
‚Üê[92m05:56:43 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 -

2025-07-10 05:56:43,370 - LiteLLM - DEBUG -

‚Üê[92m05:56:43 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:461 - self.optional_params: {}
2025-07-10 05:56:43,372 - LiteLLM - DEBUG - self.optional_params: {}
‚Üê[92m05:56:43 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-07-10 05:56:43,373 - LiteLLM - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
‚Üê[92m05:56:43 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
2025-07-10 05:56:43,376 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
‚Üê[92m05:56:43 - LiteLLM:INFO‚Üê[0m: utils.py:3119 -
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-07-10 05:56:43,376 - LiteLLM - INFO -
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
‚Üê[92m05:56:43 - LiteLLM:DEBUG‚Üê[0m: utils.py:3122 -
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.7, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 2000, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'assistant', 'content': '–ü—Ä–æ—Å—Ç–∏, —è –Ω–µ–º–Ω–æ–≥–æ –∑–∞–ø—É—Ç–∞–ª—Å—è!  –Ø –Ω–µ –∏–º–µ—é –¥–æ—Å—Ç—É–ø–∞ –∫ –ø—Ä–µ–¥—ã–¥—É—â–∏–º —Ä–∞–∑–≥–æ–≤–æ—Ä–∞–º –∏ –Ω–µ –∑–Ω–∞—é, –æ –∫–æ–º –∏–ª–∏ –æ —á—ë–º —Ç—ã –≥–æ–≤–æ—Ä–∏–ª–∞ —Ä–∞–Ω—å—à–µ.  –ß—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–¥–∞–π —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å –∑–∞–Ω–æ–≤–æ.  –ß–µ–º –ø–æ–¥—Ä–æ–±–Ω–µ–µ —Ç—ã –æ–ø–∏—à–µ—à—å —Å–≤–æ—é –ø—Ä–æ—Å—å–±—É, —Ç–µ–º –ª—É—á—à–µ —è —Å–º–æ–≥—É —Ç–µ–±–µ –ø–æ–º–æ—á—å.'}, {'role': 'assistant', 'content': '–ü—Ä–æ—Å—Ç–∏, —è –Ω–µ–º–Ω–æ–≥–æ –∑–∞–ø—É—Ç–∞–ª—Å—è!  –Ø –Ω–µ –∏–º–µ—é –¥–æ—Å—Ç—É–ø–∞ –∫ –ø—Ä–µ–¥—ã–¥—É—â–∏–º —Ä–∞–∑–≥–æ–≤–æ—Ä–∞–º –∏ –Ω–µ –∑–Ω–∞—é, –æ –∫–æ–º –∏–ª–∏ –æ —á—ë–º —Ç—ã –≥–æ–≤–æ—Ä–∏–ª–∞ —Ä–∞–Ω—å—à–µ.  –ß—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–¥–∞–π —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å –∑–∞–Ω–æ–≤–æ.  –ß–µ–º –ø–æ–¥—Ä–æ–±–Ω–µ–µ —Ç—ã –æ–ø–∏—à–µ—à—å —Å–≤–æ—é –ø—Ä–æ—Å—å–±—É, —Ç–µ–º –ª—É—á—à–µ —è —Å–º–æ–≥—É —Ç–µ–±–µ –ø–æ–º–æ—á—å.'}, {'role': 'assistant', 'content': '–∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É?'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É?'}], 'thinking': None, 'web_search_options': None}
2025-07-10 05:56:43,385 - LiteLLM - DEBUG -
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.7, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 2000, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'assistant', 'content': '–ü—Ä–æ—Å—Ç–∏, —è –Ω–µ–º–Ω–æ–≥–æ –∑–∞–ø—É—Ç–∞–ª—Å—è!  –Ø –Ω–µ –∏–º–µ—é –¥–æ—Å—Ç—É–ø–∞ –∫ –ø—Ä–µ–¥—ã–¥—É—â–∏–º —Ä–∞–∑–≥–æ–≤–æ—Ä–∞–º –∏ –Ω–µ –∑–Ω–∞—é, –æ –∫–æ–º –∏–ª–∏ –æ —á—ë–º —Ç—ã –≥–æ–≤–æ—Ä–∏–ª–∞ —Ä–∞–Ω—å—à–µ.  –ß—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–¥–∞–π —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å –∑–∞–Ω–æ–≤–æ.  –ß–µ–º –ø–æ–¥—Ä–æ–±–Ω–µ–µ —Ç—ã –æ–ø–∏—à–µ—à—å —Å–≤–æ—é –ø—Ä–æ—Å—å–±—É, —Ç–µ–º –ª—É—á—à–µ —è —Å–º–æ–≥—É —Ç–µ–±–µ –ø–æ–º–æ—á—å.'}, {'role': 'assistant', 'content': '–ü—Ä–æ—Å—Ç–∏, —è –Ω–µ–º–Ω–æ–≥–æ –∑–∞–ø—É—Ç–∞–ª—Å—è!  –Ø –Ω–µ –∏–º–µ—é –¥–æ—Å—Ç—É–ø–∞ –∫ –ø—Ä–µ–¥—ã–¥—É—â–∏–º —Ä–∞–∑–≥–æ–≤–æ—Ä–∞–º –∏ –Ω–µ –∑–Ω–∞—é, –æ –∫–æ–º –∏–ª–∏ –æ —á—ë–º —Ç—ã –≥–æ–≤–æ—Ä–∏–ª–∞ —Ä–∞–Ω—å—à–µ.  –ß—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–¥–∞–π —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å –∑–∞–Ω–æ–≤–æ.  –ß–µ–º –ø–æ–¥—Ä–æ–±–Ω–µ–µ —Ç—ã –æ–ø–∏—à–µ—à—å —Å–≤–æ—é –ø—Ä–æ—Å—å–±—É, —Ç–µ–º –ª—É—á—à–µ —è —Å–º–æ–≥—É —Ç–µ–±–µ –ø–æ–º–æ—á—å.'}, {'role': 'assistant', 'content': '–∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É?'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É?'}], 'thinking': None, 'web_search_options': None}
‚Üê[92m05:56:43 - LiteLLM:DEBUG‚Üê[0m: utils.py:3125 -
LiteLLM: Non-Default params passed to completion() {'temperature': 0.7, 'max_tokens': 2000}
2025-07-10 05:56:43,391 - LiteLLM - DEBUG -
LiteLLM: Non-Default params passed to completion() {'temperature': 0.7, 'max_tokens': 2000}
‚Üê[92m05:56:43 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - Final returned optional params: {'temperature': 0.7, 'max_output_tokens': 2000}
2025-07-10 05:56:43,398 - LiteLLM - DEBUG - Final returned optional params: {'temperature': 0.7, 'max_output_tokens': 2000}
‚Üê[92m05:56:43 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:461 - self.optional_params: {'temperature': 0.7, 'max_tokens': 2000}
2025-07-10 05:56:43,398 - LiteLLM - DEBUG - self.optional_params: {'temperature': 0.7, 'max_tokens': 2000}
‚Üê[92m05:56:43 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:56:43,403 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:56:43 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:56:43,761 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:56:43 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:908 - ‚Üê[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****gu0Q \
-H 'Content-Type: ap****on' \
-d '{'contents': [{'role': 'model', 'parts': [{'text': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'text': '–ü—Ä–æ—Å—Ç–∏, —è –Ω–µ–º–Ω–æ–≥–æ –∑–∞–ø—É—Ç–∞–ª—Å—è!  –Ø –Ω–µ –∏–º–µ—é –¥–æ—Å—Ç—É–ø–∞ –∫ –ø—Ä–µ–¥—ã–¥—É—â–∏–º —Ä–∞–∑–≥–æ–≤–æ—Ä–∞–º –∏ –Ω–µ –∑–Ω–∞—é, –æ –∫–æ–º –∏–ª–∏ –æ —á—ë–º —Ç—ã –≥–æ–≤–æ—Ä–∏–ª–∞ —Ä–∞–Ω—å—à–µ.  –ß—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–¥–∞–π —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å –∑–∞–Ω–æ–≤–æ.  –ß–µ–º –ø–æ–¥—Ä–æ–±–Ω–µ–µ —Ç—ã –æ–ø–∏—à–µ—à—å —Å–≤–æ—é –ø—Ä–æ—Å—å–±—É, —Ç–µ–º –ª—É—á—à–µ —è —Å–º–æ–≥—É —Ç–µ–±–µ –ø–æ–º–æ—á—å.'}, {'text': '–ü—Ä–æ—Å—Ç–∏, —è –Ω–µ–º–Ω–æ–≥–æ –∑–∞–ø—É—Ç–∞–ª—Å—è!  –Ø –Ω–µ –∏–º–µ—é –¥–æ—Å—Ç—É–ø–∞ –∫ –ø—Ä–µ–¥—ã–¥—É—â–∏–º —Ä–∞–∑–≥–æ–≤–æ—Ä–∞–º –∏ –Ω–µ –∑–Ω–∞—é, –æ –∫–æ–º –∏–ª–∏ –æ —á—ë–º —Ç—ã –≥–æ–≤–æ—Ä–∏–ª–∞ —Ä–∞–Ω—å—à–µ.  –ß—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–¥–∞–π —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å –∑–∞–Ω–æ–≤–æ.  –ß–µ–º –ø–æ–¥—Ä–æ–±–Ω–µ–µ —Ç—ã –æ–ø–∏—à–µ—à—å —Å–≤–æ—é –ø—Ä–æ—Å—å–±—É, —Ç–µ–º –ª—É—á—à–µ —è —Å–º–æ–≥—É —Ç–µ–±–µ –ø–æ–º–æ—á—å.'}, {'text': '–∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É?'}, {'text': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}]}, {'role': 'user', 'parts': [{'text': '–∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É?'}]}], 'system_instruction': {'parts': [{'text': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}]}, 'generationConfig': {'temperature': 0.7, 'max_output_tokens': 2000}}'
‚Üê[0m

2025-07-10 05:56:43,765 - LiteLLM - DEBUG - ‚Üê[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****gu0Q \
-H 'Content-Type: ap****on' \
-d '{'contents': [{'role': 'model', 'parts': [{'text': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'text': '–ü—Ä–æ—Å—Ç–∏, —è –Ω–µ–º–Ω–æ–≥–æ –∑–∞–ø—É—Ç–∞–ª—Å—è!  –Ø –Ω–µ –∏–º–µ—é –¥–æ—Å—Ç—É–ø–∞ –∫ –ø—Ä–µ–¥—ã–¥—É—â–∏–º —Ä–∞–∑–≥–æ–≤–æ—Ä–∞–º –∏ –Ω–µ –∑–Ω–∞—é, –æ –∫–æ–º –∏–ª–∏ –æ —á—ë–º —Ç—ã –≥–æ–≤–æ—Ä–∏–ª–∞ —Ä–∞–Ω—å—à–µ.  –ß—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–¥–∞–π —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å –∑–∞–Ω–æ–≤–æ.  –ß–µ–º –ø–æ–¥—Ä–æ–±–Ω–µ–µ —Ç—ã –æ–ø–∏—à–µ—à—å —Å–≤–æ—é –ø—Ä–æ—Å—å–±—É, —Ç–µ–º –ª—É—á—à–µ —è —Å–º–æ–≥—É —Ç–µ–±–µ –ø–æ–º–æ—á—å.'}, {'text': '–ü—Ä–æ—Å—Ç–∏, —è –Ω–µ–º–Ω–æ–≥–æ –∑–∞–ø—É—Ç–∞–ª—Å—è!  –Ø –Ω–µ –∏–º–µ—é –¥–æ—Å—Ç—É–ø–∞ –∫ –ø—Ä–µ–¥—ã–¥—É—â–∏–º —Ä–∞–∑–≥–æ–≤–æ—Ä–∞–º –∏ –Ω–µ –∑–Ω–∞—é, –æ –∫–æ–º –∏–ª–∏ –æ —á—ë–º —Ç—ã –≥–æ–≤–æ—Ä–∏–ª–∞ —Ä–∞–Ω—å—à–µ.  –ß—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–¥–∞–π —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å –∑–∞–Ω–æ–≤–æ.  –ß–µ–º –ø–æ–¥—Ä–æ–±–Ω–µ–µ —Ç—ã –æ–ø–∏—à–µ—à—å —Å–≤–æ—é –ø—Ä–æ—Å—å–±—É, —Ç–µ–º –ª—É—á—à–µ —è —Å–º–æ–≥—É —Ç–µ–±–µ –ø–æ–º–æ—á—å.'}, {'text': '–∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É?'}, {'text': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}]}, {'role': 'user', 'parts': [{'text': '–∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É?'}]}], 'system_instruction': {'parts': [{'text': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}]}, 'generationConfig': {'temperature': 0.7, 'max_output_tokens': 2000}}'
‚Üê[0m

2025-07-10 05:56:44,128 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None
2025-07-10 05:56:44,160 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025732CCEA80>
2025-07-10 05:56:44,162 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000025732E91BD0> server_hostname='generativelanguage.googleapis.com' timeout=600.0
2025-07-10 05:56:44,202 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025732CAAF90>
2025-07-10 05:56:44,203 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-10 05:56:44,206 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-07-10 05:56:44,206 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-10 05:56:44,207 - httpcore.http11 - DEBUG - send_request_body.complete
2025-07-10 05:56:44,208 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-10 05:57:06,033 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 10 Jul 2025 00:26:57 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=21781'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-10 05:57:06,035 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyD2taiOJ6Z7nLcVQrz_U0ct4G0HlyLgu0Q "HTTP/1.1 200 OK"
2025-07-10 05:57:06,038 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-10 05:57:06,039 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-07-10 05:57:06,039 - httpcore.http11 - DEBUG - response_closed.started
2025-07-10 05:57:06,040 - httpcore.http11 - DEBUG - response_closed.complete
‚Üê[92m05:57:06 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - RAW RESPONSE:
{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "–Ø –∏–∑–≤–∏–Ω–∏–ª—Å—è –∑–∞ —Ç–æ, —á—Ç–æ –Ω–µ –ø–æ–º–Ω—é –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤.  –Ø —Å–ø—Ä–æ—Å–∏–ª, –∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É —Ç—ã —Ö–æ—á–µ—à—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å, —á—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å.  –£ –º–µ–Ω—è –Ω–µ—Ç –ø–∞–º—è—Ç–∏ –æ –ø—Ä–æ—à–ª—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö, –ø–æ—ç—Ç–æ–º—É –∫–∞–∂–¥—ã–π –Ω–∞—à —Ä–∞–∑–≥–æ–≤–æ—Ä –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞.  –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏, —á—Ç–æ —Ç—ã —Ö–æ—á–µ—à—å, —á—Ç–æ–±—ã —è —Å–¥–µ–ª–∞–ª.\n"
          }
        ],
        "role": "model"
      },
      "finishReason": "STOP",
      "avgLogprobs": -0.268834958757673
    }
  ],
  "usageMetadata": {
    "promptTokenCount": 177,
    "candidatesTokenCount": 70,
    "totalTokenCount": 247,
    "promptTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 177
      }
    ],
    "candidatesTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 70
      }
    ]
  },
  "modelVersion": "gemini-1.5-flash",
  "responseId": "vQhvaPDvB925nvgPgaXb2Ao"
}



2025-07-10 05:57:06,041 - LiteLLM - DEBUG - RAW RESPONSE:
{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "–Ø –∏–∑–≤–∏–Ω–∏–ª—Å—è –∑–∞ —Ç–æ, —á—Ç–æ –Ω–µ –ø–æ–º–Ω—é –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤.  –Ø —Å–ø—Ä–æ—Å–∏–ª, –∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É —Ç—ã —Ö–æ—á–µ—à—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å, —á—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å.  –£ –º–µ–Ω—è –Ω–µ—Ç –ø–∞–º—è—Ç–∏ –æ –ø—Ä–æ—à–ª—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö, –ø–æ—ç—Ç–æ–º—É –∫–∞–∂–¥—ã–π –Ω–∞—à —Ä–∞–∑–≥–æ–≤–æ—Ä –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞.  –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏, —á—Ç–æ —Ç—ã —Ö–æ—á–µ—à—å, —á—Ç–æ–±—ã —è —Å–¥–µ–ª–∞–ª.\n"
          }
        ],
        "role": "model"
      },
      "finishReason": "STOP",
      "avgLogprobs": -0.268834958757673
    }
  ],
  "usageMetadata": {
    "promptTokenCount": 177,
    "candidatesTokenCount": 70,
    "totalTokenCount": 247,
    "promptTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 177
      }
    ],
    "candidatesTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 70
      }
    ]
  },
  "modelVersion": "gemini-1.5-flash",
  "responseId": "vQhvaPDvB925nvgPgaXb2Ao"
}



2025-07-10 05:57:06,068 - httpcore.connection - DEBUG - close.started
2025-07-10 05:57:06,070 - httpcore.connection - DEBUG - close.complete
‚Üê[92m05:57:06 - LiteLLM:INFO‚Üê[0m: utils.py:1215 - Wrapper: Completed Call, calling success_handler
2025-07-10 05:57:06,071 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
‚Üê[92m05:57:06 - LiteLLM:INFO‚Üê[0m: cost_calculator.py:655 - selected model name for cost calculation: gemini/gemini-1.5-flash
2025-07-10 05:57:06,073 - LiteLLM - INFO - selected model name for cost calculation: gemini/gemini-1.5-flash
‚Üê[92m05:57:06 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:1394 - Logging Details LiteLLM-Success Call: Cache_hit=None
2025-07-10 05:57:06,073 - LiteLLM - DEBUG - Logging Details LiteLLM-Success Call: Cache_hit=None
‚Üê[92m05:57:06 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:57:06,076 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:57:06 - LiteLLM:INFO‚Üê[0m: cost_calculator.py:655 - selected model name for cost calculation: gemini/gemini-1.5-flash
2025-07-10 05:57:06,077 - LiteLLM - INFO - selected model name for cost calculation: gemini/gemini-1.5-flash
‚Üê[92m05:57:06 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:57:06,081 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:57:06 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:57:06,083 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:57:06 - LiteLLM:DEBUG‚Üê[0m: utils.py:4783 - model_info: {'key': 'gemini/gemini-1.5-flash', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 2000}
2025-07-10 05:57:06,086 - LiteLLM - DEBUG - model_info: {'key': 'gemini/gemini-1.5-flash', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 2000}
‚Üê[92m05:57:06 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:57:06,090 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:57:06 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:1131 - response_cost: 3.4275e-05
2025-07-10 05:57:06,102 - LiteLLM - DEBUG - response_cost: 3.4275e-05
‚Üê[92m05:57:06 - LiteLLM:DEBUG‚Üê[0m: utils.py:4783 - model_info: {'key': 'gemini/gemini-1.5-flash', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 2000}
‚úÖ –£—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏ gemini/gemini-1.5-flash
2025-07-10 05:57:06,106 - LiteLLM - DEBUG - model_info: {'key': 'gemini/gemini-1.5-flash', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 2000}
‚Üê[92m05:57:06 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:1131 - response_cost: 3.4275e-05
2025-07-10 05:57:06,116 - tools.gopiai_integration.smart_delegator - INFO - ‚úÖ –û—Ç–≤–µ—Ç –æ—Ç LLM –ø–æ–ª—É—á–µ–Ω
2025-07-10 05:57:06,121 - LiteLLM - DEBUG - response_cost: 3.4275e-05
2025-07-10 05:57:06,126 - tools.gopiai_integration.smart_delegator - INFO - ‚è± –ó–∞–ø—Ä–æ—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∑–∞ 22.83 —Å–µ–∫
‚Üê[92m05:57:06 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
‚è± –ó–∞–ø—Ä–æ—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∑–∞ 22.86 —Å–µ–∫2025-07-10 05:57:06,127 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}

‚Üê[92m05:57:06 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚úÖ –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω, –¥–ª–∏–Ω–∞: 280 —Å–∏–º–≤–æ–ª–æ–≤2025-07-10 05:57:06,131 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}

‚Üê[92m05:57:06 - LiteLLM:DEBUG‚Üê[0m: utils.py:4783 - model_info: {'key': 'gemini/gemini-1.5-flash', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 2000}
2025-07-10 05:57:06,136 - werkzeug - INFO - 127.0.0.1 - - [10/Jul/2025 05:57:06] "POST /api/process HTTP/1.1" 200 -
2025-07-10 05:57:06,134 - LiteLLM - DEBUG - model_info: {'key': 'gemini/gemini-1.5-flash', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 2000}
‚Üê[92m05:57:06 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:1423 - Logging Details LiteLLM-Success Call streaming complete
2025-07-10 05:57:06,152 - LiteLLM - DEBUG - Logging Details LiteLLM-Success Call streaming complete
‚Üê[92m05:57:06 - LiteLLM:INFO‚Üê[0m: cost_calculator.py:655 - selected model name for cost calculation: gemini/gemini-1.5-flash
2025-07-10 05:57:06,154 - LiteLLM - INFO - selected model name for cost calculation: gemini/gemini-1.5-flash
‚Üê[92m05:57:06 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:57:06,156 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:57:06 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:57:06,160 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:57:06 - LiteLLM:DEBUG‚Üê[0m: utils.py:4783 - model_info: {'key': 'gemini/gemini-1.5-flash', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 2000}
2025-07-10 05:57:06,163 - LiteLLM - DEBUG - model_info: {'key': 'gemini/gemini-1.5-flash', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 2000}
‚Üê[92m05:57:06 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:1131 - response_cost: 3.4275e-05
2025-07-10 05:57:06,176 - LiteLLM - DEBUG - response_cost: 3.4275e-05
‚Üê[92m05:57:06 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
2025-07-10 05:57:06,178 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
‚Üê[92m05:57:06 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:57:06,181 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:57:06 - LiteLLM:DEBUG‚Üê[0m: utils.py:4783 - model_info: {'key': 'gemini/gemini-1.5-flash', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 2000}
2025-07-10 05:57:06,188 - LiteLLM - DEBUG - model_info: {'key': 'gemini/gemini-1.5-flash', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 2000}
2025-07-10 05:57:27,319 - werkzeug - INFO - 127.0.0.1 - - [10/Jul/2025 05:57:27] "GET /api/health HTTP/1.1" 200 -
üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: —Å–ª–æ–∂–Ω–æ—Å—Ç—å=0, —Ç–∏–ø=creative, CrewAI=False
üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: —Å–ª–æ–∂–Ω–æ—Å—Ç—å=0, —Ç–∏–ø=creative, CrewAI=False
üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: —Å–ª–æ–∂–Ω–æ—Å—Ç—å=0, —Ç–∏–ø=creative, CrewAI=False
üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: —Å–ª–æ–∂–Ω–æ—Å—Ç—å=0, —Ç–∏–ø=creative, CrewAI=False
2025-07-10 05:57:27,368 - tools.gopiai_integration.smart_delegator - INFO - üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ AI Router...
2025-07-10 05:57:27,368 - tools.gopiai_integration.smart_delegator - INFO - ‚úÖ AI Router –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã
2025-07-10 05:57:27,373 - tools.gopiai_integration.smart_delegator - INFO - –ó–∞–≥—Ä—É–∂–µ–Ω–æ 5 —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞
2025-07-10 05:57:27,373 - tools.gopiai_integration.smart_delegator - INFO - üöÄ –í—ã–∑–æ–≤ LLM —Å –∏—Å—Ç–æ—Ä–∏–µ–π —á–∞—Ç–∞...
2025-07-10 05:57:27,373 - tools.gopiai_integration.smart_delegator - DEBUG - –û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ LLM: [
  {
    "role": "system",
    "content": "–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç."
  },
  {
    "role": "assistant",
    "content": "‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å..."
  },
  {
    "role": "assistant",
    "content": "–Ø –∏–∑–≤–∏–Ω–∏–ª—Å—è –∑–∞ —Ç–æ, —á—Ç–æ –Ω–µ –ø–æ–º–Ω—é –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤.  –Ø —Å–ø—Ä–æ—Å–∏–ª, –∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É —Ç—ã —Ö–æ—á–µ—à—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å, —á—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å.  –£ –º–µ–Ω—è –Ω–µ—Ç –ø–∞–º—è—Ç–∏ –æ –ø—Ä–æ—à–ª—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö, –ø–æ—ç—Ç–æ–º—É –∫–∞–∂–¥—ã–π –Ω–∞—à —Ä–∞–∑–≥–æ–≤–æ—Ä –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞.  –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏, —á—Ç–æ —Ç—ã —Ö–æ—á–µ—à—å, —á—Ç–æ–±—ã —è —Å–¥–µ–ª–∞–ª."
  },
  {
    "role": "assistant",
    "content": "–Ø –∏–∑–≤–∏–Ω–∏–ª—Å—è –∑–∞ —Ç–æ, —á—Ç–æ –Ω–µ –ø–æ–º–Ω—é –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤.  –Ø —Å–ø—Ä–æ—Å–∏–ª, –∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É —Ç—ã —Ö–æ—á–µ—à—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å, —á—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å.  –£ –º–µ–Ω—è –Ω–µ—Ç –ø–∞–º—è—Ç–∏ –æ –ø—Ä–æ—à–ª—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö, –ø–æ—ç—Ç–æ–º—É –∫–∞–∂–¥—ã–π –Ω–∞—à —Ä–∞–∑–≥–æ–≤–æ—Ä –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞.  –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏, —á—Ç–æ —Ç—ã —Ö–æ—á–µ—à—å, —á—Ç–æ–±—ã —è —Å–¥–µ–ª–∞–ª."
  },
  {
    "role": "assistant",
    "content": "–ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?"
  },
  {
    "role": "assistant",
    "content": "‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å..."
  },
  {
    "role": "user",
    "content": "–ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?"
  }
]
[AVAILABLE] –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è 'dialog': ['gemini/gemini-1.5-flash', 'gemini/gemini-2.0-flash-lite', 'gemini/gemini-2.5-flash-lite-preview', 'gemini/gemini-2.5-flash']
[CHECK] –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏ gemini/gemini-1.5-flash —Å 388 —Ç–æ–∫–µ–Ω–∞–º–∏...
[STATS] –ú–æ–¥–µ–ª—å gemini/gemini-1.5-flash: —Ç–µ–∫—É—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ RPM=0/15, TPM=0/250000, RPD=4/50
[OK] –ú–æ–¥–µ–ª—å gemini/gemini-1.5-flash: RPM_OK=True, TPM_OK=True, RPD_OK=True -> RESULT=True
[SELECTED] AI Router: –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å 'gemini/gemini-1.5-flash' (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 3)
2025-07-10 05:57:27,388 - tools.gopiai_integration.smart_delegator - INFO - –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: gemini/gemini-1.5-flash
[AVAILABLE] –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è 'dialog': ['gemini/gemini-1.5-flash', 'gemini/gemini-2.0-flash-lite', 'gemini/gemini-2.5-flash-lite-preview', 'gemini/gemini-2.5-flash']
[CHECK] –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏ gemini/gemini-1.5-flash —Å 388 —Ç–æ–∫–µ–Ω–∞–º–∏...
[STATS] –ú–æ–¥–µ–ª—å gemini/gemini-1.5-flash: —Ç–µ–∫—É—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ RPM=0/15, TPM=0/250000, RPD=4/50
[OK] –ú–æ–¥–µ–ª—å gemini/gemini-1.5-flash: RPM_OK=True, TPM_OK=True, RPD_OK=True -> RESULT=True
[SELECTED] AI Router: –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å 'gemini/gemini-1.5-flash' (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 3)
üîÑ –ü–æ–ø—ã—Ç–∫–∞ 1: –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å gemini/gemini-1.5-flash
‚Üê[92m05:57:27 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 -

2025-07-10 05:57:27,388 - LiteLLM - DEBUG -

‚Üê[92m05:57:27 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - ‚Üê[92mRequest to litellm:‚Üê[0m
2025-07-10 05:57:27,398 - LiteLLM - DEBUG - ‚Üê[92mRequest to litellm:‚Üê[0m
‚Üê[92m05:57:27 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - ‚Üê[92mlitellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'assistant', 'content': '–Ø –∏–∑–≤–∏–Ω–∏–ª—Å—è –∑–∞ —Ç–æ, —á—Ç–æ –Ω–µ –ø–æ–º–Ω—é –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤.  –Ø —Å–ø—Ä–æ—Å–∏–ª, –∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É —Ç—ã —Ö–æ—á–µ—à—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å, —á—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å.  –£ –º–µ–Ω—è –Ω–µ—Ç –ø–∞–º—è—Ç–∏ –æ –ø—Ä–æ—à–ª—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö, –ø–æ—ç—Ç–æ–º—É –∫–∞–∂–¥—ã–π –Ω–∞—à —Ä–∞–∑–≥–æ–≤–æ—Ä –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞.  –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏, —á—Ç–æ —Ç—ã —Ö–æ—á–µ—à—å, —á—Ç–æ–±—ã —è —Å–¥–µ–ª–∞–ª.'}, {'role': 'assistant', 'content': '–Ø –∏–∑–≤–∏–Ω–∏–ª—Å—è –∑–∞ —Ç–æ, —á—Ç–æ –Ω–µ –ø–æ–º–Ω—é –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤.  –Ø —Å–ø—Ä–æ—Å–∏–ª, –∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É —Ç—ã —Ö–æ—á–µ—à—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å, —á—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å.  –£ –º–µ–Ω—è –Ω–µ—Ç –ø–∞–º—è—Ç–∏ –æ –ø—Ä–æ—à–ª—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö, –ø–æ—ç—Ç–æ–º—É –∫–∞–∂–¥—ã–π –Ω–∞—à —Ä–∞–∑–≥–æ–≤–æ—Ä –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞.  –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏, —á—Ç–æ —Ç—ã —Ö–æ—á–µ—à—å, —á—Ç–æ–±—ã —è —Å–¥–µ–ª–∞–ª.'}, {'role': 'assistant', 'content': '–ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}], temperature=0.7, max_tokens=2000)‚Üê[0m
2025-07-10 05:57:27,399 - LiteLLM - DEBUG - ‚Üê[92mlitellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'assistant', 'content': '–Ø –∏–∑–≤–∏–Ω–∏–ª—Å—è –∑–∞ —Ç–æ, —á—Ç–æ –Ω–µ –ø–æ–º–Ω—é –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤.  –Ø —Å–ø—Ä–æ—Å–∏–ª, –∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É —Ç—ã —Ö–æ—á–µ—à—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å, —á—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å.  –£ –º–µ–Ω—è –Ω–µ—Ç –ø–∞–º—è—Ç–∏ –æ –ø—Ä–æ—à–ª—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö, –ø–æ—ç—Ç–æ–º—É –∫–∞–∂–¥—ã–π –Ω–∞—à —Ä–∞–∑–≥–æ–≤–æ—Ä –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞.  –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏, —á—Ç–æ —Ç—ã —Ö–æ—á–µ—à—å, —á—Ç–æ–±—ã —è —Å–¥–µ–ª–∞–ª.'}, {'role': 'assistant', 'content': '–Ø –∏–∑–≤–∏–Ω–∏–ª—Å—è –∑–∞ —Ç–æ, —á—Ç–æ –Ω–µ –ø–æ–º–Ω—é –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤.  –Ø —Å–ø—Ä–æ—Å–∏–ª, –∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É —Ç—ã —Ö–æ—á–µ—à—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å, —á—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å.  –£ –º–µ–Ω—è –Ω–µ—Ç –ø–∞–º—è—Ç–∏ –æ –ø—Ä–æ—à–ª—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö, –ø–æ—ç—Ç–æ–º—É –∫–∞–∂–¥—ã–π –Ω–∞—à —Ä–∞–∑–≥–æ–≤–æ—Ä –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞.  –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏, —á—Ç–æ —Ç—ã —Ö–æ—á–µ—à—å, —á—Ç–æ–±—ã —è —Å–¥–µ–ª–∞–ª.'}, {'role': 'assistant', 'content': '–ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}], temperature=0.7, max_tokens=2000)‚Üê[0m
‚Üê[92m05:57:27 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 -

2025-07-10 05:57:27,405 - LiteLLM - DEBUG -

‚Üê[92m05:57:27 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:461 - self.optional_params: {}
2025-07-10 05:57:27,405 - LiteLLM - DEBUG - self.optional_params: {}
‚Üê[92m05:57:27 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-07-10 05:57:27,415 - LiteLLM - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
‚Üê[92m05:57:27 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
2025-07-10 05:57:27,415 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
‚Üê[92m05:57:27 - LiteLLM:INFO‚Üê[0m: utils.py:3119 -
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-07-10 05:57:27,420 - LiteLLM - INFO -
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
‚Üê[92m05:57:27 - LiteLLM:DEBUG‚Üê[0m: utils.py:3122 -
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.7, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 2000, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'assistant', 'content': '–Ø –∏–∑–≤–∏–Ω–∏–ª—Å—è –∑–∞ —Ç–æ, —á—Ç–æ –Ω–µ –ø–æ–º–Ω—é –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤.  –Ø —Å–ø—Ä–æ—Å–∏–ª, –∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É —Ç—ã —Ö–æ—á–µ—à—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å, —á—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å.  –£ –º–µ–Ω—è –Ω–µ—Ç –ø–∞–º—è—Ç–∏ –æ –ø—Ä–æ—à–ª—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö, –ø–æ—ç—Ç–æ–º—É –∫–∞–∂–¥—ã–π –Ω–∞—à —Ä–∞–∑–≥–æ–≤–æ—Ä –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞.  –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏, —á—Ç–æ —Ç—ã —Ö–æ—á–µ—à—å, —á—Ç–æ–±—ã —è —Å–¥–µ–ª–∞–ª.'}, {'role': 'assistant', 'content': '–Ø –∏–∑–≤–∏–Ω–∏–ª—Å—è –∑–∞ —Ç–æ, —á—Ç–æ –Ω–µ –ø–æ–º–Ω—é –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤.  –Ø —Å–ø—Ä–æ—Å–∏–ª, –∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É —Ç—ã —Ö–æ—á–µ—à—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å, —á—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å.  –£ –º–µ–Ω—è –Ω–µ—Ç –ø–∞–º—è—Ç–∏ –æ –ø—Ä–æ—à–ª—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö, –ø–æ—ç—Ç–æ–º—É –∫–∞–∂–¥—ã–π –Ω–∞—à —Ä–∞–∑–≥–æ–≤–æ—Ä –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞.  –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏, —á—Ç–æ —Ç—ã —Ö–æ—á–µ—à—å, —á—Ç–æ–±—ã —è —Å–¥–µ–ª–∞–ª.'}, {'role': 'assistant', 'content': '–ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}], 'thinking': None, 'web_search_options': None}
2025-07-10 05:57:27,423 - LiteLLM - DEBUG -
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.7, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 2000, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'assistant', 'content': '–Ø –∏–∑–≤–∏–Ω–∏–ª—Å—è –∑–∞ —Ç–æ, —á—Ç–æ –Ω–µ –ø–æ–º–Ω—é –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤.  –Ø —Å–ø—Ä–æ—Å–∏–ª, –∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É —Ç—ã —Ö–æ—á–µ—à—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å, —á—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å.  –£ –º–µ–Ω—è –Ω–µ—Ç –ø–∞–º—è—Ç–∏ –æ –ø—Ä–æ—à–ª—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö, –ø–æ—ç—Ç–æ–º—É –∫–∞–∂–¥—ã–π –Ω–∞—à —Ä–∞–∑–≥–æ–≤–æ—Ä –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞.  –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏, —á—Ç–æ —Ç—ã —Ö–æ—á–µ—à—å, —á—Ç–æ–±—ã —è —Å–¥–µ–ª–∞–ª.'}, {'role': 'assistant', 'content': '–Ø –∏–∑–≤–∏–Ω–∏–ª—Å—è –∑–∞ —Ç–æ, —á—Ç–æ –Ω–µ –ø–æ–º–Ω—é –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤.  –Ø —Å–ø—Ä–æ—Å–∏–ª, –∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É —Ç—ã —Ö–æ—á–µ—à—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å, —á—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å.  –£ –º–µ–Ω—è –Ω–µ—Ç –ø–∞–º—è—Ç–∏ –æ –ø—Ä–æ—à–ª—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö, –ø–æ—ç—Ç–æ–º—É –∫–∞–∂–¥—ã–π –Ω–∞—à —Ä–∞–∑–≥–æ–≤–æ—Ä –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞.  –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏, —á—Ç–æ —Ç—ã —Ö–æ—á–µ—à—å, —á—Ç–æ–±—ã —è —Å–¥–µ–ª–∞–ª.'}, {'role': 'assistant', 'content': '–ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}, {'role': 'assistant', 'content': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'role': 'user', 'content': '–ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}], 'thinking': None, 'web_search_options': None}
‚Üê[92m05:57:27 - LiteLLM:DEBUG‚Üê[0m: utils.py:3125 -
LiteLLM: Non-Default params passed to completion() {'temperature': 0.7, 'max_tokens': 2000}
2025-07-10 05:57:27,423 - LiteLLM - DEBUG -
LiteLLM: Non-Default params passed to completion() {'temperature': 0.7, 'max_tokens': 2000}
‚Üê[92m05:57:27 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - Final returned optional params: {'temperature': 0.7, 'max_output_tokens': 2000}
2025-07-10 05:57:27,437 - LiteLLM - DEBUG - Final returned optional params: {'temperature': 0.7, 'max_output_tokens': 2000}
‚Üê[92m05:57:27 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:461 - self.optional_params: {'temperature': 0.7, 'max_tokens': 2000}
2025-07-10 05:57:27,437 - LiteLLM - DEBUG - self.optional_params: {'temperature': 0.7, 'max_tokens': 2000}
‚Üê[92m05:57:27 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:57:27,437 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:57:27 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:57:27,804 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:57:27 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:908 - ‚Üê[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****gu0Q \
-H 'Content-Type: ap****on' \
-d '{'contents': [{'role': 'model', 'parts': [{'text': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'text': '–Ø –∏–∑–≤–∏–Ω–∏–ª—Å—è –∑–∞ —Ç–æ, —á—Ç–æ –Ω–µ –ø–æ–º–Ω—é –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤.  –Ø —Å–ø—Ä–æ—Å–∏–ª, –∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É —Ç—ã —Ö–æ—á–µ—à—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å, —á—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å.  –£ –º–µ–Ω—è –Ω–µ—Ç –ø–∞–º—è—Ç–∏ –æ –ø—Ä–æ—à–ª—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö, –ø–æ—ç—Ç–æ–º—É –∫–∞–∂–¥—ã–π –Ω–∞—à —Ä–∞–∑–≥–æ–≤–æ—Ä –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞.  –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏, —á—Ç–æ —Ç—ã —Ö–æ—á–µ—à—å, —á—Ç–æ–±—ã —è —Å–¥–µ–ª–∞–ª.'}, {'text': '–Ø –∏–∑–≤–∏–Ω–∏–ª—Å—è –∑–∞ —Ç–æ, —á—Ç–æ –Ω–µ –ø–æ–º–Ω—é –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤.  –Ø —Å–ø—Ä–æ—Å–∏–ª, –∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É —Ç—ã —Ö–æ—á–µ—à—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å, —á—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å.  –£ –º–µ–Ω—è –Ω–µ—Ç –ø–∞–º—è—Ç–∏ –æ –ø—Ä–æ—à–ª—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö, –ø–æ—ç—Ç–æ–º—É –∫–∞–∂–¥—ã–π –Ω–∞—à —Ä–∞–∑–≥–æ–≤–æ—Ä –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞.  –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏, —á—Ç–æ —Ç—ã —Ö–æ—á–µ—à—å, —á—Ç–æ–±—ã —è —Å–¥–µ–ª–∞–ª.'}, {'text': '–ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}, {'text': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}]}, {'role': 'user', 'parts': [{'text': '–ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}]}], 'system_instruction': {'parts': [{'text': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}]}, 'generationConfig': {'temperature': 0.7, 'max_output_tokens': 2000}}'
‚Üê[0m

2025-07-10 05:57:27,807 - LiteLLM - DEBUG - ‚Üê[92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****gu0Q \
-H 'Content-Type: ap****on' \
-d '{'contents': [{'role': 'model', 'parts': [{'text': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}, {'text': '–Ø –∏–∑–≤–∏–Ω–∏–ª—Å—è –∑–∞ —Ç–æ, —á—Ç–æ –Ω–µ –ø–æ–º–Ω—é –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤.  –Ø —Å–ø—Ä–æ—Å–∏–ª, –∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É —Ç—ã —Ö–æ—á–µ—à—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å, —á—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å.  –£ –º–µ–Ω—è –Ω–µ—Ç –ø–∞–º—è—Ç–∏ –æ –ø—Ä–æ—à–ª—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö, –ø–æ—ç—Ç–æ–º—É –∫–∞–∂–¥—ã–π –Ω–∞—à —Ä–∞–∑–≥–æ–≤–æ—Ä –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞.  –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏, —á—Ç–æ —Ç—ã —Ö–æ—á–µ—à—å, —á—Ç–æ–±—ã —è —Å–¥–µ–ª–∞–ª.'}, {'text': '–Ø –∏–∑–≤–∏–Ω–∏–ª—Å—è –∑–∞ —Ç–æ, —á—Ç–æ –Ω–µ –ø–æ–º–Ω—é –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤.  –Ø —Å–ø—Ä–æ—Å–∏–ª, –∫–∞–∫—É—é –ø—Ä–æ—Å—å–±—É —Ç—ã —Ö–æ—á–µ—à—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å, —á—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å.  –£ –º–µ–Ω—è –Ω–µ—Ç –ø–∞–º—è—Ç–∏ –æ –ø—Ä–æ—à–ª—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö, –ø–æ—ç—Ç–æ–º—É –∫–∞–∂–¥—ã–π –Ω–∞—à —Ä–∞–∑–≥–æ–≤–æ—Ä –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞.  –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏, —á—Ç–æ —Ç—ã —Ö–æ—á–µ—à—å, —á—Ç–æ–±—ã —è —Å–¥–µ–ª–∞–ª.'}, {'text': '–ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}, {'text': '‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...'}]}, {'role': 'user', 'parts': [{'text': '–ü–æ–º–Ω–∏—à—å, —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ç–µ–±–µ –æ –∫–æ–º-—Ç–æ, –∫–æ–≥–æ —è –Ω–∞–∑—ã–≤–∞—é –∑–æ–ª–æ—Ç–æ–π —Ä—ã–±–∫–æ–π - –∫—Ç–æ —ç—Ç–æ –±—ã–ª?'}]}], 'system_instruction': {'parts': [{'text': '–¢—ã - GopiAI, –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'}]}, 'generationConfig': {'temperature': 0.7, 'max_output_tokens': 2000}}'
‚Üê[0m

2025-07-10 05:57:28,174 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None
2025-07-10 05:57:28,211 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025732CCC080>
2025-07-10 05:57:28,212 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000025732E93BD0> server_hostname='generativelanguage.googleapis.com' timeout=600.0
2025-07-10 05:57:28,253 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025732CCC0B0>
2025-07-10 05:57:28,254 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-10 05:57:28,255 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-07-10 05:57:28,257 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-10 05:57:28,258 - httpcore.http11 - DEBUG - send_request_body.complete
2025-07-10 05:57:28,258 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-10 05:57:34,265 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 10 Jul 2025 00:27:25 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=5982'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-10 05:57:34,273 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyD2taiOJ6Z7nLcVQrz_U0ct4G0HlyLgu0Q "HTTP/1.1 200 OK"
2025-07-10 05:57:34,276 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-10 05:57:34,276 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-07-10 05:57:34,276 - httpcore.http11 - DEBUG - response_closed.started
2025-07-10 05:57:34,276 - httpcore.http11 - DEBUG - response_closed.complete
‚Üê[92m05:57:34 - LiteLLM:DEBUG‚Üê[0m: utils.py:340 - RAW RESPONSE:
{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "–ò–∑–≤–∏–Ω–∏, –Ω–æ —É –º–µ–Ω—è –Ω–µ—Ç –ø–∞–º—è—Ç–∏ –æ –ø—Ä–æ—à–ª—ã—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–∞—Ö.  –ö–∞–∂–¥—ã–π –Ω–∞—à –¥–∏–∞–ª–æ–≥ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –∑–∞–Ω–æ–≤–æ.  –ß—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, —Ä–∞—Å—Å–∫–∞–∂–∏ –º–Ω–µ, –∫—Ç–æ —Ç–∞–∫–∞—è ¬´–∑–æ–ª–æ—Ç–∞—è —Ä—ã–±–∫–∞¬ª.\n"
          }
        ],
        "role": "model"
      },
      "finishReason": "STOP",
      "avgLogprobs": -0.0876272201538086
    }
  ],
  "usageMetadata": {
    "promptTokenCount": 217,
    "candidatesTokenCount": 45,
    "totalTokenCount": 262,
    "promptTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 217
      }
    ],
    "candidatesTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 45
      }
    ]
  },
  "modelVersion": "gemini-1.5-flash",
  "responseId": "6QhvaIW3C93_698PvLbvwQw"
}



2025-07-10 05:57:34,276 - LiteLLM - DEBUG - RAW RESPONSE:
{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "–ò–∑–≤–∏–Ω–∏, –Ω–æ —É –º–µ–Ω—è –Ω–µ—Ç –ø–∞–º—è—Ç–∏ –æ –ø—Ä–æ—à–ª—ã—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–∞—Ö.  –ö–∞–∂–¥—ã–π –Ω–∞—à –¥–∏–∞–ª–æ–≥ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –∑–∞–Ω–æ–≤–æ.  –ß—Ç–æ–±—ã —è –º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, —Ä–∞—Å—Å–∫–∞–∂–∏ –º–Ω–µ, –∫—Ç–æ —Ç–∞–∫–∞—è ¬´–∑–æ–ª–æ—Ç–∞—è —Ä—ã–±–∫–∞¬ª.\n"
          }
        ],
        "role": "model"
      },
      "finishReason": "STOP",
      "avgLogprobs": -0.0876272201538086
    }
  ],
  "usageMetadata": {
    "promptTokenCount": 217,
    "candidatesTokenCount": 45,
    "totalTokenCount": 262,
    "promptTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 217
      }
    ],
    "candidatesTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 45
      }
    ]
  },
  "modelVersion": "gemini-1.5-flash",
  "responseId": "6QhvaIW3C93_698PvLbvwQw"
}



2025-07-10 05:57:34,298 - httpcore.connection - DEBUG - close.started
2025-07-10 05:57:34,298 - httpcore.connection - DEBUG - close.complete
‚Üê[92m05:57:34 - LiteLLM:INFO‚Üê[0m: utils.py:1215 - Wrapper: Completed Call, calling success_handler
2025-07-10 05:57:34,303 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
‚Üê[92m05:57:34 - LiteLLM:INFO‚Üê[0m: cost_calculator.py:655 - selected model name for cost calculation: gemini/gemini-1.5-flash
2025-07-10 05:57:34,306 - LiteLLM - INFO - selected model name for cost calculation: gemini/gemini-1.5-flash
‚Üê[92m05:57:34 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:1394 - Logging Details LiteLLM-Success Call: Cache_hit=None
2025-07-10 05:57:34,306 - LiteLLM - DEBUG - Logging Details LiteLLM-Success Call: Cache_hit=None
‚Üê[92m05:57:34 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:57:34,307 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:57:34 - LiteLLM:INFO‚Üê[0m: cost_calculator.py:655 - selected model name for cost calculation: gemini/gemini-1.5-flash
2025-07-10 05:57:34,307 - LiteLLM - INFO - selected model name for cost calculation: gemini/gemini-1.5-flash
‚Üê[92m05:57:34 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:57:34,307 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:57:34 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:57:34,307 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:57:34 - LiteLLM:DEBUG‚Üê[0m: utils.py:4783 - model_info: {'key': 'gemini/gemini-1.5-flash', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 2000}
2025-07-10 05:57:34,307 - LiteLLM - DEBUG - model_info: {'key': 'gemini/gemini-1.5-flash', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 2000}
‚Üê[92m05:57:34 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:57:34,318 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:57:34 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:1131 - response_cost: 2.9775e-05
2025-07-10 05:57:34,323 - LiteLLM - DEBUG - response_cost: 2.9775e-05
‚Üê[92m05:57:34 - LiteLLM:DEBUG‚Üê[0m: utils.py:4783 - model_info: {'key': 'gemini/gemini-1.5-flash', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 2000}
‚úÖ –£—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏ gemini/gemini-1.5-flash2025-07-10 05:57:34,323 - LiteLLM - DEBUG - model_info: {'key': 'gemini/gemini-1.5-flash', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 2000}

‚Üê[92m05:57:34 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:1131 - response_cost: 2.9775e-05
2025-07-10 05:57:34,344 - tools.gopiai_integration.smart_delegator - INFO - ‚úÖ –û—Ç–≤–µ—Ç –æ—Ç LLM –ø–æ–ª—É—á–µ–Ω
2025-07-10 05:57:34,344 - LiteLLM - DEBUG - response_cost: 2.9775e-05
2025-07-10 05:57:34,344 - tools.gopiai_integration.smart_delegator - INFO - ‚è± –ó–∞–ø—Ä–æ—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∑–∞ 6.98 —Å–µ–∫
‚Üê[92m05:57:34 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
‚è± –ó–∞–ø—Ä–æ—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∑–∞ 6.98 —Å–µ–∫2025-07-10 05:57:34,348 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}

‚Üê[92m05:57:34 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚úÖ –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω, –¥–ª–∏–Ω–∞: 168 —Å–∏–º–≤–æ–ª–æ–≤2025-07-10 05:57:34,348 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}

‚Üê[92m05:57:34 - LiteLLM:DEBUG‚Üê[0m: utils.py:4783 - model_info: {'key': 'gemini/gemini-1.5-flash', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 2000}
2025-07-10 05:57:34,356 - werkzeug - INFO - 127.0.0.1 - - [10/Jul/2025 05:57:34] "POST /api/process HTTP/1.1" 200 -
2025-07-10 05:57:34,354 - LiteLLM - DEBUG - model_info: {'key': 'gemini/gemini-1.5-flash', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 2000}
‚Üê[92m05:57:34 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:1423 - Logging Details LiteLLM-Success Call streaming complete
2025-07-10 05:57:34,369 - LiteLLM - DEBUG - Logging Details LiteLLM-Success Call streaming complete
‚Üê[92m05:57:34 - LiteLLM:INFO‚Üê[0m: cost_calculator.py:655 - selected model name for cost calculation: gemini/gemini-1.5-flash
2025-07-10 05:57:34,373 - LiteLLM - INFO - selected model name for cost calculation: gemini/gemini-1.5-flash
‚Üê[92m05:57:34 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:57:34,373 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:57:34 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:57:34,373 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:57:34 - LiteLLM:DEBUG‚Üê[0m: utils.py:4783 - model_info: {'key': 'gemini/gemini-1.5-flash', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 2000}
2025-07-10 05:57:34,373 - LiteLLM - DEBUG - model_info: {'key': 'gemini/gemini-1.5-flash', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 2000}
‚Üê[92m05:57:34 - LiteLLM:DEBUG‚Üê[0m: litellm_logging.py:1131 - response_cost: 2.9775e-05
2025-07-10 05:57:34,386 - LiteLLM - DEBUG - response_cost: 2.9775e-05
‚Üê[92m05:57:34 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
2025-07-10 05:57:34,386 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
‚Üê[92m05:57:34 - LiteLLM:DEBUG‚Üê[0m: utils.py:4481 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-07-10 05:57:34,398 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
‚Üê[92m05:57:34 - LiteLLM:DEBUG‚Üê[0m: utils.py:4783 - model_info: {'key': 'gemini/gemini-1.5-flash', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 2000}
2025-07-10 05:57:34,402 - LiteLLM - DEBUG - model_info: {'key': 'gemini/gemini-1.5-flash', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 7.5e-08, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 3e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': None, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': None, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': 4000000, 'rpm': 2000}
