#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Скрипт для очистки проекта GopiAI от неиспользуемых и временных файлов.

Этот скрипт анализирует структуру проекта, находит потенциально ненужные файлы
и предлагает их удалить или архивировать.
"""

import argparse
import datetime
import json
import mimetypes
import os
import re
import shutil
import sys
import zipfile
from collections import defaultdict
from pathlib import Path

# Шаблоны временных/автогенерируемых файлов
TEMP_FILE_PATTERNS = [
    r'.*\.pyc$',
    r'.*\.pyo$',
    r'.*\.bak$',
    r'.*\.tmp$',
    r'.*\.temp$',
    r'.*~$',
    r'\.DS_Store$',
    r'Thumbs\.db$',
    r'desktop\.ini$',
    r'.*\.log$',
    r'.*_log\.txt$',
    r'.*\.swp$',
]

# Потенциально ненужные расширения файлов
POTENTIALLY_UNUSED_EXTENSIONS = [
    '.rc', '.qrc', '.bat', '.sh', '.cmd', '.exe', '.dll', '.so',
    '.o', '.obj', '.a', '.lib', '.spec', '.cache'
]

# Специальные директории, которые могут содержать ненужные файлы
SPECIAL_DIRS = [
    'venv', '__pycache__', '.pytest_cache', '.tox', '.coverage',
    'logs', 'temp', 'tmp', 'picked_icons', 'workspace',
    '.backup', 'duplication_data', 'vulture_reports'
]

# Файлы, которые никогда не должны быть отмечены как ненужные
SAFELIST_FILES = [
    'requirements.txt', 'setup.py', 'README.md', 'LICENSE', '.gitignore',
    '.gitattributes', 'main.py', 'run_with_venv.py', 'run_with_venv.bat'
]

# Путь к файлу с белым списком
SAFELIST_PATH = 'project_safelist.txt'


class ProjectCleaner:
    """Класс для анализа и очистки проекта от ненужных файлов."""

    def __init__(self):
        """Инициализация анализатора проекта."""
        self.project_root = Path(os.getcwd())
        self.unused_files = []
        self.special_dirs_content = defaultdict(list)
        self.report_data = {
            'temp_files': [],
            'potentially_unused_files': [],
            'special_dirs': {},
            'large_files': [],
            'auto_generated_files': [],
            'backup_files': []
        }

        # Загрузка белого списка из файла
        self.safelist = SAFELIST_FILES.copy()
        if os.path.exists(SAFELIST_PATH):
            with open(SAFELIST_PATH, 'r', encoding='utf-8') as f:
                self.safelist.extend([line.strip() for line in f if line.strip()])

        # Скомпилированные шаблоны регулярных выражений
        self.temp_patterns = [re.compile(pattern) for pattern in TEMP_FILE_PATTERNS]

    def is_on_safelist(self, path):
        """Проверяет, находится ли файл в белом списке."""
        path_str = str(path)

        # Проверка по имени файла
        if os.path.basename(path_str) in self.safelist:
            return True

        # Проверка по полному пути
        for safe_item in self.safelist:
            if safe_item in path_str:
                return True

        return False

    def is_temp_file(self, path):
        """Проверяет, является ли файл временным."""
        path_str = str(path)
        for pattern in self.temp_patterns:
            if pattern.match(path_str):
                return True
        return False

    def is_potentially_unused(self, path):
        """Проверяет, является ли файл потенциально неиспользуемым."""
        if path.suffix.lower() in POTENTIALLY_UNUSED_EXTENSIONS:
            # Проверка, что файл не является важным скриптом
            if path.suffix.lower() in ['.bat', '.sh', '.cmd'] and self.is_important_script(path):
                return False
            return True
        return False

    def is_important_script(self, path):
        """Проверяет, является ли скрипт важным для проекта."""
        # Чтение первых строк файла для анализа
        try:
            with open(path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read(2000)  # Читаем первые 2000 символов

                # Проверка на наличие важных команд или импортов
                if re.search(r'(python|pip|import|venv|virtualenv|main\.py)', content, re.IGNORECASE):
                    return True

                # Проверка на наличие вызовов команд активации окружения
                if re.search(r'(activate|env|source)', content, re.IGNORECASE):
                    return True
        except:
            pass

        return False

    def is_auto_generated(self, path):
        """Проверяет, является ли файл автоматически сгенерированным."""
        try:
            with open(path, 'r', encoding='utf-8', errors='ignore') as f:
                first_lines = ''.join([f.readline() for _ in range(5)])
                # Поиск типичных маркеров автогенерированных файлов
                if re.search(r'(auto[- ]generated|generated by|do not edit|не редактируйте)',
                             first_lines, re.IGNORECASE):
                    return True
        except:
            pass
        return False

    def is_backup_file(self, path):
        """Проверяет, является ли файл резервной копией."""
        file_name = path.name.lower()
        if any(s in file_name for s in ['backup', 'bak', 'copy', 'old', 'prev']):
            return True
        return False

    def is_large_file(self, path, size_threshold_mb=10):
        """Проверяет, является ли файл слишком большим."""
        if path.is_file():
            size_mb = os.path.getsize(path) / (1024 * 1024)
            if size_mb > size_threshold_mb:
                return size_mb
        return 0

    def analyze_project(self):
        """Анализирует проект и находит файлы-кандидаты на удаление."""
        print(f"Анализ проекта в директории: {self.project_root}")

        # Общие счетчики
        total_files = 0
        processed_files = 0

        # Обход всех директорий проекта
        for root, dirs, files in os.walk(self.project_root, topdown=True):
            path = Path(root)

            # Пропускаем скрытые директории и .git
            dirs[:] = [d for d in dirs if not d.startswith('.git')]

            # Проверка специальных директорий
            rel_path = path.relative_to(self.project_root)

            # Анализ специальных директорий
            for special_dir in SPECIAL_DIRS:
                if special_dir in str(rel_path):
                    if not special_dir in self.report_data['special_dirs']:
                        self.report_data['special_dirs'][special_dir] = {
                            'path': str(rel_path),
                            'size_mb': self.get_dir_size(path) / (1024 * 1024),
                            'files_count': sum(len(files) for _, _, files in os.walk(path)),
                            'last_modified': datetime.datetime.fromtimestamp(
                                os.path.getmtime(path)).strftime('%Y-%m-%d %H:%M:%S')
                        }

            # Анализ файлов
            for file in files:
                file_path = path / file
                total_files += 1

                # Пропускаем файлы из белого списка
                if self.is_on_safelist(file_path):
                    continue

                processed_files += 1

                # Проверяем на временные файлы
                if self.is_temp_file(file_path):
                    self.report_data['temp_files'].append(str(file_path.relative_to(self.project_root)))

                # Проверяем на потенциально неиспользуемые файлы
                if self.is_potentially_unused(file_path):
                    self.report_data['potentially_unused_files'].append(str(file_path.relative_to(self.project_root)))

                # Проверяем на автогенерированные файлы
                if self.is_auto_generated(file_path):
                    self.report_data['auto_generated_files'].append(str(file_path.relative_to(self.project_root)))

                # Проверяем на резервные копии
                if self.is_backup_file(file_path):
                    self.report_data['backup_files'].append(str(file_path.relative_to(self.project_root)))

                # Проверяем размер файла
                file_size = self.is_large_file(file_path)
                if file_size > 0:
                    self.report_data['large_files'].append({
                        'path': str(file_path.relative_to(self.project_root)),
                        'size_mb': round(file_size, 2)
                    })

        print(f"Проанализировано файлов: {processed_files} из {total_files}")
        return self.report_data

    def get_dir_size(self, path):
        """Возвращает размер директории в байтах."""
        total_size = 0
        for dirpath, _, filenames in os.walk(path):
            for f in filenames:
                fp = os.path.join(dirpath, f)
                if os.path.isfile(fp):
                    total_size += os.path.getsize(fp)
        return total_size

    def generate_report(self, output_file="project_cleaning_report.json"):
        """Генерирует отчет о найденных файлах."""
        # Добавляем метаданные отчета
        report = {
            'metadata': {
                'timestamp': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'project_root': str(self.project_root),
                'summary': {
                    'temp_files_count': len(self.report_data['temp_files']),
                    'potentially_unused_files_count': len(self.report_data['potentially_unused_files']),
                    'special_dirs_count': len(self.report_data['special_dirs']),
                    'large_files_count': len(self.report_data['large_files']),
                    'auto_generated_files_count': len(self.report_data['auto_generated_files']),
                    'backup_files_count': len(self.report_data['backup_files'])
                }
            },
            'data': self.report_data
        }

        # Вычисляем общий размер потенциально удаляемых файлов
        total_size_mb = 0
        # Временные файлы
        for file_path in self.report_data['temp_files']:
            try:
                total_size_mb += os.path.getsize(file_path) / (1024 * 1024)
            except:
                pass

        # Потенциально ненужные файлы
        for file_path in self.report_data['potentially_unused_files']:
            try:
                total_size_mb += os.path.getsize(file_path) / (1024 * 1024)
            except:
                pass

        # Специальные директории
        for dir_info in self.report_data['special_dirs'].values():
            total_size_mb += dir_info['size_mb']

        report['metadata']['summary']['total_size_mb'] = round(total_size_mb, 2)

        # Сохраняем отчет
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        # Генерируем текстовый отчет для чтения пользователем
        self.generate_text_report(report, output_file.replace('.json', '.txt'))

        return output_file

    def generate_text_report(self, report, output_file):
        """Генерирует текстовый отчет для чтения пользователем."""
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("=== ОТЧЕТ ПО ОЧИСТКЕ ПРОЕКТА ===\n")
            f.write(f"Дата создания: {report['metadata']['timestamp']}\n")
            f.write(f"Корневая директория проекта: {report['metadata']['project_root']}\n\n")

            f.write("=== СВОДНАЯ ИНФОРМАЦИЯ ===\n")
            summary = report['metadata']['summary']
            f.write(f"- Временные файлы: {summary['temp_files_count']}\n")
            f.write(f"- Потенциально неиспользуемые файлы: {summary['potentially_unused_files_count']}\n")
            f.write(f"- Специальные директории: {summary['special_dirs_count']}\n")
            f.write(f"- Большие файлы: {summary['large_files_count']}\n")
            f.write(f"- Автогенерированные файлы: {summary['auto_generated_files_count']}\n")
            f.write(f"- Резервные копии: {summary['backup_files_count']}\n")
            f.write(f"- Общий размер потенциально удаляемых файлов: {summary['total_size_mb']} МБ\n\n")

            # Выводим информацию о специальных директориях
            f.write("=== СПЕЦИАЛЬНЫЕ ДИРЕКТОРИИ ===\n")
            for dir_name, dir_info in report['data']['special_dirs'].items():
                f.write(f"- {dir_name}\n")
                f.write(f"  Путь: {dir_info['path']}\n")
                f.write(f"  Размер: {round(dir_info['size_mb'], 2)} МБ\n")
                f.write(f"  Количество файлов: {dir_info['files_count']}\n")
                f.write(f"  Последнее изменение: {dir_info['last_modified']}\n\n")

            # Выводим информацию о больших файлах
            if report['data']['large_files']:
                f.write("=== БОЛЬШИЕ ФАЙЛЫ ===\n")
                for file_info in sorted(report['data']['large_files'],
                                       key=lambda x: x['size_mb'], reverse=True):
                    f.write(f"- {file_info['path']} ({file_info['size_mb']} МБ)\n")
                f.write("\n")

            # Выводим информацию о временных файлах
            if report['data']['temp_files']:
                f.write("=== ВРЕМЕННЫЕ ФАЙЛЫ ===\n")
                for file_path in sorted(report['data']['temp_files']):
                    f.write(f"- {file_path}\n")
                f.write("\n")

            # Выводим информацию о потенциально неиспользуемых файлах
            if report['data']['potentially_unused_files']:
                f.write("=== ПОТЕНЦИАЛЬНО НЕИСПОЛЬЗУЕМЫЕ ФАЙЛЫ ===\n")
                for file_path in sorted(report['data']['potentially_unused_files']):
                    f.write(f"- {file_path}\n")
                f.write("\n")

            # Выводим информацию о автогенерированных файлах
            if report['data']['auto_generated_files']:
                f.write("=== АВТОГЕНЕРИРОВАННЫЕ ФАЙЛЫ ===\n")
                for file_path in sorted(report['data']['auto_generated_files']):
                    f.write(f"- {file_path}\n")
                f.write("\n")

            # Выводим информацию о резервных копиях
            if report['data']['backup_files']:
                f.write("=== РЕЗЕРВНЫЕ КОПИИ ===\n")
                for file_path in sorted(report['data']['backup_files']):
                    f.write(f"- {file_path}\n")
                f.write("\n")

            f.write("=== РЕКОМЕНДАЦИИ ПО ОЧИСТКЕ ===\n")
            f.write("1. Удалите временные файлы (*.pyc, *.bak, *.tmp)\n")
            f.write("2. Проверьте и при необходимости удалите специальные директории (venv, logs, tmp)\n")
            f.write("3. Проанализируйте большие файлы, возможно, их стоит переместить или архивировать\n")
            f.write("4. Проверьте потенциально неиспользуемые файлы на предмет их актуальности\n")
            f.write("5. Автогенерированные файлы могут быть удалены, если они могут быть восстановлены\n")
            f.write("6. Резервные копии можно архивировать для экономии места\n")

            f.write("\n=== КАК ИСПОЛЬЗОВАТЬ ===\n")
            f.write("Для удаления файлов запустите скрипт с параметром --clean:\n")
            f.write("python clean_project.py --clean\n")
            f.write("Для создания архива перед удалением файлов используйте параметр --backup:\n")
            f.write("python clean_project.py --clean --backup\n")
            f.write("Для удаления только временных файлов используйте параметр --temp-only:\n")
            f.write("python clean_project.py --clean --temp-only\n")

    def archive_before_cleaning(self, archive_name="project_backup"):
        """Создает архив проекта перед очисткой."""
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        archive_name = f"{archive_name}_{timestamp}.zip"

        print(f"Создание архива проекта: {archive_name}")

        with zipfile.ZipFile(archive_name, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for root, dirs, files in os.walk(self.project_root):
                # Исключаем сам архивный файл
                if archive_name in root:
                    continue

                # Исключаем директории venv и __pycache__
                if '__pycache__' in root or 'venv' in root:
                    continue

                # Добавляем файлы
                for file in files:
                    file_path = os.path.join(root, file)
                    if file_path == os.path.join(self.project_root, archive_name):
                        continue

                    rel_path = os.path.relpath(file_path, self.project_root)
                    zipf.write(file_path, rel_path)

        print(f"Архив создан: {archive_name}")
        return archive_name

    def clean_project(self, temp_only=False):
        """Удаляет найденные ненужные файлы."""
        deleted_files = []
        deleted_dirs = []

        # Удаляем временные файлы
        for file_path in self.report_data['temp_files']:
            try:
                full_path = self.project_root / file_path
                if full_path.exists():
                    os.remove(full_path)
                    deleted_files.append(file_path)
            except Exception as e:
                print(f"Ошибка при удалении файла {file_path}: {e}")

        # Если требуется удалить только временные файлы, возвращаем результат
        if temp_only:
            return {'deleted_files': deleted_files, 'deleted_dirs': deleted_dirs}

        # Удаляем потенциально неиспользуемые файлы
        for file_path in self.report_data['potentially_unused_files']:
            try:
                full_path = self.project_root / file_path
                if full_path.exists():
                    os.remove(full_path)
                    deleted_files.append(file_path)
            except Exception as e:
                print(f"Ошибка при удалении файла {file_path}: {e}")

        # Удаляем автогенерированные файлы
        for file_path in self.report_data['auto_generated_files']:
            try:
                full_path = self.project_root / file_path
                if full_path.exists():
                    os.remove(full_path)
                    deleted_files.append(file_path)
            except Exception as e:
                print(f"Ошибка при удалении файла {file_path}: {e}")

        # Удаляем резервные копии
        for file_path in self.report_data['backup_files']:
            try:
                full_path = self.project_root / file_path
                if full_path.exists():
                    os.remove(full_path)
                    deleted_files.append(file_path)
            except Exception as e:
                print(f"Ошибка при удалении файла {file_path}: {e}")

        return {'deleted_files': deleted_files, 'deleted_dirs': deleted_dirs}


def main():
    parser = argparse.ArgumentParser(
        description='Анализ и очистка проекта от неиспользуемых и временных файлов'
    )
    parser.add_argument('--analyze', action='store_true',
                      help='Только анализ проекта без удаления файлов')
    parser.add_argument('--clean', action='store_true',
                      help='Удаление файлов после анализа')
    parser.add_argument('--backup', action='store_true',
                      help='Создание архива проекта перед очисткой')
    parser.add_argument('--temp-only', action='store_true',
                      help='Удаление только временных файлов')
    parser.add_argument('--output', default='project_cleaning_reports',
                      help='Директория для сохранения отчетов')

    args = parser.parse_args()

    # По умолчанию только анализируем
    if not args.analyze and not args.clean:
        args.analyze = True

    # Создаем директорию для отчетов, если она не существует
    if not os.path.exists(args.output):
        os.makedirs(args.output)

    timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
    output_json = os.path.join(args.output, f"cleaning_report_{timestamp}.json")

    cleaner = ProjectCleaner()
    data = cleaner.analyze_project()
    report_path = cleaner.generate_report(output_json)

    print(f"Отчет сохранен в: {report_path}")
    print(f"Сводная информация:")
    print(f"- Временные файлы: {len(data['temp_files'])}")
    print(f"- Потенциально неиспользуемые файлы: {len(data['potentially_unused_files'])}")
    print(f"- Специальные директории: {len(data['special_dirs'])}")
    print(f"- Большие файлы: {len(data['large_files'])}")
    print(f"- Автогенерированные файлы: {len(data['auto_generated_files'])}")
    print(f"- Резервные копии: {len(data['backup_files'])}")

    if args.clean:
        if args.backup:
            backup_file = cleaner.archive_before_cleaning()
            print(f"Создан архив проекта: {backup_file}")

        result = cleaner.clean_project(args.temp_only)
        print(f"Удалено файлов: {len(result['deleted_files'])}")
        print(f"Удалено директорий: {len(result['deleted_dirs'])}")

        # Сохраняем информацию о удаленных файлах
        cleanup_results = os.path.join(args.output, f"cleanup_results_{timestamp}.txt")
        with open(cleanup_results, 'w', encoding='utf-8') as f:
            f.write("=== УДАЛЕННЫЕ ФАЙЛЫ ===\n")
            for file_path in sorted(result['deleted_files']):
                f.write(f"- {file_path}\n")

            f.write("\n=== УДАЛЕННЫЕ ДИРЕКТОРИИ ===\n")
            for dir_path in sorted(result['deleted_dirs']):
                f.write(f"- {dir_path}\n")

        print(f"Информация о удаленных файлах сохранена в: {cleanup_results}")


if __name__ == "__main__":
    main()
