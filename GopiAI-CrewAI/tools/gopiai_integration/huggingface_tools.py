"""
ü§ó Hugging Face LLM Tool –¥–ª—è GopiAI-CrewAI
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Hugging Face Inference API
"""

import os
import json
import requests
from typing import Type, Any, Dict, Optional
from datetime import datetime
from pydantic import BaseModel, Field
from crewai.tools.base_tool import BaseTool

class HuggingFaceInput(BaseModel):
    """–°—Ö–µ–º–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è Hugging Face"""
    message: str = Field(description="–°–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –º–æ–¥–µ–ª–∏")
    model_name: str = Field(default="tiiuae/falcon-7b-instruct", description="–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ HF (–Ω–∞–ø—Ä–∏–º–µ—Ä, tiiuae/falcon-7b-instruct, bigscience/bloomz-560m, tiiuae/falcon-7b-instruct, tiiuae/falcon-7b-instruct)")
    task_type: str = Field(default="text-generation", description="–¢–∏–ø –∑–∞–¥–∞—á–∏")
    max_length: int = Field(default=200, description="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞")
    temperature: float = Field(default=0.7, description="–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")

class GopiAIHuggingFaceTool(BaseTool):
    """
    –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Hugging Face –º–æ–¥–µ–ª—è–º–∏
    
    –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
    - –î–æ—Å—Ç—É–ø –∫ —Ç—ã—Å—è—á–∞–º –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
    - –†–∞–∑–ª–∏—á–Ω—ã–µ —Ç–∏–ø—ã –∑–∞–¥–∞—á (—Ç–µ–∫—Å—Ç, –∫–æ–¥, —á–∞—Ç)
    - –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ª–∏–º–∏—Ç–æ–≤
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –ø–æ –∑–∞–¥–∞—á–µ
    """
    
    name: str = Field(default="gopiai_huggingface", description="–ò–º—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞")
    description: str = Field(default="–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç HuggingFace –¥–ª—è CrewAI", description="–û–ø–∏—Å–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞")

    def run(self, message: str, model_name: str = "tiiuae/falcon-7b-instruct", 
            task_type: str = "text-generation", max_length: int = 200, temperature: float = 0.7) -> str:
        """
        –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –∫ Hugging Face Inference API
        –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∑–∞–¥–∞—á: text-generation, text2text-generation, text-classification, conversational, code, chat
        """
        api_key = os.getenv('HUGGINGFACE_API_KEY')
        if not api_key:
            return "‚ùå HUGGINGFACE_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è"
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        payload = {}
        # –§–æ—Ä–º–∏—Ä—É–µ–º payload –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏
        if task_type in ["text-generation", "code-generation", "text2text-generation"]:
            payload = {
                "inputs": message,
                "parameters": {
                    "max_length": max_length,
                    "temperature": temperature,
                    "do_sample": True,
                    "top_p": 0.9
                }
            }
        elif task_type in ["conversational", "chat"]:
            # –î–ª—è chat –º–æ–¥–µ–ª–µ–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, Llama-2-chat, Falcon-chat)
            payload = {
                "inputs": {
                    "text": message
                },
                "parameters": {
                    "max_length": max_length,
                    "temperature": temperature,
                    "do_sample": True,
                    "top_p": 0.9
                }
            }
        elif task_type == "text-classification":
            payload = {"inputs": message}
        else:
            payload = {"inputs": message}
        try:
            response = requests.post(
                f"https://api-inference.huggingface.co/models/{model_name}",
                headers=headers,
                json=payload,
                timeout=60
            )
            if response.status_code == 200:
                data = response.json()
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –æ—Ç–≤–µ—Ç–∞
                if isinstance(data, list):
                    if len(data) > 0 and "generated_text" in data[0]:
                        generated_text = data[0]["generated_text"]
                        if generated_text.startswith(message):
                            generated_text = generated_text[len(message):].strip()
                        return generated_text or str(data)
                    elif len(data) > 0 and "label" in data[0]:
                        # text-classification
                        return f"–ö–ª–∞—Å—Å: {data[0]['label']}, score: {data[0].get('score', '')}"
                    else:
                        return str(data)
                elif isinstance(data, dict):
                    if "generated_text" in data:
                        return data["generated_text"]
                    elif "conversation" in data:
                        # conversational/chat
                        return data["conversation"].get("generated_responses", [""])[-1]
                    elif "labels" in data:
                        return str(data["labels"])
                    else:
                        return str(data)
                else:
                    return str(data)
            elif response.status_code == 503:
                return "‚è≥ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —á–µ—Ä–µ–∑ 20 —Å–µ–∫—É–Ω–¥"
            elif response.status_code == 429:
                return "‚ö†Ô∏è –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ (1000/–º–µ—Å—è—Ü)"
            else:
                return f"‚ùå API –æ—à–∏–±–∫–∞: {response.status_code} {response.text}"
        except requests.exceptions.Timeout:
            return "‚è∞ –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ (60 —Å–µ–∫)"
        except requests.exceptions.RequestException as e:
            return f"üåê –°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞: {str(e)}"
        except Exception as e:
            return f"‚ùå –û—à–∏–±–∫–∞ HuggingFace Tool: {str(e)}"


    def _run(self, *args, **kwargs):
        """
        –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫: –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –≤—Å–µ—Ö –∑–∞–¥–∞—á HF (text, code, chat, classification)
        """
        message = kwargs.get('message') or (args[0] if args else None)
        if message is None:
            return "‚ùå –ù–µ –ø–µ—Ä–µ–¥–∞–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è HuggingFace Tool"
        model_name = kwargs.get('model_name', "tiiuae/falcon-7b-instruct")
        task_type = kwargs.get('task_type', "text-generation")
        max_length = kwargs.get('max_length', 200)
        temperature = kwargs.get('temperature', 0.7)
        return self.run(str(message), model_name, task_type, max_length, temperature)
    def get_usage_stats(self) -> str:
        return "(—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –≤ —ç—Ç–æ–π –≤–µ—Ä—Å–∏–∏)"

    # print("‚úÖ Hugging Face Tool –≥–æ—Ç–æ–≤!")  # —É–±—Ä–∞–Ω–æ –∏–∑ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞

