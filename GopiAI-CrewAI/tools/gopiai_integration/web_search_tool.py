"""
üîç GopiAI Web Search Tool –¥–ª—è CrewAI
–ü—Ä–æ—Å—Ç–æ–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä–∞–∑–Ω—ã—Ö –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º
"""

import requests
import logging
import os
from typing import Type, Any, Optional, Dict, List
from pydantic import BaseModel, Field
from bs4 import BeautifulSoup
import json
import time
from urllib.parse import quote_plus

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º BaseTool –∏–∑ crewai
from crewai.tools.base_tool import BaseTool

class WebSearchInput(BaseModel):
    """–°—Ö–µ–º–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –ø–æ–∏—Å–∫–∞ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ"""
    query: str = Field(description="–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å")
    search_engine: str = Field(default="duckduckgo", description="–ü–æ–∏—Å–∫–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞: duckduckgo, google_scrape, serper, serpapi")
    num_results: int = Field(default=10, description="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–º–∞–∫—Å–∏–º—É–º 20)")
    language: str = Field(default="ru", description="–Ø–∑—ã–∫ –ø–æ–∏—Å–∫–∞ (ru, en)")

class GopiAIWebSearchTool(BaseTool):
    """
    –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ
    
    –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
    - –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ DuckDuckGo (–±–µ–∑ API –∫–ª—é—á–∞)
    - –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Google (—Å–∫—Ä–∞–ø–∏–Ω–≥)
    - –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Serper API (—Å –∫–ª—é—á–æ–º)
    - –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ SerpAPI (—Å –∫–ª—é—á–æ–º)
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –¥–æ—Å—Ç—É–ø–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞
    """
    
    name: str = Field(default="gopiai_web_search", description="–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –ø–æ–∏—Å–∫–∞ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ")
    description: str = Field(default="""–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–Ω—ã–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã–π –º–µ—Ç–æ–¥.
    –ù–µ —Ç—Ä–µ–±—É–µ—Ç API –∫–ª—é—á–µ–π –¥–ª—è –±–∞–∑–æ–≤–æ–≥–æ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞.""", description="–û–ø–∏—Å–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞")
    args_schema: Type[BaseModel] = WebSearchInput
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –ø–æ–∏—Å–∫–∞"""
        super().__init__()
    
    @property
    def logger(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ª–æ–≥–≥–µ—Ä–∞ –¥–ª—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞"""
        return logging.getLogger(__name__)
    
    @property
    def session(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ HTTP —Å–µ—Å—Å–∏–∏"""
        if not hasattr(self, '_session'):
            self._session = requests.Session()
            self._session.headers.update({
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            })
        return self._session
    
    @property
    def timeout(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–∞–π–º–∞—É—Ç–∞"""
        return 10
    
    @property
    def serper_key(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ API –∫–ª—é—á–∞ Serper"""
        return os.getenv('SERPER_API_KEY')
    
    @property
    def serpapi_key(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ API –∫–ª—é—á–∞ SerpAPI"""
        return os.getenv('SERPAPI_API_KEY')
    
    def _run(self, query: str, search_engine: str = "duckduckgo", num_results: int = 10, language: str = "ru") -> str:
        """
        –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–∏—Å–∫–∞ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ
        """
        try:
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞
            if not query or not query.strip():
                return "‚ùå –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –Ω–µ —É–∫–∞–∑–∞–Ω"
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            num_results = min(max(num_results, 1), 20)
            
            # –í—ã–±–∏—Ä–∞–µ–º –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞
            if search_engine == "auto":
                search_engine = self._choose_best_search_engine()
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
            if search_engine == "duckduckgo":
                return self._search_duckduckgo(query, num_results, language)
            elif search_engine == "google_scrape":
                return self._search_google_scrape(query, num_results, language)
            elif search_engine == "serper" and self.serper_key:
                return self._search_serper(query, num_results, language)
            elif search_engine == "serpapi" and self.serpapi_key:
                return self._search_serpapi(query, num_results, language)
            else:
                # Fallback –∫ DuckDuckGo
                return self._search_duckduckgo(query, num_results, language)
                
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ: {e}")
            return f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ: {str(e)}"
    
    def _choose_best_search_engine(self) -> str:
        """–í—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à–∏–π –¥–æ—Å—Ç—É–ø–Ω—ã–π –ø–æ–∏—Å–∫–æ–≤—ã–π –¥–≤–∏–∂–æ–∫"""
        if self.serper_key:
            return "serper"
        elif self.serpapi_key:
            return "serpapi"
        else:
            return "duckduckgo"
    
    def _search_duckduckgo(self, query: str, num_results: int, language: str) -> str:
        """–ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ DuckDuckGo (–±–µ–∑ API –∫–ª—é—á–∞)"""
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º URL –¥–ª—è –ø–æ–∏—Å–∫–∞
            encoded_query = quote_plus(query)
            url = f"https://html.duckduckgo.com/html/?q={encoded_query}"
            
            if language == "ru":
                url += "&kl=ru-ru"
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
            response = self.session.get(url, timeout=self.timeout)
            response.raise_for_status()
            
            # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            soup = BeautifulSoup(response.text, 'html.parser')
            results = []
            
            # –ò—â–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞
            search_results = soup.find_all('div', class_='result')
            
            for result in search_results[:num_results]:
                try:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ —Å—Å—ã–ª–∫—É
                    title_elem = result.find('a', class_='result__a')
                    if not title_elem:
                        continue
                    
                    title = title_elem.get_text(strip=True)
                    link = title_elem.get('href', '')
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ
                    snippet_elem = result.find('a', class_='result__snippet')
                    snippet = snippet_elem.get_text(strip=True) if snippet_elem else ""
                    
                    if title and link:
                        results.append({
                            'title': title,
                            'link': link,
                            'snippet': snippet
                        })
                        
                except Exception as e:
                    self.logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ DuckDuckGo: {e}")
                    continue
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            if results:
                response_text = f"üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ DuckDuckGo –¥–ª—è '{query}' ({len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤):\n\n"
                for i, result in enumerate(results, 1):
                    response_text += f"{i}. **{result['title']}**\n"
                    response_text += f"   {result['link']}\n"
                    if result['snippet']:
                        response_text += f"   {result['snippet']}\n"
                    response_text += "\n"
                return response_text
            else:
                return f"‚ùå –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{query}' –≤ DuckDuckGo"
                
        except Exception as e:
            return f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ DuckDuckGo: {str(e)}"
    
    def _search_google_scrape(self, query: str, num_results: int, language: str) -> str:
        """–ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Google (—Å–∫—Ä–∞–ø–∏–Ω–≥)"""
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º URL –¥–ª—è –ø–æ–∏—Å–∫–∞
            encoded_query = quote_plus(query)
            url = f"https://www.google.com/search?q={encoded_query}&num={num_results}"
            
            if language == "ru":
                url += "&hl=ru&lr=lang_ru"
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
            response = self.session.get(url, timeout=self.timeout)
            response.raise_for_status()
            
            # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            soup = BeautifulSoup(response.text, 'html.parser')
            results = []
            
            # –ò—â–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ (Google —á–∞—Å—Ç–æ –º–µ–Ω—è–µ—Ç –∫–ª–∞—Å—Å—ã)
            search_results = soup.find_all('div', class_='g')
            
            for result in search_results[:num_results]:
                try:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ —Å—Å—ã–ª–∫—É
                    title_elem = result.find('h3')
                    link_elem = result.find('a')
                    
                    if not title_elem or not link_elem:
                        continue
                    
                    title = title_elem.get_text(strip=True)
                    link = link_elem.get('href', '')
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ
                    snippet_elem = result.find('span', class_='aCOpRe') or result.find('div', class_='VwiC3b')
                    snippet = snippet_elem.get_text(strip=True) if snippet_elem else ""
                    
                    if title and link and link.startswith('http'):
                        results.append({
                            'title': title,
                            'link': link,
                            'snippet': snippet
                        })
                        
                except Exception as e:
                    self.logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ Google: {e}")
                    continue
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            if results:
                response_text = f"üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ Google –¥–ª—è '{query}' ({len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤):\n\n"
                for i, result in enumerate(results, 1):
                    response_text += f"{i}. **{result['title']}**\n"
                    response_text += f"   {result['link']}\n"
                    if result['snippet']:
                        response_text += f"   {result['snippet']}\n"
                    response_text += "\n"
                return response_text
            else:
                return f"‚ùå –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{query}' –≤ Google"
                
        except Exception as e:
            return f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ Google: {str(e)}"
    
    def _search_serper(self, query: str, num_results: int, language: str) -> str:
        """–ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Serper API"""
        try:
            url = "https://google.serper.dev/search"
            
            payload = {
                "q": query,
                "num": num_results
            }
            
            if language == "ru":
                payload["gl"] = "ru"
                payload["hl"] = "ru"
            
            headers = {
                "X-API-KEY": self.serper_key,
                "Content-Type": "application/json"
            }
            
            response = requests.post(url, json=payload, headers=headers, timeout=self.timeout)
            response.raise_for_status()
            
            data = response.json()
            results = []
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ä–≥–∞–Ω–∏—á–µ—Å–∫–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if 'organic' in data:
                for result in data['organic'][:num_results]:
                    results.append({
                        'title': result.get('title', ''),
                        'link': result.get('link', ''),
                        'snippet': result.get('snippet', '')
                    })
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            if results:
                response_text = f"üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ Serper –¥–ª—è '{query}' ({len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤):\n\n"
                for i, result in enumerate(results, 1):
                    response_text += f"{i}. **{result['title']}**\n"
                    response_text += f"   {result['link']}\n"
                    if result['snippet']:
                        response_text += f"   {result['snippet']}\n"
                    response_text += "\n"
                return response_text
            else:
                return f"‚ùå –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{query}' –≤ Serper"
                
        except Exception as e:
            return f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ Serper: {str(e)}"
    
    def _search_serpapi(self, query: str, num_results: int, language: str) -> str:
        """–ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ SerpAPI"""
        try:
            url = "https://serpapi.com/search"
            
            params = {
                "engine": "google",
                "q": query,
                "num": num_results,
                "api_key": self.serpapi_key
            }
            
            if language == "ru":
                params["gl"] = "ru"
                params["hl"] = "ru"
            
            response = requests.get(url, params=params, timeout=self.timeout)
            response.raise_for_status()
            
            data = response.json()
            results = []
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ä–≥–∞–Ω–∏—á–µ—Å–∫–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if 'organic_results' in data:
                for result in data['organic_results'][:num_results]:
                    results.append({
                        'title': result.get('title', ''),
                        'link': result.get('link', ''),
                        'snippet': result.get('snippet', '')
                    })
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            if results:
                response_text = f"üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ SerpAPI –¥–ª—è '{query}' ({len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤):\n\n"
                for i, result in enumerate(results, 1):
                    response_text += f"{i}. **{result['title']}**\n"
                    response_text += f"   {result['link']}\n"
                    if result['snippet']:
                        response_text += f"   {result['snippet']}\n"
                    response_text += "\n"
                return response_text
            else:
                return f"‚ùå –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{query}' –≤ SerpAPI"
                
        except Exception as e:
            return f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ SerpAPI: {str(e)}"
    
    def get_available_engines(self) -> List[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø–æ–∏—Å–∫–æ–≤—ã—Ö –¥–≤–∏–∂–∫–æ–≤"""
        engines = ["duckduckgo", "google_scrape"]
        
        if self.serper_key:
            engines.append("serper")
        
        if self.serpapi_key:
            engines.append("serpapi")
        
        return engines