"""
üîÑ GopiAI AI Router LLM –¥–ª—è CrewAI
–ê–¥–∞–ø—Ç–µ—Ä, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π Python-based —Å–∏—Å—Ç–µ–º—É —Ä–æ—Ç–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π.
"""

import traceback
from typing import Dict, List, Optional, Any, Mapping

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –±–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –∏ –Ω–æ–≤—É—é –ª–æ–≥–∏–∫—É —Ä–æ—Ç–∞—Ü–∏–∏
from .base.base_tool import GopiAIBaseTool
from llm_rotation_config import select_llm_model_safe, rate_limit_monitor, get_api_key_for_provider, LLM_MODELS_CONFIG
from crewai import Agent, Task, Crew, Process
from crewai import LLM

class AIRouterLLM(GopiAIBaseTool):
    """
    LLM-–∞–¥–∞–ø—Ç–µ—Ä –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è AI Router —Å CrewAI.
    
    –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ä–æ—Ç–∞—Ü–∏—è –º–µ–∂–¥—É –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º–∏
    - Fallback –ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ –ª–∏–º–∏—Ç–æ–≤
    - –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ–¥ –∑–∞–¥–∞—á—É
    """
    
    def __init__(self, **kwargs):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç AI Router LLM –∞–¥–∞–ø—Ç–µ—Ä"""
        super().__init__()
        self.model_configs = {m['id']: m for m in LLM_MODELS_CONFIG}
        print("‚úÖ Python-based AI Router LLM –∞–¥–∞–ø—Ç–µ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
    
    def call(self, prompt: str, temperature: float = 0.7, max_tokens: int = 2000) -> str:
        """
        –í—ã–∑–æ–≤ LLM —á–µ—Ä–µ–∑ AI Router
        
        –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É, –æ–∂–∏–¥–∞–µ–º–æ–º—É CrewAI
        """
        try:
            # 1. –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å
            # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ –æ—Ü–µ–Ω–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –ø—Ä–æ–º–ø—Ç–µ
            prompt_tokens = len(prompt) // 3 
            model_id = select_llm_model_safe("dialog", tokens=prompt_tokens)
            
            if not model_id:
                return "‚ùå –í—Å–µ LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã –∏–∑-–∑–∞ –ª–∏–º–∏—Ç–æ–≤. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ."

            model_config = self.model_configs.get(model_id)
            if not model_config:
                 return f"‚ùå –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏ {model_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞."

            provider_name = model_config['provider']
            api_key = get_api_key_for_provider(provider_name)

            if not api_key:
                return f"‚ùå API –∫–ª—é—á –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ {provider_name} –Ω–µ –Ω–∞–π–¥–µ–Ω."

            print(f"üîÑ AI Router: –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å '{model_id}' –æ—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ '{provider_name}'.")

            # 2. –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä LLM
            llm_params = {
                'model': model_id,
                'api_key': api_key,
                'config': {
                    'temperature': temperature,
                    'max_tokens': max_tokens,
                }
            }
            # –î–ª—è –º–æ–¥–µ–ª–µ–π Google (gemini) CrewAI –Ω–µ —Ç—Ä–µ–±—É–µ—Ç base_url,
            # –æ–Ω –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ –ø—Ä–µ—Ñ–∏–∫—Å—É –º–æ–¥–µ–ª–∏.

            llm_instance = LLM(**llm_params)

            # 3. –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
            response = llm_instance.call(prompt)
            
            # 4. –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
            response_tokens = len(response) // 3
            rate_limit_monitor.register_use(model_id, tokens=prompt_tokens + response_tokens)
            
            return response

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ AI Router: {e}")
            traceback.print_exc()
            return f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ AI Router: {e}"
            
    def get_llm_instance(self):
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä LLM –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å CrewAI
        
        Returns:
            LLM: –≠–∫–∑–µ–º–ø–ª—è—Ä LLM –¥–ª—è CrewAI
        """
        try:
            from langchain.llms.base import LLM as LangChainLLM
            
            class AIRouterWrapper(LangChainLLM):
                """–û–±–µ—Ä—Ç–∫–∞ –¥–ª—è AI Router, —Å–æ–≤–º–µ—Å—Ç–∏–º–∞—è —Å LangChain/CrewAI"""
                
                def __init__(self, ai_router: 'AIRouterLLM', **kwargs):
                    super().__init__(**kwargs)
                    self.ai_router = ai_router
                
                @property
                def _llm_type(self) -> str:
                    return "gopiai_router"
                
                def _call(self, prompt: str, stop: Optional[List[str]] = None, **kwargs) -> str:
                    """–í—ã–∑–æ–≤ AI Router"""
                    # –ü–µ—Ä–µ–¥–∞–µ–º kwargs –≤ –æ—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ call
                    return self.ai_router.call(prompt, **kwargs)
                
                @property
                def _identifying_params(self) -> Mapping[str, Any]:
                    """–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è LangChain"""
                    return {"model": "gopiai_router"}
            
            return AIRouterWrapper(ai_router=self)
            
        except ImportError:
            print("‚ö†Ô∏è langchain –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º self. –≠—Ç–æ –º–æ–∂–µ—Ç –≤—ã–∑–≤–∞—Ç—å –ø—Ä–æ–±–ª–µ–º—ã –≤ CrewAI.")
            return self

    def _run(self, message: str, **kwargs) -> str:
        """
        –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –Ω–∞—Å–ª–µ–¥–Ω–∏–∫–æ–≤ GopiAIBaseTool
        –ü–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª—è–µ—Ç –≤—ã–∑–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ `call`.
        """
        return self.call(message, **kwargs)
