import logging
import traceback
import time
from typing import List, Optional, Any, Mapping, ClassVar
from pydantic import Field

# –ò–º–ø–æ—Ä—Ç –Ω–∞—à–µ–≥–æ –∫–∞—Å—Ç–æ–º–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞ –¥–ª—è –æ–±—Ö–æ–¥–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ Gemini
from .gemini_crewai_adapter import GeminiDirectLLM, create_gemini_direct_llm
from langchain.llms.base import BaseLLM
from langchain.schema import LLMResult, Generation
import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω—é GopiAI-CrewAI
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.append(project_root)

from llm_rotation_config import (
    select_llm_model_safe, 
    rate_limit_monitor, 
    LLM_MODELS_CONFIG,
    get_available_models,
    get_models_by_intelligence,
    get_next_available_model,
    register_use,
    is_model_blacklisted
)
# –ï–î–ò–ù–´–ô –ò–°–¢–û–ß–ù–ò–ö –ü–†–ê–í–î–´: –º–µ–Ω–µ–¥–∂–µ—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π –º–æ–¥–µ–ª–µ–π
from .model_config_manager import get_model_config_manager, ModelProvider
# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º LLM –∏–∑ crewai
from crewai.llm import LLM
class AIRouterLLM(BaseLLM):
    """
    –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô AI Router —Å bulletproof —Å–∏—Å—Ç–µ–º–æ–π —Ä–æ—Ç–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π
    
    –û—Å–Ω–æ–≤–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è:
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö API 429
    - –ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å
    - Comprehensive error detection –∏ handling
    - Graceful degradation –ø—Ä–∏ –∏—Å—á–µ—Ä–ø–∞–Ω–∏–∏ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
    """
    logger: ClassVar[logging.Logger] = logging.getLogger(__name__)
    model_configs: dict = Field(default_factory=dict)
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.model_configs = {m['id']: m for m in LLM_MODELS_CONFIG}
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π –∫–∞–∫ single source of truth
        try:
            self.model_config_manager = get_model_config_manager()
            self.logger.info("‚úÖ AIRouterLLM –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å ModelConfigurationManager (SSOT)")
        except Exception as e:
            self.model_config_manager = None
            self.logger.warning(f"‚ö†Ô∏è ModelConfigurationManager –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
        self.logger.info("‚úÖ AIRouterLLM –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π —Ä–æ—Ç–∞—Ü–∏–∏")
    def _is_quota_error(self, error):
        """–î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç –≤—Å–µ —Ç–∏–ø—ã –æ—à–∏–±–æ–∫ –ª–∏–º–∏—Ç–æ–≤ –∏ –∫–≤–æ—Ç"""
        error_str = str(error).lower()
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ keywords –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ—à–∏–±–æ–∫ –∫–≤–æ—Ç
        quota_keywords = [
            'quota', 'rate limit', 'exceeded', 'resource_exhausted', 
            'too many requests', '429', 'billing', 'quota_exceeded',
            'limit_exceeded', 'rate_limited', 'throttled', 'overloaded',
            'service unavailable', 'temporarily_unavailable', 'capacity',
            'usage_limit', 'daily_quota', 'monthly_quota', 'free_quota'
        ]
        
        is_quota = any(keyword in error_str for keyword in quota_keywords)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ HTTP —Å—Ç–∞—Ç—É—Å –∫–æ–¥–æ–≤
        status_codes = ['429', '503', '502', '500']
        has_status_code = any(code in error_str for code in status_codes)
        
        return is_quota or has_status_code
    def _try_model_request(self, prompt, model_id, attempt_number=1):
        """–ü–æ–ø—ã—Ç–∫–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        try:
            model_config = self.model_configs.get(model_id)
            if not model_config:
                raise ValueError(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏ {model_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            # –ñ–ï–°–¢–ö–û: –±–µ—Ä—ë–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –∏ –∫–ª—é—á –∏–∑ SSOT (model_configurations.json —á–µ—Ä–µ–∑ –º–µ–Ω–µ–¥–∂–µ—Ä)
            provider_name = model_config.get('provider')
            api_key_env = model_config.get('api_key_env')
            if self.model_config_manager:
                # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è env: –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º GOOGLE_API_KEY –∏ GEMINI_API_KEY –∫–∞–∫ —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω—ã–µ –¥–ª—è Gemini
                if provider_name == 'gemini' and api_key_env == 'GOOGLE_API_KEY':
                    api_key_env = 'GEMINI_API_KEY' if os.getenv('GEMINI_API_KEY') else 'GOOGLE_API_KEY'
                api_key = os.getenv(api_key_env or '')
            else:
                api_key = os.getenv(api_key_env or '')
            if not api_key:
                raise ValueError(f"API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω: env={api_key_env} –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ {provider_name}")
            
            # üöÄ –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –£–õ–£–ß–®–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞—Å—Ç–æ–º–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è Google/Gemini
            # –¥–ª—è –æ–±—Ö–æ–¥–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ (–±–µ–∑ safetySettings)
            if provider_name.lower() in ('google', 'gemini'):
                self.logger.info(f"üî• –ò—Å–ø–æ–ª—å–∑—É–µ–º GeminiDirectClient –¥–ª—è –æ–±—Ö–æ–¥–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ {model_id}")
                
                # –°–æ–∑–¥–∞–µ–º –Ω–∞—à –∫–∞—Å—Ç–æ–º–Ω—ã–π LLM –±–µ–∑ safetySettings
                llm_instance = create_gemini_direct_llm(
                    model=model_id,
                    api_key=api_key,
                    temperature=0.7,
                    max_tokens=8192  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤
                )
                
                self.logger.info(f"‚úÖ GeminiDirectLLM —Å–æ–∑–¥–∞–Ω –¥–ª—è –º–æ–¥–µ–ª–∏ {model_id} (–ë–ï–ó safetySettings!)")
            else:
                # –î–ª—è –¥—Ä—É–≥–∏—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–æ–¥—Ö–æ–¥
                llm_params = {
                    'model': model_id,
                    'api_key': api_key,
                    'config': {
                        'temperature': 0.7,
                        'max_tokens': 2000,
                    }
                }
                llm_instance = LLM(**llm_params)
                self.logger.info(f"üìã –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π LLM —Å–æ–∑–¥–∞–Ω –¥–ª—è –º–æ–¥–µ–ª–∏ {model_id}")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è rate limits
            if attempt_number > 1:
                delay = min(attempt_number * 2, 10)  # –ú–∞–∫—Å–∏–º—É–º 10 —Å–µ–∫—É–Ω–¥
                self.logger.info(f"‚è±Ô∏è –ó–∞–¥–µ—Ä–∂–∫–∞ {delay} —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ –ø–æ–ø—ã—Ç–∫–æ–π {attempt_number}")
                time.sleep(delay)
            
            self.logger.info(f"üîÑ –ü–æ–ø—ã—Ç–∫–∞ {attempt_number}: –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ –º–æ–¥–µ–ª–∏ {model_id}")
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
            response = llm_instance.call(prompt)
            
            if not response or response.strip() == "":
                raise ValueError("–ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏")
                
            self.logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏ {model_id} (–¥–ª–∏–Ω–∞: {len(response)} —Å–∏–º–≤–æ–ª–æ–≤)")
            return response
            
        except Exception as e:
            self.logger.warning(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ –º–æ–¥–µ–ª–∏ {model_id}: {e}")
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –¥–ª—è Google –º–æ–¥–µ–ª–µ–π
            if 'google' in model_id.lower() or 'gemini' in model_id.lower():
                self.logger.info(f"üîç –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ Google/Gemini –º–æ–¥–µ–ª–∏ {model_id}: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä—è–º–æ–π HTTP-–∫–ª–∏–µ–Ω—Ç –±–µ–∑ safetySettings")
            
            raise e
    def _generate(self, prompts: List[str], stop: Optional[List[str]] = None) -> LLMResult:
        generations = []
        
        for prompt_idx, prompt in enumerate(prompts):
            self.logger.info(f"üß† –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–º–ø—Ç–∞ {prompt_idx + 1}/{len(prompts)}")
            response_text = ""
            
            try:
                # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ –æ—Ü–µ–Ω–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –ø—Ä–æ–º–ø—Ç–µ
                prompt_tokens = len(prompt) // 3
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –Ω—É–∂–Ω–∞ –ª–∏ –≤—ã—Å–æ–∫–æ–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å
                intelligence_priority = (len(prompt) > 1000 or 
                                       "—Å–ª–æ–∂–Ω" in prompt.lower() or 
                                       "–∞–Ω–∞–ª–∏–∑" in prompt.lower() or
                                       "–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ" in prompt.lower())
                
                self.logger.info(f"üß† {'–í—ã—Å–æ–∫–∏–π' if intelligence_priority else '–û–±—ã—á–Ω—ã–π'} –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞")
                
                # üö® –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: Bulletproof —Å–∏—Å—Ç–µ–º–∞ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
                max_model_attempts = 3  # –ú–∞–∫—Å–∏–º—É–º –ø–æ–ø—ã—Ç–æ–∫ —Å —Ä–∞–∑–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
                current_model_id = None
                used_models = []
                
                for model_attempt in range(max_model_attempts):
                    try:
                        # –í—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å, –∏—Å–∫–ª—é—á–∞—è —É–∂–µ –ø–æ–ø—Ä–æ–±–æ–≤–∞–Ω–Ω—ã–µ
                        # –í—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å. –°—Ç–∞—Ä—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä exclude_models —É–±—Ä–∞–Ω –∏–∑ –≤—ã–∑–æ–≤–∞,
                        # —á—Ç–æ–±—ã –Ω–µ –ª–æ–º–∞—Ç—å —Å–∏–≥–Ω–∞—Ç—É—Ä—É select_llm_model_safe. –ò—Å–∫–ª—é—á–µ–Ω–∏–µ —É–∂–µ
                        # –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≤—ã–ø–æ–ª–Ω—è–µ–º –ª–æ–∫–∞–ª—å–Ω–æ –Ω–∞ —É—Ä–æ–≤–Ω–µ –∫–æ–¥–∞.
                        # select_llm_model_safe –ø–æ —Ç–µ–∫—É—â–µ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –°–õ–û–í–ê–†–¨ –º–æ–¥–µ–ª–∏,
                        # –∞ —Ç–∞–∫–∂–µ —Å–∞–º —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ—Ç –µ—ë –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ. –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º—Å—è –ø–æ–¥ —ç—Ç–æ API.
                        model_cfg = select_llm_model_safe(
                            task_type="dialog",
                            tokens=prompt_tokens,
                            intelligence_priority=intelligence_priority
                        )
                        # –õ–æ–∫–∞–ª—å–Ω–æ –∏—Å–∫–ª—é—á–∞–µ–º —É–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏ —á–µ—Ä–Ω—ã–π —Å–ø–∏—Å–æ–∫
                        if model_cfg:
                            cand_id = model_cfg.get("id")
                            if cand_id and (cand_id in used_models or is_model_blacklisted(cand_id)):
                                self.logger.info(
                                    f"‚Ü©Ô∏è –ú–æ–¥–µ–ª—å {cand_id} —É–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –∏–ª–∏ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–º blacklist ‚Äî –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Å–ª–µ–¥—É—é—â—É—é"
                                )
                                try:
                                    next_model_cfg = get_next_available_model(
                                        task_type="dialog",
                                        tokens=prompt_tokens
                                    )
                                    model_cfg = next_model_cfg
                                except Exception as _e:
                                    self.logger.debug(f"get_next_available_model –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω/–æ—à–∏–±–∫–∞: {_e}")
                        if model_cfg:
                            candidate_model_id = model_cfg.get("id")
                        else:
                            candidate_model_id = None
                        
                        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –º–æ–¥–µ–ª–∏, —É–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ —Ä–∞–Ω–µ–µ –∏–ª–∏ –Ω–∞—Ö–æ–¥—è—â–∏–µ—Å—è –≤ blacklist
                        if candidate_model_id and (candidate_model_id in used_models or is_model_blacklisted(candidate_model_id)):
                            self.logger.info(
                                f"‚Ü©Ô∏è –ú–æ–¥–µ–ª—å {candidate_model_id} —É–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –∏–ª–∏ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–º blacklists ‚Äî –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Å–ª–µ–¥—É—é—â—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é"
                            )
                            try:
                                next_model_cfg = get_next_available_model(
                                    task_type="dialog",
                                    tokens=prompt_tokens
                                )
                                model_cfg = next_model_cfg
                                candidate_model_id = next_model_cfg.get("id") if next_model_cfg else None
                            except Exception as _e:
                                self.logger.debug(f"get_next_available_model –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω/–≤–µ—Ä–Ω—É–ª –æ—à–∏–±–∫—É: {_e}")
                        
                        current_model_id = candidate_model_id
                        
                        if not current_model_id:
                            self.logger.error(f"‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –ø–æ—Å–ª–µ {model_attempt + 1} –ø–æ–ø—ã—Ç–æ–∫")
                            self.logger.error(f"Blacklist —Å—Ç–∞—Ç—É—Å: {rate_limit_monitor.get_blacklist_status()}")
                            self.logger.error(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏: {used_models}")
                            
                            # –ï—Å–ª–∏ —ç—Ç–æ –ø–µ—Ä–≤–∞—è –ø–æ–ø—ã—Ç–∫–∞ –∏ –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, –∂–¥–µ–º –∏ –ø—Ä–æ–±—É–µ–º –µ—â–µ —Ä–∞–∑
                            if model_attempt == 0:
                                self.logger.info("‚è±Ô∏è –û–∂–∏–¥–∞–Ω–∏–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π...")
                                time.sleep(30)  # –ñ–¥–µ–º 30 —Å–µ–∫—É–Ω–¥
                                continue
                            else:
                                raise Exception("–í—Å–µ –º–æ–¥–µ–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")
                        
                        used_models.append(current_model_id)
                        
                        # –ò–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
                        model_info = self.model_configs.get(current_model_id, {})
                        self.logger.info(f"üéØ –ü–æ–ø—ã—Ç–∫–∞ {model_attempt + 1}: –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å '{current_model_id}' " +
                                       f"(–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {model_info.get('priority', 'N/A')}, " +
                                       f"score: {model_info.get('base_score', 'N/A')})")
                        
                        # –ü—ã—Ç–∞–µ–º—Å—è –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å —Å retry –ª–æ–≥–∏–∫–æ–π –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏
                        max_retries = 2  # –ú–∞–∫—Å–∏–º—É–º –ø–æ–ø—ã—Ç–æ–∫ –¥–ª—è –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏
                        last_error = None
                        
                        for retry_attempt in range(max_retries):
                            try:
                                response_text = self._try_model_request(
                                    prompt, 
                                    current_model_id, 
                                    retry_attempt + 1
                                )
                                
                                # –£—Å–ø–µ—Ö! –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∏ –≤—ã—Ö–æ–¥–∏–º
                                response_tokens = len(response_text) // 3
                                # –ü–æ –Ω–æ–≤–æ–π —Å—Ö–µ–º–µ register_use –ø—Ä–∏–Ω–∏–º–∞–µ—Ç model_id
                                register_use(
                                    current_model_id,
                                    tokens=prompt_tokens + response_tokens
                                )
                                
                                self.logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –ø—Ä–æ–º–ø—Ç {prompt_idx + 1} –º–æ–¥–µ–ª—å—é {current_model_id}")
                                break  # –í—ã—Ö–æ–¥–∏–º –∏–∑ retry loop
                                
                            except Exception as retry_error:
                                last_error = retry_error
                                self.logger.warning(f"‚ö†Ô∏è Retry {retry_attempt + 1}/{max_retries} –¥–ª—è –º–æ–¥–µ–ª–∏ {current_model_id}: {retry_error}")
                                
                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –æ—à–∏–±–∫–∏
                                if self._is_quota_error(retry_error):
                                    self.logger.error(f"üö´ Quota error –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –¥–ª—è –º–æ–¥–µ–ª–∏ {current_model_id}")
                                    # –í –Ω–æ–≤–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —É —Ç—Ä–µ–∫–µ—Ä–∞ –Ω–µ—Ç –ø—Ä—è–º–æ–≥–æ mark_model_unavailable.
                                    # –ü–æ–ª–∞–≥–µ–º—Å—è –Ω–∞ –º—è–≥–∫–∏–π blacklist –≤–Ω—É—Ç—Ä–∏ UsageTracker (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ RPM),
                                    # –∞ —Ç–∞–∫–∂–µ –∏–∑–±–µ–≥–∞–µ–º –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –≤ —Ç–µ–∫—É—â–µ–º —Ü–∏–∫–ª–µ:
                                    if current_model_id:
                                        used_models.append(current_model_id)
                                    break  # –í—ã—Ö–æ–¥–∏–º –∏–∑ retry loop –∏ –ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å
                                
                                # –î–ª—è –¥—Ä—É–≥–∏—Ö –æ—à–∏–±–æ–∫ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º retry
                                if retry_attempt < max_retries - 1:
                                    time.sleep(2 ** retry_attempt)  # Exponential backoff
                        
                        # –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–∏ –æ—Ç–≤–µ—Ç, –≤—ã—Ö–æ–¥–∏–º –∏–∑ loop –ø–æ–ø—ã—Ç–æ–∫ –º–æ–¥–µ–ª–µ–π
                        if response_text:
                            break
                            
                        # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–∏ –æ—Ç–≤–µ—Ç, –ª–æ–≥–∏—Ä—É–µ–º –∏ –ø—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â—É—é –º–æ–¥–µ–ª—å
                        if self._is_quota_error(last_error):
                            self.logger.warning(f"üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é –º–æ–¥–µ–ª—å –∏–∑-–∑–∞ quota error")
                        else:
                            self.logger.warning(f"üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é –º–æ–¥–µ–ª—å –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏: {last_error}")
                            
                    except Exception as model_error:
                        self.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –º–æ–¥–µ–ª—å—é {current_model_id}: {model_error}")
                        
                        # –ï—Å–ª–∏ —ç—Ç–æ quota error, –±–ª–æ–∫–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
                        if current_model_id and self._is_quota_error(model_error):
                            # –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ, –º—è–≥–∫–∏–π blacklist –∏ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏–∑ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –≤—ã–±–æ—Ä–∞
                            used_models.append(current_model_id)
                        
                        # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∫ —Å–ª–µ–¥—É—é—â–µ–π –º–æ–¥–µ–ª–∏
                        continue
                
                # –ï—Å–ª–∏ –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫ –Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞
                if not response_text:
                    blacklist_status = rate_limit_monitor.get_blacklist_status()
                    response_text = (f"‚ùå –í—Å–µ LLM –º–æ–¥–µ–ª–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã –∏–∑-–∑–∞ –∏—Å—á–µ—Ä–ø–∞–Ω–∏—è –ª–∏–º–∏—Ç–æ–≤. "
                                   f"–ó–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω—ã: {list(blacklist_status.keys())}. "
                                   f"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
                    
                    self.logger.error(f"üí• –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –°–ò–¢–£–ê–¶–ò–Ø: –í—Å–µ –º–æ–¥–µ–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞ {prompt_idx + 1}")
                    self.logger.error(f"Blacklist: {blacklist_status}")
                    self.logger.error(f"–ü–æ–ø—Ä–æ–±–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏: {used_models}")
            except Exception as e:
                self.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø—Ä–æ–º–ø—Ç–∞ {prompt_idx + 1}: {e}")
                traceback.print_exc()
                response_text = f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ AI Router: {e}"
            generations.append([Generation(text=response_text)])
            
        return LLMResult(generations=generations)
    @property
    def _llm_type(self) -> str:
        return "ai_router_bulletproof"
    @property
    def _identifying_params(self) -> Mapping[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã LLM."""
        return {"model": self._llm_type}
    def _run(self, message: str, **kwargs) -> str:
        """
        –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –Ω–∞—Å–ª–µ–¥–Ω–∏–∫–æ–≤ GopiAIBaseTool
        –ü–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª—è–µ—Ç –≤—ã–∑–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ `_generate`.
        """
        result = self._generate(prompts=[message])
        return result.generations[0][0].text
    def get_llm_instance(self) -> LLM:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä LLM –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ CrewAI —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Ä–æ—Ç–∞—Ü–∏–µ–π.
        """
        try:
            # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å
            # –£–±–∏—Ä–∞–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ select_llm_model_safe
            model_id = select_llm_model_safe("dialog", intelligence_priority=True)
            if not model_id:
                model_id = select_llm_model_safe("dialog", intelligence_priority=False)
            if not model_id:
                raise ValueError("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è CrewAI")
            
            model_config = self.model_configs.get(model_id)
            if not model_config:
                raise ValueError(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏ {model_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            
            provider_name = model_config.get('provider')
            api_key_env = model_config.get('api_key_env')
            # –ï–¥–∏–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –ø—Ä–∞–≤–¥—ã: –∫–ª—é—á –±–µ—Ä—ë–º –∏–∑ api_key_env
            if provider_name == 'gemini' and api_key_env == 'GOOGLE_API_KEY':
                api_key_env = 'GEMINI_API_KEY' if os.getenv('GEMINI_API_KEY') else 'GOOGLE_API_KEY'
            api_key = os.getenv(api_key_env or '')
            if not api_key:
                raise ValueError(f"API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω: env={api_key_env} –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ {provider_name}")
            
            # –î–ª—è Gemini –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—à –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç; –∏–Ω–∞—á–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π LLM
            if provider_name and provider_name.lower() in ('google', 'gemini'):
                llm_instance = create_gemini_direct_llm(
                    model=model_id,
                    api_key=api_key,
                    temperature=0.7,
                    max_tokens=8192
                )
                self.logger.info(f"üéØ CrewAI –∏—Å–ø–æ–ª—å–∑—É–µ—Ç GeminiDirectLLM: {model_id} (env={api_key_env})")
                return llm_instance  # —Å–æ–≤–º–µ—Å—Ç–∏–º —Å crewai.llm.LLM –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º-–∞–¥–∞–ø—Ç–µ—Ä–æ–º
            else:
                llm_params = {
                    'model': model_id,
                    'api_key': api_key,
                    'config': {
                        'temperature': 0.7,
                        'max_tokens': 2000,
                    }
                }
                self.logger.info(f"üéØ CrewAI –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π LLM: {model_id} –ø—Ä–æ–≤–∞–π–¥–µ—Ä={provider_name} (env={api_key_env})")
                return LLM(**llm_params)
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ LLM instance –¥–ª—è CrewAI: {e}")
            raise e
    # üö® –ù–û–í–û–ï: –ú–µ—Ç–æ–¥—ã –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
    def get_system_status(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã —Ä–æ—Ç–∞—Ü–∏–∏"""
        blacklist = rate_limit_monitor.get_blacklist_status()
        available_models = [m['id'] for m in get_available_models() 
                          if not is_model_blacklisted(m['id'])]
        
        return {
            "blacklisted_models": blacklist,
            "available_models": available_models,
            "total_models": len(LLM_MODELS_CONFIG),
            "blocked_count": len(blacklist),
            "available_count": len(available_models)
        }
    def force_unblock_model(self, model_id):
        """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–±–ª–æ–∫–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)"""
        # –í –Ω–æ–≤–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω–µ—Ç –ø—Ä—è–º–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ –∫ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞–º blacklist.
        # –ü–æ—Å–∫–æ–ª—å–∫—É –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º—è–≥–∫–∏–π blacklist –ø–æ –≤—Ä–µ–º–µ–Ω–∏, —è–≤–Ω–∞—è —Ä–∞–∑–±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è.
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º False –∏ –ª–æ–≥–∏—Ä—É–µ–º –ø–æ–¥—Å–∫–∞–∑–∫—É.
        self.logger.info("‚õî –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è —Ä–∞–∑–±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –≤ —Ç–µ–∫—É—â–µ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ UsageTracker")
        return False
    def get_model_health(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç health check –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"""
        health = {}
        for model in LLM_MODELS_CONFIG:
            model_id = model['id']
            # –ï—Å–ª–∏ –Ω–µ—Ç –º–µ—Ç–æ–¥–∞ get_model_usage_stats, –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º usage_stats –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–≥–ª—É—à–∫—É
            health[model_id] = {
                "available": not is_model_blacklisted(model_id),
                "usage_stats": None,  # –∏–ª–∏ {} –µ—Å–ª–∏ –Ω—É–∂–µ–Ω –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å
                "priority": model['priority'],
                "deprecated": model.get('deprecated', False)
            }
        return health
