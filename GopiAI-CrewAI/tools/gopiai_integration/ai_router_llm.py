import logging
import traceback
import time
from typing import List, Optional, Any, Mapping, ClassVar
from pydantic import Field
from langchain.llms.base import BaseLLM
from langchain.schema import LLMResult, Generation
from llm_rotation_config import (
    select_llm_model_safe, 
    rate_limit_monitor, 
    get_api_key_for_provider, 
    LLM_MODELS_CONFIG,
    get_active_models,
    get_models_by_intelligence,
    get_next_available_model
)
from crewai import LLM # Assuming this is litellm's LLM
from .base.base_tool import GopiAIBaseTool # Keeping this for now, as _run method might use it
class AIRouterLLM(BaseLLM):
    """
    üö® –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô AI Router —Å bulletproof —Å–∏—Å—Ç–µ–º–æ–π —Ä–æ—Ç–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π
    
    –û—Å–Ω–æ–≤–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è:
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö API 429
    - –ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å
    - Comprehensive error detection –∏ handling
    - Graceful degradation –ø—Ä–∏ –∏—Å—á–µ—Ä–ø–∞–Ω–∏–∏ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
    """
    logger: ClassVar[logging.Logger] = logging.getLogger(__name__)
    model_configs: dict = Field(default_factory=dict)
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.model_configs = {m['id']: m for m in LLM_MODELS_CONFIG}
        self.logger.info("‚úÖ AIRouterLLM –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π —Ä–æ—Ç–∞—Ü–∏–∏")
    def _is_quota_error(self, error):
        """–î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç –≤—Å–µ —Ç–∏–ø—ã –æ—à–∏–±–æ–∫ –ª–∏–º–∏—Ç–æ–≤ –∏ –∫–≤–æ—Ç"""
        error_str = str(error).lower()
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ keywords –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ—à–∏–±–æ–∫ –∫–≤–æ—Ç
        quota_keywords = [
            'quota', 'rate limit', 'exceeded', 'resource_exhausted', 
            'too many requests', '429', 'billing', 'quota_exceeded',
            'limit_exceeded', 'rate_limited', 'throttled', 'overloaded',
            'service unavailable', 'temporarily_unavailable', 'capacity',
            'usage_limit', 'daily_quota', 'monthly_quota', 'free_quota'
        ]
        
        is_quota = any(keyword in error_str for keyword in quota_keywords)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ HTTP —Å—Ç–∞—Ç—É—Å –∫–æ–¥–æ–≤
        status_codes = ['429', '503', '502', '500']
        has_status_code = any(code in error_str for code in status_codes)
        
        return is_quota or has_status_code
    def _try_model_request(self, prompt, model_id, attempt_number=1):
        """–ü–æ–ø—ã—Ç–∫–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        try:
            model_config = self.model_configs.get(model_id)
            if not model_config:
                raise ValueError(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏ {model_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            provider_name = model_config['provider']
            api_key = get_api_key_for_provider(provider_name)
            if not api_key:
                raise ValueError(f"API –∫–ª—é—á –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ {provider_name} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä LLM
            llm_params = {
                'model': model_id,
                'api_key': api_key,
                'config': {
                    'temperature': 0.7,
                    'max_tokens': 2000,
                }
            }
            llm_instance = LLM(**llm_params)
            # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è rate limits
            if attempt_number > 1:
                delay = min(attempt_number * 2, 10)  # –ú–∞–∫—Å–∏–º—É–º 10 —Å–µ–∫—É–Ω–¥
                self.logger.info(f"‚è±Ô∏è –ó–∞–¥–µ—Ä–∂–∫–∞ {delay} —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ –ø–æ–ø—ã—Ç–∫–æ–π {attempt_number}")
                time.sleep(delay)
            self.logger.info(f"üîÑ –ü–æ–ø—ã—Ç–∫–∞ {attempt_number}: –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ –º–æ–¥–µ–ª–∏ {model_id}")
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
            response = llm_instance.call(prompt)
            
            if not response or response.strip() == "":
                raise ValueError("–ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏")
                
            self.logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏ {model_id}")
            return response
        except Exception as e:
            self.logger.warning(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ –º–æ–¥–µ–ª–∏ {model_id}: {e}")
            raise e
    def _generate(self, prompts: List[str], stop: Optional[List[str]] = None) -> LLMResult:
        generations = []
        
        for prompt_idx, prompt in enumerate(prompts):
            self.logger.info(f"üß† –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–º–ø—Ç–∞ {prompt_idx + 1}/{len(prompts)}")
            response_text = ""
            
            try:
                # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ –æ—Ü–µ–Ω–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –ø—Ä–æ–º–ø—Ç–µ
                prompt_tokens = len(prompt) // 3
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –Ω—É–∂–Ω–∞ –ª–∏ –≤—ã—Å–æ–∫–æ–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å
                intelligence_priority = (len(prompt) > 1000 or 
                                       "—Å–ª–æ–∂–Ω" in prompt.lower() or 
                                       "–∞–Ω–∞–ª–∏–∑" in prompt.lower() or
                                       "–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ" in prompt.lower())
                
                self.logger.info(f"üß† {'–í—ã—Å–æ–∫–∏–π' if intelligence_priority else '–û–±—ã—á–Ω—ã–π'} –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞")
                
                # üö® –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: Bulletproof —Å–∏—Å—Ç–µ–º–∞ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
                max_model_attempts = 3  # –ú–∞–∫—Å–∏–º—É–º –ø–æ–ø—ã—Ç–æ–∫ —Å —Ä–∞–∑–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
                current_model_id = None
                used_models = []
                
                for model_attempt in range(max_model_attempts):
                    try:
                        # –í—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å, –∏—Å–∫–ª—é—á–∞—è —É–∂–µ –ø–æ–ø—Ä–æ–±–æ–≤–∞–Ω–Ω—ã–µ
                        current_model_id = select_llm_model_safe(
                            "dialog", 
                            tokens=prompt_tokens, 
                            intelligence_priority=intelligence_priority,
                            exclude_models=used_models
                        )
                        
                        if not current_model_id:
                            self.logger.error(f"‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –ø–æ—Å–ª–µ {model_attempt + 1} –ø–æ–ø—ã—Ç–æ–∫")
                            self.logger.error(f"Blacklist —Å—Ç–∞—Ç—É—Å: {rate_limit_monitor.get_blacklist_status()}")
                            self.logger.error(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏: {used_models}")
                            
                            # –ï—Å–ª–∏ —ç—Ç–æ –ø–µ—Ä–≤–∞—è –ø–æ–ø—ã—Ç–∫–∞ –∏ –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, –∂–¥–µ–º –∏ –ø—Ä–æ–±—É–µ–º –µ—â–µ —Ä–∞–∑
                            if model_attempt == 0:
                                self.logger.info("‚è±Ô∏è –û–∂–∏–¥–∞–Ω–∏–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π...")
                                time.sleep(30)  # –ñ–¥–µ–º 30 —Å–µ–∫—É–Ω–¥
                                continue
                            else:
                                raise Exception("–í—Å–µ –º–æ–¥–µ–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")
                        
                        used_models.append(current_model_id)
                        
                        # –ò–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
                        model_info = self.model_configs.get(current_model_id, {})
                        self.logger.info(f"üéØ –ü–æ–ø—ã—Ç–∫–∞ {model_attempt + 1}: –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å '{current_model_id}' " +
                                       f"(–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {model_info.get('priority', 'N/A')}, " +
                                       f"score: {model_info.get('base_score', 'N/A')})")
                        
                        # –ü—ã—Ç–∞–µ–º—Å—è –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å —Å retry –ª–æ–≥–∏–∫–æ–π –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏
                        max_retries = 2  # –ú–∞–∫—Å–∏–º—É–º –ø–æ–ø—ã—Ç–æ–∫ –¥–ª—è –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏
                        last_error = None
                        
                        for retry_attempt in range(max_retries):
                            try:
                                response_text = self._try_model_request(
                                    prompt, 
                                    current_model_id, 
                                    retry_attempt + 1
                                )
                                
                                # –£—Å–ø–µ—Ö! –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∏ –≤—ã—Ö–æ–¥–∏–º
                                response_tokens = len(response_text) // 3
                                rate_limit_monitor.register_use(
                                    current_model_id, 
                                    tokens=prompt_tokens + response_tokens
                                )
                                
                                self.logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –ø—Ä–æ–º–ø—Ç {prompt_idx + 1} –º–æ–¥–µ–ª—å—é {current_model_id}")
                                break  # –í—ã—Ö–æ–¥–∏–º –∏–∑ retry loop
                                
                            except Exception as retry_error:
                                last_error = retry_error
                                self.logger.warning(f"‚ö†Ô∏è Retry {retry_attempt + 1}/{max_retries} –¥–ª—è –º–æ–¥–µ–ª–∏ {current_model_id}: {retry_error}")
                                
                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –æ—à–∏–±–∫–∏
                                if self._is_quota_error(retry_error):
                                    self.logger.error(f"üö´ Quota error –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –¥–ª—è –º–æ–¥–µ–ª–∏ {current_model_id}")
                                    # –ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ –±–ª–æ–∫–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å –∏ –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–π
                                    rate_limit_monitor.mark_model_unavailable(current_model_id, duration=3600)
                                    break  # –í—ã—Ö–æ–¥–∏–º –∏–∑ retry loop –∏ –ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å
                                
                                # –î–ª—è –¥—Ä—É–≥–∏—Ö –æ—à–∏–±–æ–∫ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º retry
                                if retry_attempt < max_retries - 1:
                                    time.sleep(2 ** retry_attempt)  # Exponential backoff
                        
                        # –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–∏ –æ—Ç–≤–µ—Ç, –≤—ã—Ö–æ–¥–∏–º –∏–∑ loop –ø–æ–ø—ã—Ç–æ–∫ –º–æ–¥–µ–ª–µ–π
                        if response_text:
                            break
                            
                        # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–∏ –æ—Ç–≤–µ—Ç, –ª–æ–≥–∏—Ä—É–µ–º –∏ –ø—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â—É—é –º–æ–¥–µ–ª—å
                        if self._is_quota_error(last_error):
                            self.logger.warning(f"üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é –º–æ–¥–µ–ª—å –∏–∑-–∑–∞ quota error")
                        else:
                            self.logger.warning(f"üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é –º–æ–¥–µ–ª—å –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏: {last_error}")
                            
                    except Exception as model_error:
                        self.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –º–æ–¥–µ–ª—å—é {current_model_id}: {model_error}")
                        
                        # –ï—Å–ª–∏ —ç—Ç–æ quota error, –±–ª–æ–∫–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
                        if current_model_id and self._is_quota_error(model_error):
                            rate_limit_monitor.mark_model_unavailable(current_model_id, duration=3600)
                        
                        # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∫ —Å–ª–µ–¥—É—é—â–µ–π –º–æ–¥–µ–ª–∏
                        continue
                
                # –ï—Å–ª–∏ –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫ –Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞
                if not response_text:
                    blacklist_status = rate_limit_monitor.get_blacklist_status()
                    response_text = (f"‚ùå –í—Å–µ LLM –º–æ–¥–µ–ª–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã –∏–∑-–∑–∞ –∏—Å—á–µ—Ä–ø–∞–Ω–∏—è –ª–∏–º–∏—Ç–æ–≤. "
                                   f"–ó–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω—ã: {list(blacklist_status.keys())}. "
                                   f"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
                    
                    self.logger.error(f"üí• –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –°–ò–¢–£–ê–¶–ò–Ø: –í—Å–µ –º–æ–¥–µ–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞ {prompt_idx + 1}")
                    self.logger.error(f"Blacklist: {blacklist_status}")
                    self.logger.error(f"–ü–æ–ø—Ä–æ–±–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏: {used_models}")
            except Exception as e:
                self.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø—Ä–æ–º–ø—Ç–∞ {prompt_idx + 1}: {e}")
                traceback.print_exc()
                response_text = f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ AI Router: {e}"
            generations.append([Generation(text=response_text)])
            
        return LLMResult(generations=generations)
    @property
    def _llm_type(self) -> str:
        return "ai_router_bulletproof"
    @property
    def _identifying_params(self) -> Mapping[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã LLM."""
        return {"model": self._llm_type}
    def _run(self, message: str, **kwargs) -> str:
        """
        –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –Ω–∞—Å–ª–µ–¥–Ω–∏–∫–æ–≤ GopiAIBaseTool
        –ü–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª—è–µ—Ç –≤—ã–∑–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ `_generate`.
        """
        result = self._generate(prompts=[message])
        return result.generations[0][0].text
    def get_llm_instance(self) -> LLM:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä LLM –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ CrewAI —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Ä–æ—Ç–∞—Ü–∏–µ–π.
        """
        try:
            # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å
            model_id = select_llm_model_safe("dialog", intelligence_priority=True)
            
            if not model_id:
                # Fallback: –ø—Ä–æ–±—É–µ–º –ª—é–±—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å
                model_id = select_llm_model_safe("dialog", intelligence_priority=False)
                
            if not model_id:
                raise ValueError("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è CrewAI")
            
            model_config = self.model_configs.get(model_id)
            if not model_config:
                raise ValueError(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏ {model_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                
            provider_name = model_config['provider']
            api_key = get_api_key_for_provider(provider_name)
            if not api_key:
                raise ValueError(f"API –∫–ª—é—á –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ {provider_name} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            llm_params = {
                'model': model_id,
                'api_key': api_key,
                'config': {
                    'temperature': 0.7,
                    'max_tokens': 2000,
                }
            }
            
            self.logger.info(f"üéØ CrewAI –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å: {model_id}")
            return LLM(**llm_params)
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ LLM instance –¥–ª—è CrewAI: {e}")
            raise e
    # üö® –ù–û–í–û–ï: –ú–µ—Ç–æ–¥—ã –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
    def get_system_status(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã —Ä–æ—Ç–∞—Ü–∏–∏"""
        blacklist = rate_limit_monitor.get_blacklist_status()
        available_models = [m['id'] for m in get_active_models() 
                          if not rate_limit_monitor.is_model_blocked(m['id'])]
        
        return {
            "blacklisted_models": blacklist,
            "available_models": available_models,
            "total_models": len(LLM_MODELS_CONFIG),
            "blocked_count": len(blacklist),
            "available_count": len(available_models)
        }
    def force_unblock_model(self, model_id):
        """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–±–ª–æ–∫–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)"""
        if model_id in rate_limit_monitor.blacklisted_models:
            del rate_limit_monitor.blacklisted_models[model_id]
            self.logger.info(f"üîì –ú–æ–¥–µ–ª—å {model_id} –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞")
            return True
        return False
    def get_model_health(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç health check –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"""
        health = {}
        for model in LLM_MODELS_CONFIG:
            model_id = model['id']
            # –ï—Å–ª–∏ –Ω–µ—Ç –º–µ—Ç–æ–¥–∞ get_model_usage_stats, –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º usage_stats –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–≥–ª—É—à–∫—É
            health[model_id] = {
                "available": not rate_limit_monitor.is_model_blocked(model_id),
                "usage_stats": None,  # –∏–ª–∏ {} –µ—Å–ª–∏ –Ω—É–∂–µ–Ω –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å
                "priority": model['priority'],
                "deprecated": model.get('deprecated', False)
            }
        return health