=== LLM PROVIDER: Cerebras ===
TIME: 20250623_224607_808365
LLM CONFIG: {'model': 'cerebras/llama3.1-70b', 'api_key': 'csk-4f2586c9p45n56hkejvd9ytcncrhfjrcfmw3ee4dtp8wef2c', 'base_url': 'https://api.cerebras.ai/v1', 'temperature': 0.5, 'max_tokens': 1500}
PROMPT: Скажи 'ОК'
EXCEPTION: litellm.NotFoundError: NotFoundError: CerebrasException - Model llama3.1-70b does not exist or you do not have access to it.
Traceback (most recent call last):
  File "C:\Users\crazy\GOPI_AI_MODULES\GopiAI-CrewAI\crewai_env\Lib\site-packages\litellm\llms\openai\openai.py", line 725, in completion
    raise e
  File "C:\Users\crazy\GOPI_AI_MODULES\GopiAI-CrewAI\crewai_env\Lib\site-packages\litellm\llms\openai\openai.py", line 653, in completion
    ) = self.make_sync_openai_chat_completion_request(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\crazy\GOPI_AI_MODULES\GopiAI-CrewAI\crewai_env\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 149, in sync_wrapper
    result = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\crazy\GOPI_AI_MODULES\GopiAI-CrewAI\crewai_env\Lib\site-packages\litellm\llms\openai\openai.py", line 471, in make_sync_openai_chat_completion_request
    raise e
  File "C:\Users\crazy\GOPI_AI_MODULES\GopiAI-CrewAI\crewai_env\Lib\site-packages\litellm\llms\openai\openai.py", line 453, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\crazy\GOPI_AI_MODULES\GopiAI-CrewAI\crewai_env\Lib\site-packages\openai\_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\crazy\GOPI_AI_MODULES\GopiAI-CrewAI\crewai_env\Lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\crazy\GOPI_AI_MODULES\GopiAI-CrewAI\crewai_env\Lib\site-packages\openai\resources\chat\completions\completions.py", line 925, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\crazy\GOPI_AI_MODULES\GopiAI-CrewAI\crewai_env\Lib\site-packages\openai\_base_client.py", line 1249, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\crazy\GOPI_AI_MODULES\GopiAI-CrewAI\crewai_env\Lib\site-packages\openai\_base_client.py", line 1037, in request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'message': 'Model llama3.1-70b does not exist or you do not have access to it.', 'type': 'not_found_error', 'param': 'model', 'code': 'model_not_found'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\crazy\GOPI_AI_MODULES\GopiAI-CrewAI\crewai_env\Lib\site-packages\litellm\main.py", line 1853, in completion
    raise e
  File "C:\Users\crazy\GOPI_AI_MODULES\GopiAI-CrewAI\crewai_env\Lib\site-packages\litellm\main.py", line 1826, in completion
    response = openai_chat_completions.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\crazy\GOPI_AI_MODULES\GopiAI-CrewAI\crewai_env\Lib\site-packages\litellm\llms\openai\openai.py", line 736, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 404 - {'message': 'Model llama3.1-70b does not exist or you do not have access to it.', 'type': 'not_found_error', 'param': 'model', 'code': 'model_not_found'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\crazy\GOPI_AI_MODULES\GopiAI-CrewAI\main.py", line 194, in create_llm_with_fallback
    test_response = llm.call(test_prompt)
                    ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\crazy\GOPI_AI_MODULES\GopiAI-CrewAI\crewai_env\Lib\site-packages\crewai\llm.py", line 956, in call
    return self._handle_non_streaming_response(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\crazy\GOPI_AI_MODULES\GopiAI-CrewAI\crewai_env\Lib\site-packages\crewai\llm.py", line 768, in _handle_non_streaming_response
    response = litellm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\crazy\GOPI_AI_MODULES\GopiAI-CrewAI\crewai_env\Lib\site-packages\litellm\utils.py", line 1283, in wrapper
    raise e
  File "C:\Users\crazy\GOPI_AI_MODULES\GopiAI-CrewAI\crewai_env\Lib\site-packages\litellm\utils.py", line 1161, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\crazy\GOPI_AI_MODULES\GopiAI-CrewAI\crewai_env\Lib\site-packages\litellm\main.py", line 3241, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\crazy\GOPI_AI_MODULES\GopiAI-CrewAI\crewai_env\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2239, in exception_type
    raise e
  File "C:\Users\crazy\GOPI_AI_MODULES\GopiAI-CrewAI\crewai_env\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 420, in exception_type
    raise NotFoundError(
litellm.exceptions.NotFoundError: litellm.NotFoundError: NotFoundError: CerebrasException - Model llama3.1-70b does not exist or you do not have access to it.
