import os
import logging
from crewai import LLM

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ —Ñ–∞–π–ª
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('vertex_debug.log'),
        logging.StreamHandler()
    ]
)

# –ü–æ–ª—É—á–∞–µ–º –∫–ª—é—á –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è
api_key = os.getenv('GEMINI_API_KEY')
if not api_key:
    print("‚ùå GEMINI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
    exit(1)

print(f"‚úÖ GEMINI_API_KEY –Ω–∞–π–¥–µ–Ω: {api_key[:10]}...")

# –ü—Ä–æ–±—É–µ–º —Å–æ–∑–¥–∞—Ç—å LLM –∏ —Å–¥–µ–ª–∞—Ç—å –ø—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å
try:
    print("üîÑ –°–æ–∑–¥–∞–µ–º LLM —ç–∫–∑–µ–º–ø–ª—è—Ä...")
    llm = LLM(
        model='gemini/gemini-1.5-flash',
        api_key=api_key,
        config={
            'temperature': 0.7,
            'max_tokens': 100
        }
    )
    
    print("üîÑ –î–µ–ª–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å...")
    response = llm.call("–ü—Ä–æ—Å—Ç–æ —Å–∫–∞–∂–∏ '–ü—Ä–∏–≤–µ—Ç!'")
    
    print(f"‚úÖ –£—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç: {response}")
    
except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
    logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ LLM: {e}")

print("üìù –õ–æ–≥–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ vertex_debug.log")
